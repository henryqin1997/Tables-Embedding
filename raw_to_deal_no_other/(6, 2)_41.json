{"relation": [["Stat", "ep_version", "ep_storage_age", "ep_storage_age_highwat", "ep_min_data_age", "ep_startup_time", "ep_queue_age_cap", "ep_max_txn_size", "ep_data_age", "ep_data_age_highwat", "ep_too_young", "ep_too_old", "ep_total_enqueued", "ep_total_new_items", "ep_total_del_items", "ep_total_persisted", "ep_item_flush_failed", "ep_item_commit_failed", "ep_item_begin_failed", "ep_expired_access", "ep_expired_pager", "ep_item_flush_expired", "ep_queue_size", "ep_flusher_todo", "ep_flusher_state", "ep_commit_num", "ep_commit_time", "ep_commit_time_total", "ep_vbucket_del", "ep_vbucket_del_fail", "ep_vbucket_del_max_walltime", "ep_vbucket_del_avg_walltime", "ep_flush_duration_total", "ep_flush_all", "ep_num_ops_get_meta", "ep_num_ops_set_meta", "ep_num_ops_del_meta", "curr_items", "curr_temp_items", "curr_items_tot", "ep_kv_size", "ep_value_size", "ep_overhead", "ep_max_data_size", "ep_mem_low_wat", "ep_mem_high_wat", "ep_total_cache_size", "ep_oom_errors", "ep_tmp_oom_errors", "ep_mem_tracker_enabled", "ep_bg_fetched", "ep_bg_meta_fetched", "ep_bg_remaining_jobs", "ep_tap_bg_fetched", "ep_tap_bg_fetch_requeued", "ep_num_pager_runs", "ep_num_expiry_pager_runs", "ep_num_access_scanner_runs", "ep_access_scanner_num_items", "ep_access_scanner_task_time", "ep_access_scanner_last_runtime", "ep_items_rm_from_checkpoints", "ep_num_value_ejects", "ep_num_eject_failures", "ep_num_not_my_vbuckets", "ep_tap_keepalive", "ep_dbname", "ep_dbinit", "ep_io_num_read", "ep_io_num_write", "ep_io_read_bytes", "ep_io_write_bytes", "ep_pending_ops", "ep_pending_ops_total", "ep_pending_ops_max", "ep_pending_ops_max_duration", "ep_bg_num_samples", "ep_bg_min_wait", "ep_bg_max_wait", "ep_bg_wait_avg", "ep_bg_min_load", "ep_bg_max_load", "ep_bg_load_avg", "ep_num_non_resident", "ep_store_max_concurrency", "ep_store_max_readers", "ep_store_max_readwrite", "ep_bg_wait", "ep_bg_load", "ep_mlog_compactor_runs", "ep_vb_total", "curr_items_tot", "curr_items", "curr_temp_items", "vb_dead_num", "ep_diskqueue_items", "ep_diskqueue_memory", "ep_diskqueue_fill", "ep_diskqueue_drain", "ep_diskqueue_pending", "ep_vb_snapshot_total", "vb_active_num", "vb_active_curr_items", "vb_active_num_non_resident", "vb_active_perc_mem_resident", "vb_active_eject", "vb_active_expired", "vb_active_ht_memory", "vb_active_itm_memory", "vb_active_meta_data_memory", "vb_active_ops_create", "vb_active_ops_update", "vb_active_ops_delete", "vb_active_ops_reject", "vb_active_queue_size", "vb_active_queue_memory", "vb_active_queue_age", "vb_active_queue_pending", "vb_active_queue_fill", "vb_active_queue_drain", "vb_active_num_ref_items", "vb_active_num_ref_ejects", "vb_pending_num", "vb_pending_curr_items", "vb_pending_num_non_resident", "vb_pending_perc_mem_resident", "vb_pending_eject", "vb_pending_expired", "vb_pending_ht_memory", "vb_pending_itm_memory", "vb_pending_meta_data_memory", "vb_pending_ops_create", "vb_pending_ops_update", "vb_pending_ops_delete", "vb_pending_ops_reject", "vb_pending_queue_size", "vb_pending_queue_memory", "vb_pending_queue_age", "vb_pending_queue_pending", "vb_pending_queue_fill", "vb_pending_queue_drain", "vb_pending_num_ref_items", "vb_pending_num_ref_ejects"], ["Description", "Version number of ep_engine.", "Seconds since most recently stored object was initially queued.", "ep_storage_age high water mark", "Minimum data age setting.", "System-generated engine startup time", "Queue age cap setting.", "Max number of updates per transaction.", "Seconds since most recently stored object was modified.", "ep_data_age high water mark", "Deprecated in 2.1.0. Number of times an object was not stored due to being too young.", "Deprecated in 2.1.0. Number of times an object was stored after being dirty too long.", "Total number of items queued for persistence", "Total number of persisted new items.", "Total number of persisted deletions.", "Total number of items persisted.", "Number of times an item failed to flush due to storage errors.", "Number of times a transaction failed to commit due to storage errors.", "Number of times a transaction failed to start due to storage errors.", "Number of times an item was expired on application access.", "Number of times an item was expired by ep engine item pager.", "Number of times an item is not flushed due to the expiry of the item", "Number of items queued for storage.", "Number of items remaining to be written.", "Current state of the flusher thread.", "Total number of write commits.", "Number of milliseconds of most recent commit", "Cumulative milliseconds spent committing.", "Number of vbucket deletion events.", "Number of failed vbucket deletion events.", "Max wall time (\u00b5s) spent by deleting a vbucket", "Avg wall time (\u00b5s) spent by deleting a vbucket", "Cumulative seconds spent flushing.", "True if disk flush_all is scheduled", "Number of getMeta operations", "Number of setWithMeta operations", "Number of delWithMeta operations", "Num items in active vbuckets (temp + live)", "Num temp items in active vbuckets", "Num current items including those not active (replica, dead and pending states)", "Memory used to store item metadata, keys and values, no matter the vbucket\u2019s state. If an item\u2019s value is ejected, this stat will be decremented by the size of the item\u2019s value.", "Memory used to store values for resident keys", "Extra memory used by transient data like persistence queues, replication queues, checkpoints, etc.", "Max amount of data allowed in memory.", "Low water mark for auto-evictions.", "High water mark for auto-evictions.", "The total byte size of all items, no matter the vbucket\u2019s state, no matter if an item\u2019s value is ejected.", "Number of times unrecoverable OOMs happened while processing operations", "Number of times temporary OOMs happened while processing operations", "True if memory usage tracker is enabled", "Number of items fetched from disk.", "Number of meta items fetched from disk.", "Number of remaining background fetch jobs.", "Number of tap disk fetches", "Number of times a tap background fetch task is re-queued.", "Number of times we ran pager loops to seek additional memory.", "Number of times we ran expiry pager loops to purge expired items from memory/disk", "Number of times we ran access scanner to snapshot working set", "Number of items that last access scanner task swept to access log.", "Time of the next access scanner task (GMT)", "Number of seconds that last access scanner task took to complete.", "Number of items removed from closed unreferenced checkpoints.", "Number of times item values got ejected from memory to disk", "Number of items that could not be ejected", "Number of times Not My VBucket exception happened during runtime", "Tap keep-alive time.", "DB path.", "Number of seconds to initialize DB.", "Number of io read operations", "Number of io write operations", "Number of bytes read (key + values)", "Number of bytes written (key + values)", "Number of ops awaiting pending vbuckets", "Total blocked pending ops since reset", "Max ops seen awaiting 1 pending vbucket", "Max time (\u00b5s) used waiting on pending vbuckets", "The number of samples included in the average", "The shortest time (\u00b5s) in the wait queue", "The longest time (\u00b5s) in the wait queue", "The average wait time (\u00b5s) for an item before it is serviced by the dispatcher", "The shortest load time (\u00b5s)", "The longest load time (\u00b5s)", "The average time (\u00b5s) for an item to be loaded from the persistence layer", "The number of non-resident items", "Maximum allowed concurrency at the storage layer.", "Maximum number of concurrent read-only storage threads.", "Maximum number of concurrent read/write storage threads.", "The total elapse time for the wait queue", "The total elapse time for items to be loaded from the persistence layer", "Number of times mutation log compactor is executed", "Total vBuckets (count)", "Total number of items", "Number of active items in memory", "Number of temporary items in memory", "Number of dead vBuckets", "Total items in disk queue", "Total memory used in disk queue", "Total enqueued items on disk queue", "Total drained items on disk queue", "Total bytes of pending writes", "Total VB state snapshots persisted in disk", "Number of active vBuckets", "Number of in memory items", "Number of non-resident items", "% memory resident", "Number of times item values got ejected", "Number of times an item was expired", "Memory overhead of the hashtable", "Total item memory", "Total metadata memory", "Number of create operations", "Number of update operations", "Number of delete operations", "Number of rejected operations", "Active items in disk queue", "Memory used for disk queue", "Sum of disk queue item age in milliseconds", "Total bytes of pending writes", "Total enqueued items", "Total drained items", "Number of referenced items", "Number of times referenced item values got ejected", "Number of pending vBuckets", "Number of in memory items", "Number of non-resident items", "% of memory used for resident items", "Number of times item values got ejected", "Number of times an item was expired", "Memory overhead of the hashtable", "Total item in memory", "Total metadata memory", "Number of create operations", "Number of update operations", "Number of delete operations", "Number of rejected operations", "Pending items in disk queue", "Memory used for disk queue", "Sum of disk queue item age in milliseconds", "Total bytes of pending writes", "Total enqueued items", "Total drained items", "Number of referenced items", "Number of times referenced item values got ejected"]], "pageTitle": "couchbase-manual-2.1", "title": "", "url": "http://docs.couchbase.com/couchbase-manual-2.1/", "hasHeader": true, "headerPosition": "FIRST_ROW", "tableType": "RELATION", "tableNum": 27, "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042981525.10/warc/CC-MAIN-20150728002301-00115-ip-10-236-191-2.ec2.internal.warc.gz", "recordEndOffset": 74035487, "recordOffset": 73778130, "tableOrientation": "HORIZONTAL", "TableContextTimeStampAfterTable": "{257808=The server has a process that will periodically scan every key in RAM and compile them into a log, named access.log as well as maintain a backup of this access log, named access.old. The server can use this backup file during warmup if the most recent access log has been corrupted during warmup or node failure. By default this process runs initially at 2:00 GMT and will run again in 24- hour time periods after that point. You can configure this process to run at a different initial time and at a different fixed interval., 291398=To prevent auto compaction taking place when your database is in heavy use, you can configure a time during which compaction is allowed. This is expressed as the hour and minute combination between which compaction occurs. For example, you could configure compaction to take place between 01:00 and 06:00., 79505=The expiration value is user-specified on a document basis at the point when the data is stored. The expiration can also be updated when the data is updated, or explicitly changed through the Couchbase protocol. The expiration time can either be specified as a relative time (for example, in 60 seconds), or absolute time (31st December 2012, 12:00pm)., 862889=May be returned within the view processor as:, 247744=This indicates we have three reader threads and two writer threads on bucket_name in the cluster at hostname:11210. The vBucket map for the data bucket is grouped into multiple shards, where one read worker will access one of the shards. In this example we have one reader for each of the three shards. This report also tell us we are optimized for read data access because we have more reader threads than writer threads for the bucket. You can also view the number of threads if you view the data bucket properties via a REST call:, 635487=Be aware that if you are trying to restore data to a different cluster, that you should make sure that cluster should have the same number of vBuckets as the cluster that you backed up. If you attempt to restore data from a cluster to a cluster with a different number of vBuckets, it will fail when you use the default port of 8091. The default number of vBuckets for Couchbase 2.0 is 1024; in earlier versions of Couchbase, you may have a different number of vBuckets. If you do want to restore data to a cluster with a different number of vBuckets, you should perform this command with port 11211, which will accommodate the difference in vBuckets:, 966632=Then precise date (and time) ranges can be selected by specifying the date and time in the generated data. For example, to get information between 1st April 2011, 00:00 and 30th September 2011, 23:59:, 810164=Interval between checkpoints, 60 to 14400 (seconds). Default 1800. At this time interval, batches of data via XDCR replication will be placed in the front of the disk persistence queue. This time interval determines the volume of data that will be replicated via XDCR should replication need to restart. The greater this value, the longer amount of time transpires for XDCR queues to grow. For example, if you set this to 10 minutes and a network error occurs, when XDCR restarts replication, 10 minutes of items will have accrued for replication., 648598=This shows we transferred 1053 batches of data at 550.8 batches per second. The tool outputs \u201ccannot save bucket design\u2026.\u201d to indicate that no design documents were exported. To import information from a.csv file to a named bucket in a cluster:, 264041=By default the scanner process will run once every 24 hours with a default initial start time of 2:00 AM UTC. This means after you install a new Couchbase Server 2.0 instance or restart the server, by default the scanner will run every 24- hour time period at 2:00 AM UTC by default. To change the time interval when the access scanner process runs to every 20 minutes:, 127693=For Windows 2008, you must upgrade your Windows Server 2008 R2 installation with Service Pack 1 installed before running Couchbase Server. You can obtain Service Pack 1 from Microsoft TechNet., 966952=The flexible structure and nature of the startkey and endkey values enable selection through a variety of range specifications. For example, you can obtain all of the data from the beginning of the year until the 5th March using:, 238821=The server-side (embedded) proxy exists within Couchbase Server using port 11211. It supports the memcached protocol and allows an existing application to communicate with Couchbase Cluster without installing another piece of proxy software. The downside to this approach is performance., 1081154=0 to 21199 \u2014 inclusive for dynamic cluster communication, 264931=In this example we set the initial time to 1:00 PM UTC., 61032=SASL authenticating Couchbase buckets may only be placed on port 11211 and each bucket is differentiated by its name and password. SASL bucket may not be placed on any other port beside 11211. These buckets can be reached with either a vBucket aware smart client or a binary client that has SASL support. These buckets cannot be reached with ASCII clients., 915638=Converts a JavaScript Date object or a valid date string such as \u201c2012-07-30T23:58:22.193Z\u201d into an array of individual date components. For example, the previous string would be converted into a JavaScript array:, 121920=Please note that you have to update your firewall configuration to allow connections to the following ports: 11211, 11210, 11209, 4369, 8091, 8092 and from 21100 to 21299., 1081334=Couchbase Server supports Red Hat (and CentOS) versions 5 starting with update 2, Ubuntu 9 and Windows Server 2008 (other versions have been shown to work but are not being specifically tested). There are both 32-bit and 64-bit versions available. Community support for Mac OS X is available. Future releases will provide support for additional platforms., 60667=Non-SASL buckets may be placed on any available port with the exception of port 11211 if the bucket is not named \u201cdefault\u201d. Only one Non-SASL bucket may placed on any individual port. These buckets may be reached with a vBucket aware smart client, an ASCII client or a binary client that doesn\u2019t use SASL authentication, 220476=All nodes in the cluster should be able to communicate with each other on 11210 and 8091., 1051812=In a Couchbase Server cluster, any communication (stats or data) to a port other than 11210 will result in the request going through a Moxi process. This means that any stats request will be aggregated across the cluster (and may produce some inconsistencies or confusion when looking at stats that are not \u201caggregatable\u201d)., 89635=However, Couchbase Server also allows information to be stored in the database with an expiry value. The expiry value states when a key/value pair should be automatically deleted from the entire database, and can either be specified as a relative time (for example, in 60 seconds), or absolute time (31st December 2012, 12:00pm)., 1052158=In general, it is best to run all your stat commands against port 11210 which will always give you the information for the specific node that you are sending the request to. It is a best practice to then aggregate the relevant data across nodes at a higher level (in your own script or monitoring system)., 601130=To change the initial time that the access scanner process runs from the default of 2:00 AM UTC:, 591149=For this command, host is the IP address for your Couchbase cluster, or node in the cluster. The port will always be the standard port used for cluster-wide stats and is at 11210. You also provide the named bucket and the password for the named bucket. After this you provide command options and authentication., 600576=By default the scanner process will run once every 24 hours with a default initial start time of 2:00 AM UTC. This means after you install a new Couchbase Server 2.0 instance or restart the server, by default the scanner will run every 24- hour time period at 2:00 AM GMT and then 2:00 PM GMT by default. To change the time interval when the access scanner process runs to every 20 minutes:, 807545=(Number) xdcrCheckpointInterval: Interval between checkpoints, 60 to 14400 (seconds). Default 1800., 264562=This updates the parameter for the named bucket, beer-sample on the given node on localhost. To change the initial time that the access scanner process runs from the default of 2:00 AM UTC:, 973512=If you specify a group_level of 2 then you must specify a key using at least the year and month information. For example, you can specify an explicit key, such as [2012,8] :, 1003127=The input includes a count for each of the error types for each month. Note that because the key output includes the year, month and date, the view also supports explicit querying while still supporting grouping and roll-up across the specified group. For example, to show information from 15th November 2010 to 30th April 2011 using the following query:, 812156=Document batching size, 10 to 100000 (KB). Default 2048. In general, increasing this value by 2 or 3 times will improve XDCR transmissions rates, since larger batches of data will be sent in the same timed interval. For unidirectional replication from a source to a destination cluster, adjusting this setting by 2 or 3 times will improve overall replication performance as long as persistence to disk is fast enough on the destination cluster. Note however that this can have a negative impact on the destination cluster if you are performing bi-directional replication between two clusters and the destination already handles a significant volume of reads/writes., 110290=Couchbase clusters with mixed platforms are not supported. Specifically, Couchbase Server on Mac OS X uses 64 vBuckets as opposed to the 1024 vBuckets used by other platforms. Due to this difference, if you need to move data between a Mac OS X cluster and a cluster hosted on another platform use cbbackup and cbrestore. For more information, see Backup and Restore Between Mac OS X and Other Platforms., 645209=This shows we successfully transferred 10000 total documents in batch size of 1088 documents each. This next examples shows how you can send all the data from a node to standard output:, 237774=We configured the memcached client to have just one server in its server list (localhost), so all operations are forwarded to localhost:11211 \u2014 a port serviced by the proxy. The proxy hashes the document ID to a vBucket, looks up the host server in the vBucket table, and then sends the operation to the appropriate Couchbase Server on port 11210., 259777=Here the localhost:11210 is the host name and default memcached port for a given node and beer_sample is a named bucket for the node. If you do not specify a bucket name, the command will apply to any existing default bucket for the node., 59970=The default bucket is a Couchbase bucket that always resides on port 11211 and is a non-SASL authenticating bucket. When Couchbase Server is first installed this bucket is automatically set up during installation. This bucket may be removed after installation and may also be re-added later, but when re-adding a bucket named \u201cdefault\u201d, the bucket must be place on port 11211 and must be a non-SASL authenticating bucket. A bucket not named default may not reside on port 11211 if it is a non-SASL bucket. The default bucket may be reached with a vBucket aware smart client, an ASCII client or a binary client that doesn\u2019t use SASL authentication., 601389=In this example we set the initial time to 11:00 PM UTC.}", "lastModified": "Sat, 30 May 2015 02:14:55 GMT", "textBeforeTable": "There are two types of data bucket in Couchbase Server: 1) memcached buckets, and 2) couchbase buckets. The two different types of buckets enable you to store data in-memory only, or to store data in-memory as well as on disk for added reliability. When you set up Couchbase Server you can choose what type of bucket you need in your implementation: Couchbase Server provides data management services using buckets ; these are isolated virtual containers for data. A bucket is a logical grouping of physical resources within a cluster of Couchbase Servers. They can be used by multiple client applications across a cluster. Buckets provide a secure mechanism for organizing, managing, and analyzing data storage resources. Data Storage\u00b6 Access to the Cluster Manager is provided through the administration interface (see Administration Tools ) on a dedicated network port, and through dedicated network ports for client access. Additional ports are configured for inter-node communication. Client proxy service to redirect requests Security for administrative and client access Multi-tenancy Run-time logging Statistics gathering and aggregation Node monitoring Node administration Cluster management Every node within a Couchbase Cluster includes the Cluster Manager component. The Cluster Manager is responsible for the following within a cluster: Cluster Manager\u00b6 Cluster A cluster is a collection of one ore more instances of Couchbase Server that are configured as a logical cluster. All nodes within the cluster are", "textAfterTable": "Unpacking couchbase-server (from couchbase-server_x86_64_2.1.0-xxx-rel.deb) \u2026 libssl0.9.8 is installed. Continue installing Minimum RAM required : 4 GB System RAM configured : 4058708 KB Minimum number of processors required : 4 cores Number of processors on the system : 4 cores Setting up couchbase-server (2.1.0) \u2026 * Started couchbase-server You have successfully installed Couchbase Server. Please browse to http://slv-0501:8091/ to configure your server. Please refer to http://couchbase.com for additional resources. Please note that you have to update your firewall configuration to allow connections to the following ports: 11211, 11210, 11209, 4369, 8091, 8092 and from 21100 to 21299. By using this software you agree to the End User License Agreement. See /opt/couchbase/LICENSE.txt. Processing triggers for ureadahead \u2026 ureadahead will be reprofiled on next reboot After successful installation, you can use the service command to manage the Couchbase Server service, including checking the current status. Refer to the Ubuntu documentation for instructions. To provide initial setup for Couchbase, open a web browser and access the web administration interface. See Initial Server Setup. Microsoft Windows Installation\u00b6 Before you install, make sure you check the supported platforms, see Supported Platforms. To install on Windows, download the Windows installer package. This is supplied as a Windows executable. You can install the package either using the wizard, or by doing an unattended installation process. In either case make sure that you have no anti-virus software running on", "hasKeyColumn": true, "keyColumnIndex": 1, "headerRowIndex": 0}