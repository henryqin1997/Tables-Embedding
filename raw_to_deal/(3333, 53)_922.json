{"relation": [["Test name", "hmm_simple", "hmm_discrete", "discrete_hmm_with_prior", "hmm_dirichlet", "hmm_factorial", "hmm_gauss_1d", "hmm_gauss", "hmm_multinomial", "hmm_poisson", "hmm_vonmises", "hmm_torus", "hmm_kent", "hmm_bippo", "infenginehmm", "infenginemm"], ["C++ (s)", "0.52", "48.12", "55.95", "340.72", "0.01", "53.97", "16.02", "134.64", "11.00", "7.22", "53.79", "61.35", "40.66", "0.01", "0.01"], ["Python (s)", "0.58", "43.45", "50.09", "353.98", "0.12", "63.39", "16.96", "125.83", "10.60", "7.36", "53.65", "61.06", "41.81", "0.12", "0.15"]], "pageTitle": "GSOC2011 Mocapy - Biopython", "title": "", "url": "http://biopython.org/w/index.php?title=GSOC2011_Mocapy&diff=3612&oldid=3487", "hasHeader": true, "headerPosition": "FIRST_ROW", "tableType": "RELATION", "tableNum": 2, "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042986357.49/warc/CC-MAIN-20150728002306-00198-ip-10-236-191-2.ec2.internal.warc.gz", "recordEndOffset": 26127983, "recordOffset": 26101325, "tableOrientation": "HORIZONTAL", "TableContextTimeStampAfterTable": "{97807=There is already an effort to provide bindings for Mocapy++ using Swig. However, Swig is not the best option if performance is to be required. The Sage project aims at providing an open source alternative to Mathematica or Maple. Cython was developed in conjunction with Sage (it is an independent project, though), thus it is based on Sage's requirements. They tried Swig, but declined it for performance issues. According to the Sage programming guide \"The idea was to write code in C++ for SAGE that needed to be fast, then wrap it in SWIG. This ground to a halt, because the result was not sufficiently fast. First, there is overhead when writing code in C++ in the first place. Second, SWIG generates several layers of code between Python and the code that does the actual work\". This was written back in 2004, but it seems things didn't evolve much. The only reason I would consider Swig is for future including Mocapy++ bindings on BioJava and BioRuby projects., 119894=Frellsen J, Moltke I, Thiim M, Mardia KV, Ferkinghoff-Borg J, et al. 2009 A Probabilistic Model of RNA Conformational Space. PLoS Comput Biol 5(6): e1000406. doi:10.1371/journal.pcbi.1000406., 123669=Wouter Boomsma, Kanti V. Mardia, Charles C. Taylor, Jesper Ferkinghoff-Borg, Anders Krogh, and Thomas Hamelryck. A generative, probabilistic model of local protein structure. Proc Natl Acad Sci U S A. 2008 July 1; 105(26): 8932\u20138937. http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2440424/}", "textBeforeTable": "Here are the average running time of the examples available with Mocapy (10 runs): The profiling tests were made using Callgrind and visualized using Kcachegrind. DBN with discrete nodes, Python implementation DBN with discrete nodes, C++ implementation There were no significant performance differences. For both implementations the methods responsible for consuming most cpu time were the same: A few performance measurements were made comparing test cases implemented both in C++ and in Python. The tests were run in a computer with the following specification: Core 2 Duo T7250 2.00GHz, Memory Dual Channel 4.0GB (2x2048) 667 MHz DDR2 SDRAM, Hard Drive 200GB 7200RPM. Performance For more details on the model API, see the test files: https://github.com/mchelem/biopython/blob/master/Tests/test_TorusDBNTrainer.py and https://github.com/mchelem/biopython/blob/master/Tests/test_TorusDBNModel.py. IC is either the Bayesian Information Criterion (BIC) or the Akaike Information Criterion (AIC) (Defaults to BIC. AIC can be specified by setting the use_aic flag). model =", "textAfterTable": "TorusDBN Even though the PDB files are read, parsed and transformed in a format mocapy can understand, the most time consuming methods are the ones performing mathematical operations during the sampling process (Chebyshev and exp, for example). Training of the TorusDBN model The model has been trained with a training set consisting of about 950 chains with maximum 20% homology, resolution below 1.6 \u00c5 and R-factor below 25%. It took about 67 minutes to read and train the whole dataset. The resulting DBN is available at https://github.com/mchelem/biopython/blob/master/Tests/TorusDBN/pisces_dataset.dbn and can be loaded directly into the model as explained in the TorusDBN section above. Future work The summer is over, but the work continues... There are still a lot of things I intend to work on: Test the trained models to check their effectiveness in protein structure prediction. Try to reduce dynamic allocation as it is responsible for a lot of running time. Guarantee there are no memory leaks in the bindings.", "hasKeyColumn": true, "keyColumnIndex": 0, "headerRowIndex": 0}