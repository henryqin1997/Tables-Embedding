{
    "relation": [
        [
            "Citing Patent",
            "US6940999 *",
            "US7379925 *",
            "US7603323",
            "US7630981 *",
            "US7672484 *",
            "US7676065",
            "US7693299",
            "US7738707",
            "US7796837 *",
            "US7894675",
            "US7983446",
            "US8055103 *",
            "US8064727 *",
            "US8081799",
            "US8111289 *",
            "US8135174",
            "US8139863 *",
            "US8161066",
            "US8190684",
            "US8200617",
            "US8275796 *",
            "US8295543 *",
            "US8369622",
            "US8438124",
            "US8862579",
            "US8868560",
            "US8924838",
            "US8965979",
            "US9020967",
            "US9037567",
            "US20020012451 *",
            "US20050013486 *",
            "US20110051999 *",
            "US20120078930 *"
        ],
        [
            "Filing date",
            "Jun 13, 2001",
            "Aug 8, 2005",
            "Oct 8, 2007",
            "Dec 26, 2006",
            "Mar 10, 2008",
            "Oct 31, 2007",
            "Jan 13, 2005",
            "Mar 10, 2008",
            "Sep 22, 2005",
            "Mar 10, 2008",
            "Jul 18, 2003",
            "Jun 7, 2007",
            "Aug 20, 2010",
            "Sep 24, 2010",
            "Jul 15, 2003",
            "Sep 24, 2010",
            "Apr 25, 2008",
            "Jan 23, 2009",
            "Apr 16, 2008",
            "Jun 22, 2009",
            "Aug 22, 2008",
            "Mar 28, 2008",
            "Oct 29, 2009",
            "Oct 18, 2007",
            "Apr 14, 2010",
            "Oct 18, 2007",
            "Aug 7, 2007",
            "Apr 24, 2012",
            "Nov 10, 2009",
            "Apr 14, 2010",
            "Jun 13, 2001",
            "Jul 18, 2003",
            "",
            "Sep 29, 2010"
        ],
        [
            "Publication date",
            "Sep 6, 2005",
            "May 27, 2008",
            "Oct 13, 2009",
            "Dec 8, 2009",
            "Mar 2, 2010",
            "Mar 9, 2010",
            "Apr 6, 2010",
            "Jun 15, 2010",
            "Sep 14, 2010",
            "Feb 22, 2011",
            "Jul 19, 2011",
            "Nov 8, 2011",
            "Nov 22, 2011",
            "Dec 20, 2011",
            "Feb 7, 2012",
            "Mar 13, 2012",
            "Mar 20, 2012",
            "Apr 17, 2012",
            "May 29, 2012",
            "Jun 12, 2012",
            "Sep 25, 2012",
            "Oct 23, 2012",
            "Feb 5, 2013",
            "May 7, 2013",
            "Oct 14, 2014",
            "Oct 21, 2014",
            "Dec 30, 2014",
            "Feb 24, 2015",
            "Apr 28, 2015",
            "May 19, 2015",
            "Jan 31, 2002",
            "Jan 20, 2005",
            "Mar 3, 2011",
            "Mar 29, 2012"
        ],
        [
            "Applicant",
            "American Gnc Corp.",
            "New York University",
            "New York University",
            "Robert Bosch Gmbh",
            "Lockheed Martin Corporation",
            "Lockheed Martin Corporation",
            "New York University",
            "Lockheed Martin Corporation",
            "Google Inc.",
            "Lockheed Martin Corporation",
            "Lockheed Martin Corporation",
            "National Chiao Tung University",
            "Google Inc.",
            "Lockheed Martin Corporation",
            "Magna B.S.P. Ltd.",
            "Lockheed Martin Corporation",
            "Hsu Shin-Yi",
            "Evri, Inc.",
            "Evri Inc.",
            "Evri, Inc.",
            "Evri Inc.",
            "Lockheed Martin Corporation",
            "Hsu Shin-Yi",
            "Evri Inc.",
            "Vcvc Iii Llc",
            "Vcvc Iii Llc",
            "Vcvc Iii Llc.",
            "Vcvc Iii Llc.",
            "Vcvc Iii Llc",
            "Vcvc Iii Llc",
            "Ching-Fang Lin",
            "Lockheed Martin Corporation",
            "Lockheed Martin Corporation",
            "International Business Machines Corporation"
        ],
        [
            "Title",
            "Method for target detection and identification by using proximity pixel information",
            "Logic arrangement, data structure, system and method for multilinear representation of multimodal data ensembles for synthesis, rotation and compression",
            "Logic arrangement, data structure, system and method for multilinear representation of multimodal data ensembles for synthesis recognition and compression",
            "Method and system for learning ontological relations from documents",
            "Method and apparatus for automatic identification of linear objects in an image",
            "Method and apparatus for automatic identification of objects in an image",
            "Method, system, storage medium, and data structure for image recognition using multilinear independent component analysis",
            "Method and apparatus for automatic identification of bodies of water",
            "Processing an image map for display on computing device",
            "Method and apparatus for automatic linear object identification using identified terrain types in images",
            "Method and apparatus for automatic object identification",
            "Object-based image search system and method",
            "Adaptive image maps",
            "Method and apparatus for automatic object identification using identified perpendicular lines, gradient magnitudes and distances",
            "Method and apparatus for implementing multipurpose monitoring system",
            "Automatic image object identification using threshold gradient magnitude based on terrain type",
            "System for capturing, characterizing and visualizing lidar and generic image data",
            "Methods and systems for creating a semantic object",
            "Methods and systems for semantically managing offers and requests over a network",
            "Automatic mapping of a location identifier pattern of an object to a semantic type using object metadata",
            "Semantic web portal and platform",
            "Device and method for detecting targets in images based on user-defined classifiers",
            "Multi-figure system for object feature extraction tracking and recognition",
            "System and method of a knowledge management and networking environment",
            "Search and search optimization using a pattern of a location identifier",
            "System and method of a knowledge management and networking environment",
            "Harvesting data from page",
            "Methods and systems for semantically managing offers and requests over a network",
            "Semantically representing a target entity using a semantic object",
            "Generating user-customized search results and building a semantics-enhanced search engine",
            "Method for target detection and identification by using proximity pixel information",
            "Method and apparatus for automatic object identification",
            "Device and method for detecting targets in images based on user-defined classifiers",
            "Framework for extremely large complex objects (xlcos)"
        ]
    ],
    "pageTitle": "Patent US6741744 - Compiliable language for extracting objects from an image using a primitive ... - Google Patents",
    "title": "",
    "url": "http://www.google.com/patents/US6741744?dq=5,973,252",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 25,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042990609.0/warc/CC-MAIN-20150728002310-00315-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 485018835,
    "recordOffset": 484975286,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampAfterTable": "{100634=A two-meter resolution image for processing, using conventional means, dictates an appropriate sized image of 1024\ufffd1024 pixels. In this case, the area coverage is a distance of 2,048 meters on one side of the square region, equivalent to 0.018618 degrees on the earth coordinate system, or 3.7 percent of a one-half degree. This comparison is shown in Table IX., 71241=International Publication No. WO 93/22762, by William Gibbens REDMANN et al., discloses a system for tracking movement within a field of view, so that a layman can conduct the performance of a prerecorded music score by means of image processing. By analyzing change in centers of movement between the pixels of the current image and those of previous images, tempo and volume are derived., 166134=Two object-extraction examples that use these photo-interpreters' vocabularies are given in FIGS. 2 and 5. The vehicle used for performing this object-recognition process by using a human-like language centered on concepts that are utilized by photo-interpreters is the IMaG System described in an allowed patent, bearing Ser. No. 08/066,691 and filed on May 21, 1993., 58123=Schutzer (1985) in his article entitled, \u201cThe Tools and Techniques of Applied Artificial Intelligence\u201d in Andriole (1985 ed.), listed LISP and PROLOG as applicable, artificial-intelligence (AI) languages. The inventive language differs from these., 27755=In the past 30 years or more, image processing and pattern recognition have been centered on extracting objects using simple and complex algorithms within an image of appropriate dimensions, such as 128\ufffd128, 256\ufffd256, 512\ufffd152 and 1024\ufffd1024 pixels. It is extremely rare for a complex algorithm to extract an object from a scene larger than 2048\ufffd2048 pixels, in view of the fact that historically even a workstation has a limited memory capacity to handle large images., 70848=While Dobson (1993, p. 1495) predicted that \u201ctechnical integration will remain an illusive target not likely to be achieved for decades, \u201d the present invention proposes that, by using pseudo-English as a programming language, one can shorten this predicted timetable from decades to years, and make \u201ctechnological integration\u201d an integral part of \u201cconceptual integration\u201d., 104896=In terms of a two dimension space, a region covered by 1024\ufffd1024 pixels with a spatial resolution of two meters is equivalent to only 0.03466 percent of one degree on the earth surface. In other words, approximately 2,885 images are needed to cover a one-degree region, each image having 1024\ufffd1024 pixels., 76229=The invention provides a mechanism for generating feature primitives from various imagery types for object extraction generalizable to a climatic zone instead of a small image frame such as 512\ufffd512 or 1024\ufffd1024 pixels. The mechanism simultaneously destroys and creates information to generate a single band image containing spatial feature primitives for object recognition from single band, multispectral and multi-sensor imagery. Cartographers and image analysts are thus provided with a single-band imagery for extracting objects and features manually and/or automatically by using expert rule sets., 106482=A set of images, panchromatic and near infrared, was obtained, covering the New River Inlet Quad of North Carolina. Each of the three air photos was digitized at the resolution level of 600 dots per inch, resulting in a spatial resolution of approximately 1.7 meters per pixel on a linear scale. With 60 percent overlap and 30 percent side lap between adjacent air photos, the 7.5 minute topoquad was covered by about 50 images, each being 1024 by 1024 pixels. In this format, about 200 pixels of overlap exist between adjacent cells., 24082=This application is a CIP of Ser. No. 08/759,280 filed on Dec. 2, 1996 and now abandoned., 105221=Suppose that a conventional image processing and pattern recognition approach to extract objects from 2885 images requires two minutes of processing time for each image. Approximately 63 hours will be needed to complete a task which may be devoted to extracting only one target object. The second task will require the same amount of hours. A more troubling aspect of the problem, using a conventional approach to perform this task, lies in the fact that a given object extraction algorithm may not be applicable to even the nearest neighbor of the region where the algorithm originates. Therefore, the above-noted 63 hours per task is based on the assumption that a given object extraction algorithm is generalizable within a one degree region, which is usually not the case., 48462=Consider an approximate length for one degree on the earth coordinate system: 110 kilometers. One half of a degree is approximately 55 km. If a panchromatic image has a linear spatial resolution of 5 meters per pixel, a square region of one half of a degree is equivalent to 11,000\ufffd11,000 pixels. A one-degree region on the earth is covered by a scene of 22,000\ufffd22,000 pixels at the linear resolution of 5 meters per pixel. It is not unusual for a cartographer to extract features from a one-degree scene. In digital image processing, on the other hand, a unit of analysis is usually set at the level of 512 by 512 pixels or 1024 by 1024 pixels. In other words, it is rare that a sophisticated feature extraction algorithm is applied to scene of 2024 by 2024 pixels.}",
    "textBeforeTable": "Patent Citations Thus, it can be seen that the methodology of the invention can be adapted to process other physical phenomenon, in addition to images, such as sounds, textures, fragrances, and flavors. Merely by providing appropriate physical phenomenon models and descriptors to the system, the inventive method can be used to analyze and extract portions of such physical phenomena. Since other modifications and changes varied to fit particular operating requirements and environments will be apparent to those skilled in the art, the invention is not considered limited to the example chosen for purposes of disclosure. The image primitives 270 are applied to the analyst's human-readable language 280 in accordance with the invention. Once the language 280 processes these primitives, features and objects 290 can be extracted from the image originally provided in single band 210, multiple band 220 and multiple sensor 230 form. The extracted features and objects 290 can also be fed back into the analyst's language 280 to generate new objects. This architecture for converting raw images to image primitives and subsequent extraction or recognition by using a new language and data analysis paradigm is illustrated in FIG. 11. Large area scenes 200, which could have been created as a single band 210, multiple bands 220, or by the use of multiple sensors 230 are applied to respective rules in a rule base 240, 250, 260. The output from these rules 240, 250, 260 is input",
    "textAfterTable": "US8275796 * Aug 22, 2008 Sep 25, 2012 Evri Inc. Semantic web portal and platform US8295543 * Mar 28, 2008 Oct 23, 2012 Lockheed Martin Corporation Device and method for detecting targets in images based on user-defined classifiers US8369622 Oct 29, 2009 Feb 5, 2013 Hsu Shin-Yi Multi-figure system for object feature extraction tracking and recognition US8438124 Oct 18, 2007 May 7, 2013 Evri Inc. System and method of a knowledge management and networking environment US8862579 Apr 14, 2010 Oct 14, 2014 Vcvc Iii Llc Search and search optimization using a pattern of a location identifier US8868560 Oct 18, 2007 Oct 21, 2014 Vcvc Iii Llc System and method of a knowledge management and networking environment US8924838 Aug 7, 2007 Dec 30, 2014 Vcvc Iii Llc. Harvesting data from page US8965979 Apr 24, 2012 Feb 24, 2015 Vcvc Iii Llc.",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}