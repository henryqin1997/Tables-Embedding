{
    "relation": [
        [
            "Count",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1"
        ],
        [
            "Component",
            "",
            "",
            "",
            "",
            "",
            ""
        ],
        [
            "DateTime",
            "2004-08-17T00:00:00",
            "2004-09-15T00:00:00",
            "2004-09-30T00:00:00",
            "2005-04-15T00:00:00",
            "2008-01-25T00:00:00",
            "2009-07-20T00:00:00"
        ],
        [
            "Description",
            "EarthData has developed a unique method for processing lidar data to identify and remove elevation points falling on vegetation, buildings, and other aboveground structures. The algorithms for filtering data were utilized within EarthData's proprietary software and commercial software written by TerraSolid. This software suite of tools provides efficient processing for small to large-scale, projects and has been incorporated into ISO 9001 compliant production work flows. The following is a step-by-step breakdown of the process. 1. Using the lidar data set provided by EarthData, the technician performs calibrations on the data set. 2. Using the lidar data set provided by EarthData, the technician performed a visual inspection of the data to verify that the flight lines overlap correctly. The technician also verified that there were no voids, and that the data covered the project limits. The technician then selected a series of areas from the data set and inspected them where adjacent flight lines overlapped. These overlapping areas were merged and a process which utilizes 3-D Analyst and EarthData's proprietary software was run to detect and color code the differences in elevation values and profiles. The technician reviewed these plots and located the areas that contained systematic errors or distortions that were introduced by the lidar sensor. 3. Systematic distortions highlighted in step 2 were removed and the data was re-inspected. Corrections and adjustments can involve the application of angular deflection or compensation for curvature of the ground surface that can be introduced by crossing from one type of land cover to another. 4. The lidar data for each flight line was trimmed in batch for the removal of the overlap areas between flight lines. The data was checked against a control network to ensure that vertical requirements were maintained. Conversion to the client-specified datum and projections were then completed. The lidar flight line data sets were then segmented into adjoining tiles for batch processing and data management. 5. The initial batch-processing run removed 95% of points falling on vegetation. The algorithm also removed the points that fell on the edge of hard features such as structures, elevated roadways and bridges. 6. The operator interactively processed the data using lidar editing tools. During this final phase the operator generated a TIN based on a desired thematic layer to evaluate the automated classification performed in step 5. This allowed the operator to quickly re-classify points from one layer to another and recreate the TIN surface to see the effects of edits. Geo-referenced images were toggled on or off to aid the operator in identifying problem areas. The data was also examined with an automated profiling tool to aid the operator in the reclassification. 7. The data were separated into a bare-earth DEM. A grid-fill program was used to fill data voids caused by reflective objects such as buildings and vegetation. The final DEM was written to an ASCII XYZ and LAS format. 8. The reflective surface data were also delivered in ASCII XYZ and LAS format. 9. Final TIN files are created and delivered.",
            "The digital orthophotography was produced in natural color at a natural ratio of 1 to 2,400 with a 1 ft pixel resolution. A step-by-step breakdown of the digital orthophoto production process follows. 1. Digital image swath files were visually checked for image quality on the networked ISTAR processing farm. 2. The digital image files were loaded onto the digital orthophoto production workstation. The following information was then loaded onto the workstation. - The camera parameters and flight line direction - Ground control and pass point locations - The exterior orientation parameters from the aerotriangulation process - ASCII file containing the corner coordinates of the orthophotos - The digital elevation model. - Project-specific requirements such as final tile size and resolution. -Orientation parameters developed from the aerotriangulation solution. A coordinate transformation based on the camera calibration fiducial coordinates was then undertaken. This transformation allowed the conversion of every measured element of the images to a sample/line location. Each pixel in an image was then referenced by sample and line (its horizontal and vertical position) and matched to project control. 3. The newly re-sected image was visually checked for pixel drop-out and/or other artifacts that may degrade the final orthophoto image. 4. DTM data were imported and written to the correct subdirectory on disk. 5. The DTM file was re-inspected for missing or erroneous data points. 6. A complete differential rectification was carried out using a cubic convolution algorithm that removed image displacement due to topographic relief, tip and tilt of the aircraft at the moment of exposure, and radial distortion within the camera. Each final orthophoto was produced at a natural scale of 1 to 2,400 with a 1ft pixel resolution. At this point in the process, the digital orthophotos covered the full aerial frame. 7. Each digital orthophoto image was visually checked for accuracy on the workstation screen. Selected control points (control panels or photo-identifiable points) that are visible on the original film were visited on the screen, and the X and Y coordinates of the location of the panel or photo-identifiable point were measured. This information was cross-referenced with the X and Y information provided by the original ground survey. If the orthophoto did not meet or exceed NMAS standards, the rectification was regenerated. The digital orthophotos were then edge-matched using proprietary software that runs in Z/I Imaging OrthoPro software package. Adjoining images were displayed in alternating colors of red and cyan. In areas of exact overlap, the image appears in gray-scale rendition. Offsets were colored red or cyan, depending on the angle of displacement. The operator panned down each overlap line at a map scale to inspect the overlap area. Any offset exceeding accuracy standards was re-rectified after the DTM and AT information was rechecked. 8. Once the orthos were inspected and approved for accuracy, the files were copied to the network and downloaded by the ortho finishing department. This production unit was charged with radiometrically correcting the orthophotos prior to completing the mosaicking and clipping of the final tiles. The image processing technician performed a histogram analysis of several images that contained different land forms (urban, agricultural, forested, etc.) and established a histogram that best preserves detail in highlight and shadow areas. EarthData International has developed a proprietary piece of software called \"Image Dodging.\" This radiometric correction algorithm was utilized in batch and interactive modes. Used in this fashion, this routine eliminated density changes due to sun angle and changes in flight direction. A block of images were processed through image dodging, in batch mode and displayed using Z/I Imaging OrthoPro software. At this point the images have been balanced internally, but there are global differences in color and brightness that were adjusted interactively. The technician assigned correction values for each orthophoto then displayed the corrected files to assess the effectiveness of the adjustment. This process was repeated until the match was considered near seamless. The files then were returned to digital orthophoto production to mosaic the images. 9. The processed images were mosaicked using the Z/I Imaging software. The mosaic lines were set up interactively by the technician and were placed in areas that avoided buildings, bridges, elevated roadways, or other features that would highlight the mosaic lines. File names were assigned. 10.The finishing department performed final visual checks for orthophoto image quality. The images were inspected using Adobe Photoshop, which enabled the technician to remove dust and lint from the image files interactively. Depending on the size and location of the flaw, Photoshop provided several tools to remove the flaw. Interactive removal of dust was accomplished at high magnification so that repairs are invisible. 11.The final orthophoto images were written out into GeoTIFF format.",
            "New ground control was established to control and orient the photography, and included only photo-identifiable features. The ground control network and airborne GPS data was integrated into a rigid network through the completion of a fully analytical bundle aerotriangulation adjustment. 1. The digital aerial photo data was ingested into the ISTAR processing system by uploading the data from portable hard drives. 2. The coverage of the imagery was checked for gaps and a directory tree structure for the project was established on one of the workstations. This project was then accessed by other workstations through the network. The criteria used for establishment of the directory structure and file naming conventions accessed through the network avoids confusion or errors due to inconsistencies in digital data. The project area was reviewed against the client-approved boundary. The technician verified that the datum and units of measurement for the supplied control were consistent with the project requirements. 3. The photogrammetric technician performed an automatic triangulation of the data using the ISTAR processing system. The aerotriangulation adjustment merged the airborne GPS, IMU, and ground control data into a project-wide network. 4. While ground control points (GCPs) were used, reliance on the GPS-/IMU-derived orientation parameters required significantly fewer GCPs than are typically used in aerotriangulation. 5. The adjustment was performed for each sortie and then multiple sorties were merged to produce a project-wide adjustment. 6. The aerotriangulation component of the ISTAR suite utilized the airborne GPS as a separate control source and held the IMU (Inertial Measurement Unit) parameters rigidly. 7. The accuracy of the final solution was verified by running the final adjustment, placing no constraints on any quality control points. The RMSE values for these points must fall within the tolerances above for the solution to be acceptable.",
            "This process describes the method used to compile hydro-breaklines to support H&H modeling efforts. The technical method used to produce hydro-breaklines for use in this project only included water features and they should not be confused with traditional stereo-graphic or field survey derived breaklines. Watershed Concepts and EarthData utilized techniques developed for FEMA floodmap modernization projects to synthesize 3D break lines using digital orthophotos and lidar data. 1. For larger streams (widths greater than 50 feet), breaklines were collected on the left and right water edge lines. The 2D lines defining streams and other water bodies were manually digitized into ArcView shape file format from the ADS-40 digital imagery. Flat water bodies such as ponds were collected by examining points near the edge of water, were a low point could be quickly identified. This allowed the operators to draw an even-elevation breakline at that elevation around the water body's perimeter. 2. A bounding polygon, created from the edge of bank lines, was used to remove all lidar points from within the channels of streams and bodies of water. This step ensures that the lidar bare-earth point files match the breaklines. 3. The elevation component of the 3D streamlines (breaklines) was derived from the lowest adjacent bare earth lidar point and was adjusted to ensure that the streams flow downstream. The best elevation that can be derived for the 3D streamlines will be the water surface elevation on the date that the lidar data was acquired. 4. Automatic processes assigned elevations to the vertices of the centerline based on surrounding lidar points. The lines were then smoothed to ensure a continuous downhill flow. Edge-of-bank vertices were adjusted vertically to match the stream centerline vertices. 5. The new 3D lines were then viewed in profile to correct any anomalous vertices or remove errant points from the lidar DTM, which cause unrealistic \"spikes\" or \"dips\" in the breaklines. 6. For this project, hydro breaklines were generated in the matter described above for all streams and water bodies. a) A 2000 to identify any quality issues. b) An automated routine was run to check the data for closure of water bodies. c) An evaporation routine was run to remove lidar points from water bodies. d) A final routine was run to check the generate TINs for anomalies including outside township/range boundary and elevation extremes. 7. New TINs were then created from the remaining lidar points and newly created breaklines. 8. The breakline data set was then put into an ESRI shape file format 9. The 1 foot contours were generated in Microstation (using 2 foot specifications) with an overlay software package called TerraSolid. Within TerraSolid, the module Terramodeler was utilized to first create the tin and then a color relief was created to view for any irregularities before the contour generator was run. The contours were checked for accuracy over the DTM and then the Index contours were annotated. At this point the technician identified any areas of heavy tree coverage by collecting obscure shapes. Any contours that were found within these shapes are coded as obscure. The data set was viewed over the orthos before the final conversion. The contours were then converted to Arc/Info where final QC AMLs were run to verify that no contours were crossing. The contours were delivered in ESRI .shp format as a merged file. <>",
            "The NOAA Coastal Services Center (CSC) received the files in LAS format. The files contained Lidar elevation measurements. The data was in Florida State Plane Projection and NAVD88 vertical datum. CSC performed the following processing to the data to make it available within the LDART Retrieval Tool (LDART): 1. The data were converted from Florida State Plane West coordinates to geographic coordinates. 2. The data were converted from NAVD88 (orthometric) heights to GRS80 (ellipsoid) heights using Geoid03. 3. The LAS data were sorted by latitude and the headers were updated.",
            "The NOAA National Geophysical Data Center (NGDC) received lidar data files via ftp transfer from the NOAA Coastal Services Center. The data are currently being served via NOAA CSC Digital Coast at http://www.csc.noaa.gov/digitalcoast/. The data can be used to re-populate the system. The data are archived in LAS or LAZ format. The LAS format is an industry standard for LiDAR data developed by the American Society of Photogrammetry and Remote Sensing (ASPRS); LAZ is a loseless compressed version of LAS developed by Martin Isenburg (http://www.laszip.org/). The data are exclusively in geographic coordinates (either NAD83 or ITRF94). The data are referenced vertically to the ellipsoid (either GRS80 or ITRF94), allowing for the ability to apply the most up to date geoid model when transforming to orthometric heights."
        ]
    ],
    "pageTitle": "Docucomp ISO19115Components-HTMLTable",
    "title": "",
    "url": "http://www.ngdc.noaa.gov/docucomp/page?xml=NOAA/NESDIS/NGDC/MGG/Lidar/iso/xml/2004_FL_SWFWMD_Pasco_m62.xml&view=ISO19115Components-HTMLTable&altview=none",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 25,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042990609.0/warc/CC-MAIN-20150728002310-00155-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 610543079,
    "recordOffset": 610529059,
    "tableOrientation": "HORIZONTAL",
    "textBeforeTable": "MD_DataIdentification Aggregation Info | Bands | Citations | Constraints | Coverage Descriptions | Dimensions | Extents | Formats | Geographic Bounding Box Georectified Information | Georeferenceable Information | Identifiers | Instruments | Mediums | OnlineResources | Operations Platforms | Process Steps | Range Elements | Reference Systems | Responsible Parties | Series | Sources | Spatial Grids | Temporal Extents Metadata Identifier: gov.noaa.csc.maps:2004_FL_SWFWMD_Pasco_m62Get DataFAQHTML, 19139 XML Assess Metadata For: Completeness, DOI Readiness, CSW Readiness, Components ISO Table ViewBack to Collection NOAA/NESDIS/NGDC/MGG/Lidar View Metadata As: , , } background-color:#F0F0F0; th{ } empty-cells:show; table{",
    "textAfterTable": "Digital Aerial Photography of Pasco County, FL 2004-02-08 1 Geographic Names Information System 1 Lidar Acquisition of Pasco County, FL 2004-05-15 1 Lidar Final Report 1 None 1 North American Datum 1983 2007-01-19 1 Report of Survey - SWFWMD, Pasco County, FL 2004-04-21 Top CI_Series none found Top CI_ResponsibleParty Count Component Individual Organization Position Email Role Linkage 1 resourceProvider http://www.epsg-registry.org/export.htm?gml=urn:ogc:def:crs:EPSG::4269 1",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}