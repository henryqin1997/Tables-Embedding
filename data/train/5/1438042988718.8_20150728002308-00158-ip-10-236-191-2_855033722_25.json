{
    "relation": [
        [
            "Test Case",
            "bmd-4",
            "bmd-7"
        ],
        [
            "SMP",
            "8",
            "16"
        ],
        [
            "4x15K RPM 72 GB SAS HDD striped HW RAID0",
            "523",
            "357"
        ],
        [
            "Sun F5100 r/w buff 4096 striped",
            "314",
            "303"
        ],
        [
            "Sun F5100 Performance Advantage",
            "67%",
            "18%"
        ]
    ],
    "pageTitle": "BestPerf",
    "title": "",
    "url": "https://blogs.oracle.com/BestPerf/tags/suse",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 25,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042988718.8/warc/CC-MAIN-20150728002308-00158-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 855079535,
    "recordOffset": 855033722,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampBeforeTable": "{84716=The following are trademarks or registered trademarks of Abaqus, Inc. or its subsidiaries in the United States and/or o ther countries: Abaqus, Abaqus/Standard, Abaqus/Explicit. All information on the ABAQUS website is Copyrighted 2004-2009 by Dassault Systemes. Results from http://www.simulia.com/support/v69/v69_performance.php as of October 12, 2009., 72864=The MSC/Nastran MD 2008 R3 module is an MCAE application based on the finite element method (FEA) of analysis. This computer based numerical method inherently involves a substantial I/O component. The purpose was to evaluate the performance of the Sun Storage F5100 Flash Array relative to high performance 15K RPM internal stripped HDDs., 142579=The Sun Blade X6275 cluster with 768 cores (one full Sun Blade 6048 chassis) was 47% faster than 1024 cores of the IBM POWER6 cluster (multiple racks)., 15717=Additional information on the MSC/Nastran Vendor 2008 benchmark test suite., 124791=WRF, see http://www.mmm.ucar.edu/wrf/WG2/bench/, results as of 3/8/2010., 195232=The following are trademarks or registered trademarks of Halliburton/Landmark Graphics: ProMAX. Results as of 9/20/2010., 183670=Multiple Job, Multiple Application Throughput Results Comparing Scheduling Strategies 2009.2 ECLIPSE 300 MM8 2 Million Cell and 3D Kirchoff Time Migration (PSTM), 190965=Results are presented below on a variety of experiments run using the 2009.2 ECLIPSE 300 2 Million Cell Performance Benchmark (MM8). The compute nodes are a cluster of Sun Fire X2270 servers connected with QDR InfiniBand. First, some definitions used in the tables below:, 193204=Oracle's Sun Storage 7410 system, attached via QDR InfiniBand to a cluster of eight of Oracle's Sun Fire X2270 servers, was used to evaluate multiple job throughput of Schlumberger's Linux-64 ECLIPSE 300 compositional reservoir simulator processing their standard 2 Million Cell benchmark model with 8 rank parallelism (MM8 job)., 174304=Copyright 2010, Oracle and/or its affiliates. All rights reserved. Oracle and Java are registered trademarks of Oracle and/or its affiliates. Other names may be trademarks of their respective owners. Results as of 9/20/2010., 218658=The 16-thread ProMAX job throughput using the distributed scheduling method is up to 8% faster when compared to the compact scheme on an 8-node Sun Fire X2270 cluster., 219827=Halliburton/Landmark's ProMAX 3D Prestack Kirchhoff Time Migration's single job scalability and multiple job throughput using various scheduling methods are evaluated on a cluster of Oracle's Sun Fire X2270 servers attached via QDR InfiniBand to Oracle's Sun Storage 7410 system., 67916=The MD (Multi Discipline) Nastran 2008 application performs both structural (stress) analysis and thermal analysis. These analyses may be either static or transient dynamic and can be linear or nonlinear as far as material behavior and/or deformations are concerned. The new release includes the MARC module for general purpose nonlinear analyses and the Dytran module that employs an explicit solver to analyze crash and high velocity impact conditions., 172148=Oracle's Sun Fire X2270 M2 server produced leading single node performance results running the ANSYS FLUENT benchmark cases as compared to the best single node results currently posted at the ANSYS FLUENT website. ANSYS FLUENT is a prominent MCAE application used for computational fluid dynamics (CFD)., 218453=The multiple job throughput characterization revealed in this benchmark study are key in pre-configuring Oracle Grid Engine resource scheduling for ProMAX on a Sun Fire X2270 cluster and provide valuable insight for server consolidation., 13979=MSC.Software is a registered trademark of MSC. All information on the MSC.Software website is copyrighted. MSC/Nastran Vendor 2008 results from http://www.mscsoftware.com and this report as of June 9, 2009., 219350=A single ProMAX job has near linear scaling of 5.5x on 6 nodes of a Sun Fire X2270 cluster., 185489=Comparing Compact and Distributed Scheduling on 4 Nodes Multiple Job Throughput Results Relative to Single Job 2009.2 ECLIPSE 300 MM8 2 Million Cell Performance Benchmark, 219229=A single ProMAX job has near linear scaling of 7.5x on a Sun Fire X2270 server when running from 1 to 8 threads., 187521=Comparing Compact and Distributed Scheduling Multiple Job Throughput Results Relative to Single Job 2009.2 ECLIPSE 300 MM8 2 Million Cell Performance Benchmark, 160787=Oracle's Sun Fire X2270 M2 server results showed outstanding performance running the MCAE application MSC.Nastran as shown by the MD Nastran MDR3 serial and parallel test cases., 189778=Compact Scheduling Multiple Job Throughput Results Relative to Single Job 2009.2 ECLIPSE 300 MM8 2 Million Cell Performance Benchmark, 142254=The Sun Blade X6275 cluster with 768 cores (on full Sun Blade 6048 chassis) outperforms the IBM Power6 cluster with 1024 cores by 28% on the 2.5 km CONUS dataset., 29552=The I/O intensive MSC/Nastran Vendor_2008 benchmark test suite was used to compare the performance on a Sun Fire X2270 server when using SSDs internally instead of HDDs., 15089=The MSC/Nastran Vendor 2008 test cases don't scale very well, a few not at all and the rest on up to 8 cores at best., 153158=MSC.Software is a registered trademark of MSC. All information on the MSC.Software website is copyrighted. MD Nastran MDR3 results from http://www.mscsoftware.com and this report as of June 28, 2010., 13649=Tags: flash hpc intel linux mcae nastran performance ssd suse x2270 x64, 171069=Results are presented for six of the seven ANSYS FLUENT benchmark tests. The seventh test is not a practical test for a single system. Results are ratings, where bigger is better. A rating is the number of jobs that could be run in a single day (86,400 / run time). Competitive results are from the ANSYS FLUENT benchmark website as of 25 June 2010., 44064=Node to Node MPI ping-pong tests show a bandwidth of 3000 MB/sec on the Sun Blade X6275 cluster using QDR. The same tests performed on a Sun Fire X2270 cluster and equipped with DDR interconnect produced a bandwidth of 1500 MB/sec. On another recent Intel based Sun Fire X2250 cluster (3.4 GHz DC E5272 processors) also equipped with DDR interconnects, the bandwidth was 1250 MB/sec. This same Sun Fire X2250 cluster equipped with SDR IB interconnect produced an MPI ping-pong bandwidth of 975 MB/sec., 65398=MSC.Software is a registered trademark of MSC. All information on the MSC.Software website is copyrighted. MD Nastran MDR3 results from http://www.mscsoftware.com and this report as of October 12, 2009., 144680=The following are trademarks or registered trademarks of Dassault Systemes, or its subsidiaries in the United States and/or other countries: Simulia, ABAQUS, ABAQUS/Standard, ABAQUS/Explicit. All information on the ABAQUS website is Copyrighted 2004-2010 by Dassault Systemes. Results from http://www.simulia.com/support/v69/v69_performance.php as of June 28, 2010., 177405=ECLIPSE is very sensitive to memory bandwidth and needs to be run on 1333 MHz or greater memory speeds. In order to maintain 1333 MHz memory, the maximum memory configuration for the processors used in this benchmark is 24 GB. Bios upgrades now allow 1333 MHz memory for up to 48 GB of memory. Additional nodes can be used to handle data sets that require more memory than available per node. Allocating at least 20% of memory per node for I/O caching helps application performance., 27279=The main memory was doubled from 24GB to 48GB. At the 24GB level one 4GB DIMM was placed in the first bay of each of the 3 CPU memory channels on each of the two CPU sockets on the Sun Fire X2270 platform. This configuration allows a memory frequency of 1333MHz., 43315=All information on the Fluent website is Copyright 2009 Altair Engineering, Inc. All Rights Reserved. Results from http://www.altairhyperworks.com/Benchmark.aspx, 29365=The effect on performance from increasing memory to augment I/O caching was also examined. The Sun Fire X2270 server was equipped with Intel QC Xeon X5570 processors (Nehalem). The positive effect of adding memory to increase I/O caching is offset to some degree by the reduction in memory frequency with additional DIMMs in the bays of each memory channel on each cpu socket for these Nehalem processors.}",
    "lastModified": "Fri, 03 Apr 2015 18:50:16 GMT",
    "textBeforeTable": "Results are total elapsed run times in seconds ABAQUS \"Standard\" Benchmark Test S4B: Advantage of Sun Storage F5100 Performance Landscape The Sun Fire X4270 server coupled with a Sun Storage F5100 Flash Array established the world record performance on a single node for the four test cases S2A, S4B, S4D and S6. The Sun Storage F5100 Flash Array outperformed the high performance 15K RPM SAS drives on the \"S4b\" test case by 14%. The ABAQUS \"Standard\" module is an MCAE application based on the finite element method (FEA) of analysis. This computer based numerical method inherently involves a substantial I/O component. The purpose was to evaluate the performance of the Sun Storage F5100 Flash Array relative to high performance 15K RPM internal striped HDDs. The I/O intensive ABAQUS \"Standard\" benchmarks test cases were run on a single Sun Fire X4270 server. Data is presented for runs at both 8 and 16 thread counts. The Sun Storage F5100 Flash Array can substantially improve performance over internal hard disk drives as shown by the I/O intensive ABAQUS MCAE application Standard benchmark tests on a Sun Fire X4270 server. By 11111 on Oct 12, 2009 MCAE ABAQUS faster on Sun F5100 and Sun X4270 - Single Node World Record Monday Oct 12, 2009",
    "textAfterTable": "S4b S4d S6 X4270 w/F5100 8 302 1192 779 1237 HP BL460c G6 8 324 1309 843 1322 X4270 w/F5100 4 552 1970 1181 1706 HP BL460c G6 4 561 2062 1234 1812 Results and Configuration Summary Hardware Configuration: Sun Fire X4270 2 x 2.93 GHz QC Intel Xeon X5570 processors Hyperthreading enabled 24 GB memory 4 x 72 GB 15K RPM striped (HW RAID0) SAS disks Sun Storage F5100 Flash Array 20 x 24 GB flash modules Intel controller Software Configuration: O/S: 64-bit SUSE Linux Enterprise Server 10 SP 2 Application: ABAQUS V6.9-1 Standard Module Benchmark: ABAQUS Standard Benchmark Test Suite Benchmark Description Abaqus/Standard Benchmark Problems These problems provide an estimate of the performance that can be expected when running Abaqus/Standard or similar commercially available MCAE (FEA) codes like ANSYS and MSC/Nastran on different computers. The jobs are representative of those typically analyzed by Abaqus/Standard and other MCAE applications. These analyses include linear statics, nonlinear statics, and natural frequency extraction. Please go here for a more complete description of the tests. Key Points and",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}