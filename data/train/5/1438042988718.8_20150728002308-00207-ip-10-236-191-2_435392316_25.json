{
    "relation": [
        [
            "Patent application number",
            "20090190427",
            "20090190429",
            "20090193200",
            "20090193201",
            "20090193203",
            "20130117513",
            "20130138878",
            "20130173858",
            "20140052936"
        ],
        [
            "Description",
            "System to Enable a Memory Hub Device to Manage Thermal Conditions at a Memory Device Level Transparent to a Memory Controller - A memory system is provided that manages thermal conditions at a memory device level transparent to a memory controller. The memory systems comprises a memory hub device integrated in a memory module, a set of memory devices coupled to the memory hub device, and a first set of thermal sensors integrated in the set of memory devices. A thermal management control unit integrated in the memory hub device monitors a temperature of the set of memory devices sensed by the first set of thermal sensors. The memory hub device reduces a memory access rate to the set of memory devices in response to a predetermined thermal threshold being exceeded thereby reducing power used by the set of memory devices which in turn decreases the temperature of the set of memory devices.",
            "System to Provide Memory System Power Reduction Without Reducing Overall Memory System Performance - A memory system is provided that provides memory system power reduction without reducing overall memory system performance. The memory system comprises a memory hub device integrated in a memory module. The memory hub device comprises a command queue that receives a memory access command from an memory controller via a memory channel at a first operating frequency. The memory system also comprises a memory hub controller integrated in the memory hub device. The memory hub controller reads the memory access command from the command queue at a second operating frequency. By receiving the memory access command at the first operating frequency and reading the memory access command at the second operating frequency an asynchronous boundary is implemented. Using the asynchronous boundary, the memory channel operates at a maximum designed operating bandwidth while the second operating frequency is independently decreased to reduce power being consumed by the set of memory devices.",
            "System to Support a Full Asynchronous Interface within a Memory Hub Device - A memory system is provided that implements an asynchronous boundary in a memory module. The memory system comprises a memory hub device integrated in a memory module. The memory system also comprises a set of memory devices coupled to the memory hub device. The memory hub device comprises a command queue that receives a memory access command from an external memory controller via a memory channel at a first operating frequency. The memory system further comprises a memory hub controller integrated in the memory hub device. The memory hub controller reads the memory access command from the command queue at a second operating frequency. By receiving the memory access command at the first operating frequency and reading the memory access command at the second operating frequency an asynchronous boundary is implemented within the memory hub device of the memory module.",
            "System to Increase the Overall Bandwidth of a Memory Channel By Allowing the Memory Channel to Operate at a Frequency Independent from a Memory Device Frequency - A memory system is provided that increases the overall bandwidth of a memory channel by operating the memory channel at a independent frequency. The memory system comprises a memory hub device integrated in a memory module. The memory hub device comprises a command queue that receives a memory access command from an external memory controller via a memory channel at a first operating frequency. The memory system also comprises a memory hub controller integrated in the memory hub device. The memory hub controller reads the memory access command from the command queue at a second operating frequency. By receiving the memory access command at the first operating frequency and reading the memory access command at the second operating frequency an asynchronous boundary is implemented. Using the asynchronous boundary, the memory channel operates at a maximum designed operating bandwidth, which is independent of the second operating frequency.",
            "System to Reduce Latency by Running a Memory Channel Frequency Fully Asynchronous from a Memory Device Frequency - A memory system is provided that reduces latency by running a memory channel fully asynchronous from a memory device frequency. The memory system comprises a memory hub device integrated in a memory module. The memory hub device comprises a command queue that receives a memory access command from an external memory controller via a memory channel at a first operating frequency. The memory system also comprises a memory hub controller integrated in the memory hub device. The memory hub controller reads the memory access command from the command queue at a second operating frequency. By receiving the memory access command at the first operating frequency and reading the memory access command at the second operating frequency an asynchronous boundary is implemented. The first operating frequency is a maximum designed operating frequency of the memory channel and the first operating frequency is independent of the second operating frequency.",
            "MEMORY QUEUE HANDLING TECHNIQUES FOR REDUCING IMPACT OF HIGH LATENCY MEMORY OPERATIONS - Techniques for handling queuing of memory accesses prevent passing excessive requests that implicate a region of memory subject to a high latency memory operation, such as a memory refresh operation, memory scrubbing or an internal bus calibration event, to a re-order queue of a memory controller. The memory controller includes a queue for storing pending memory access requests, a re-order queue for receiving the requests, and a control logic implementing a queue controller that determines if there is a collision between a received request and an ongoing high-latency memory operation. If there is a collision, then transfer of the request to the re-order queue may be rejected outright, or a count of existing queued operations that collide with the high latency operation may be used to determine if queuing the new request will exceed a threshold number of such operations.",
            "Method for Scheduling Memory Refresh Operations Including Power States - A method for performing refresh operations on a rank of memory devices is disclosed. After the completion of a memory operation, a determination is made whether or not a refresh backlog count value is less than a predetermined value and the rank of memory devices is being powered down. If the refresh backlog count value is less than the predetermined value and the rank of memory devices is being powered down, an Idle Count threshold value is set to a maximum value such that a refresh operation will be performed after a maximum delay time. If the refresh backlog count value is not less than the predetermined value or the rank of memory devices is not in a powered down state, the Idle Count threshold value is set based on the slope of an Idle Delay Function such that a refresh operation will be performed accordingly.",
            "Method for Scheduling Memory Refresh Operations Including Power States - A method for performing refresh operations on a rank of memory devices is disclosed. After the completion of a memory operation, a determination is made whether or not a refresh backlog count value is less than a predetermined value and the rank of memory devices is being powered down. If the refresh backlog count value is less than the predetermined value and the rank of memory devices is being powered down, an Idle Count threshold value is set to a maximum value such that a refresh operation will be performed after a maximum delay time. If the refresh backlog count value is not less than the predetermined value or the rank of memory devices is not in a powered down state, the Idle Count threshold value is set based on the slope of an Idle Delay Function such that a refresh operation will be performed accordingly.",
            "MEMORY QUEUE HANDLING TECHNIQUES FOR REDUCING IMPACT OF HIGH-LATENCY MEMORY OPERATIONS - Techniques for handling queuing of memory accesses prevent passing excessive requests that implicate a region of memory subject to a high latency memory operation, such as a memory refresh operation, memory scrubbing or an internal bus calibration event, to a re-order queue of a memory controller. The memory controller includes a queue for storing pending memory access requests, a re-order queue for receiving the requests, and a control logic implementing a queue controller that determines if there is a collision between a received request and an ongoing high-latency memory operation. If there is a collision, then transfer of the request to the re-order queue may be rejected outright, or a count of existing queued operations that collide with the high latency operation may be used to determine if queuing the new request will exceed a threshold number of such operations."
        ],
        [
            "Published",
            "07-30-2009",
            "07-30-2009",
            "07-30-2009",
            "07-30-2009",
            "07-30-2009",
            "05-09-2013",
            "05-30-2013",
            "07-04-2013",
            "02-20-2014"
        ]
    ],
    "pageTitle": "Brittain, US - Patent applications",
    "title": "",
    "url": "http://www.faqs.org/patents/inventor/brittain-us-5/",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 25,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042988718.8/warc/CC-MAIN-20150728002308-00207-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 435417039,
    "recordOffset": 435392316,
    "tableOrientation": "HORIZONTAL",
    "textBeforeTable": "Mark A. Brittain, Pflugerville, TX US 03-20-2014 Memory Reorder Queue Biasing Preceding High Latency Operations - A method for controlling memory refresh operations in dynamic random access memories. The method includes determining a count of deferred memory refresh operations for a first memory rank. Responsive to the count approaching a high priority threshold, issuing an early high priority refresh notification for the first memory rank, which indicates the pre-determined time for performing a high priority memory refresh operation at the first memory rank. Responsive to the early high priority refresh notification, the behavior of a read reorder queue is dynamically modified to give priority scheduling to at least one read command targeting the first memory rank, and one or more of the at least one read command is executed on the first memory rank according to the priority scheduling. Priority scheduling removes these commands from the re-order queue before the refresh operation is initiated at the first memory rank. 20140082272 08-15-2013 MEMORY RECORDER QUEUE BIASING PRECEDING HIGH LATENCY OPERATIONS - A memory system and data processing system for controlling memory refresh operations in dynamic random access memories. The memory controller comprises logic that: tracks a time remaining before a scheduled time for performing a high priority, high latency operation a first memory rank of the memory system; responsive to the time remaining reaching a pre-established early notification time before the schedule time for performing the high priority, high latency operation, biases the re-order",
    "textAfterTable": "Patent applications by Mark A. Brittain, Pflugerville, TX US Mark Andrew Brittain, Pflugerville, TX US Patent application number Description Published 20080294950 DOUBLE DRAM BIT STEERING FOR MULTIPLE ERROR CORRECTIONS - A method and system is presented for correcting a data error in a primary Dynamic Random Access Memory (DRAM) in a Dual In-line Memory Module (DIMM). Each DRAM has a left half (for storing bits 11-27-2008 20080320323 POWER MANAGEMENT VIA DIMM READ OPERATION LIMITER - A method and system for enabling directed temperature/power management at the DIMM-level and/or DRAM-level utilizing intelligent scheduling of memory access operations received at the memory controller. Hot spots within the memory subsystem, caused by operating the DIMMs/DRAMs above predetermined/preset threshold power/temperature values for operating a DIMM and/or a DRAM, are avoided/controlled by logic within the memory controller. The memory controller logic throttles the number/frequency at which commands (read/write operations) are issued to the specific DIMM/DRAM based on stored parameter values and tracking of outstanding operations issued to the memory subsystem devices. 12-25-2008 Richard Dustin Brittain, Bellingham, WA US Patent application number Description Published 20100181815 METHOD AND APPARATUS TO ENHANCE",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}