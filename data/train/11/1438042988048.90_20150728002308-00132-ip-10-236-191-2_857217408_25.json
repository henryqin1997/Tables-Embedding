{
    "relation": [
        [
            "Test",
            "1",
            "2"
        ],
        [
            "PageRank",
            "0.6443",
            "1.242"
        ],
        [
            "TrafficRank",
            "2.275",
            "1.417"
        ],
        [
            "HOTness",
            "0.4610",
            "1.160"
        ]
    ],
    "pageTitle": "A New Paradigm for Ranking Pages on the World Wide Web",
    "title": "",
    "url": "http://www.www2003.org/cdrom/papers/refereed/p042/paper42_html/p42-tomlin.htm",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 25,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042988048.90/warc/CC-MAIN-20150728002308-00132-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 857242743,
    "recordOffset": 857217408,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampAfterTable": "{48147=The methods described here have been implemented and tested extensively on graphs resulting from two crawls of the IBM Intranet (yielding about 19 and 17 million pages) and a partial crawl of the WWW made in 2001, yielding about about 173 million pages. In both sets of experiments, the graph is confined to those pages actually crawled. For both crawls, a large number of other pages were linked to, but not crawled. These links and pages are ignored., 72822=Copyright is held by the author/owner(s). WWW2003, May 20-24, 2003, Budapest, Hungary. ACM 1-58113-680-3/03/0005, 391=Copyright is held by the author/owner(s). WWW2003, May 20-24, 2003, Budapest, Hungary. ACM 1-58113-680-3/03/0005.}",
    "lastModified": "Sat, 05 Apr 2003 05:15:02 GMT",
    "textBeforeTable": ") Table 1: Average Ranks of Intranet Test URLs ( \u00a0 The test URLs were those which in the judgement of ``experts'' should be the primary results of a specified set of queries. Using all three ranking schemes, each page is ranked from highest to lowest (1 through n). Thus each page has a set of three ranks. To measure the ``quality of the results'', we took the average of the ranks for those test URLs which were covered by the crawl. Thus a low average would indicate results judged favorable by the ``experts''. The first test set is the smaller of the two, less than 100 pages. The second test set is somewhat larger (about 200). The averages obtained are shown in Table\u00a01 We first consider the Intranet results. To test the quality of the results of the Traffic and HOTness ranking, they were compared with PageRank both empirically, and on two specific test sets of URLs. The methods described here have been implemented and tested extensively on graphs resulting from two crawls of the IBM Intranet (yielding about 19 and 17 million pages) and a partial crawl of the WWW made in 2001, yielding about about 173 million pages. In both sets of experiments, the graph is confined to those pages actually crawled. For both crawls, a large number of other pages were linked to, but not",
    "textAfterTable": "\u00a0 For the smaller test set 1, the average value is considerably better for HOTness than PageRank, giving greater ``precision'' by this measure. The TrafficRank is much worse. This is because these ranks are measuring somewhat different things. PageRank (and evidently HOTness) measures the ``attractiveness'' of a page, or what is sometimes referred to as authority (see [14]). TrafficRank measures total flow through a page. This is affected by its out-links, as well as its in-links, and indeed pages which score well on TrafficRank tend to point to many other pages. Examples are the indices of manuals, and catalogs. Thus this measure tends to capture hubs (see also [14]). The test set of URLs used here is intended to be a set of authorities, so the result is not surprising. A similar trend is observed for the larger test set 2. The difference in the averages is somewhat less, but they are in the same relationship. By ordinary optimization standards, problems with a million or more variables or cnstraints are presently considered large, and so computing even an aproximate solution to the maximum entropy model for the WWW segment should represent a significant challenge--the associated nonlinear network model has 173 million constraints and over 2 billion variables. Gratifyingly, this very special network model ran, after calibration, in a small multiple (about 2.5) of the time required for the PageRank calculation on a desktop machine. There seems no reason why this approach",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}