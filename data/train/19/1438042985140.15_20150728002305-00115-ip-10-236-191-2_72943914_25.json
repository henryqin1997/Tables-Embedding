{
    "relation": [
        [
            "Command",
            "server-add",
            "server-add",
            "server-add",
            "",
            "server-readd",
            "server-readd",
            "server-readd",
            "",
            "rebalance",
            "rebalance",
            "",
            "failover",
            "",
            "cluster-*",
            "cluster-*",
            "cluster-*",
            "cluster-*",
            "",
            "node-init",
            "node-init",
            "",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "bucket-*",
            "",
            "setting-compacttion",
            "setting-compacttion",
            "setting-compacttion",
            "setting-compacttion",
            "setting-compacttion",
            "setting-compacttion",
            "setting-compacttion",
            "setting-compacttion",
            "",
            "setting-notification",
            "",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "setting-alert",
            "",
            "setting-autofailover",
            "setting-autofailover",
            "",
            "setting-xdcr",
            "setting-xdcr",
            "setting-xdcr",
            "setting-xdcr",
            "setting-xdcr",
            "setting-xdcr",
            "",
            "xdcr-setup",
            "xdcr-setup",
            "xdcr-setup",
            "xdcr-setup",
            "xdcr-setup",
            "xdcr-setup",
            "xdcr-setup",
            "",
            "xdcr-replicate",
            "xdcr-replicate",
            "xdcr-replicate",
            "xdcr-replicate",
            "xdcr-replicate"
        ],
        [
            "Option",
            "--server-add=HOST[:PORT]",
            "--server-add-username=USERNAME",
            "--server-add-password=PASSWORD",
            "",
            "--server-add=HOST[:PORT]",
            "--server-add-username=USERNAME",
            "--server-add-password=PASSWORD",
            "",
            "--server-add*",
            "--server-remove=HOST[:PORT]",
            "",
            "--server-failover=HOST[:PORT]",
            "",
            "--cluster-username=USER",
            "--cluster-password=PASSWORD",
            "--cluster-port=PORT",
            "--cluster-ramsize=RAMSIZEMB",
            "",
            "--node-init-data-path=PATH",
            "--node-init-index-path=PATH",
            "",
            "--bucket=BUCKETNAME",
            "--bucket-type=TYPE",
            "--bucket-port=PORT",
            "--bucket-password=PASSWORD",
            "--bucket-ramsize=RAMSIZEMB",
            "--bucket-replica=COUNT",
            "`\u2013enable-flush=[0",
            "`\u2013enable-index-replica=[0",
            "--wait",
            "--force",
            "--data-only",
            "--view-only",
            "",
            "--compaction-db-percentage=PERCENTAGE",
            "--compaction-db-size=SIZE[MB]",
            "--compaction-view-percentage=PERCENTAGE",
            "--compaction-view-size=SIZE[MB]",
            "--compaction-period-from=HH:MM",
            "--compaction-period-to=HH:MM",
            "`\u2013enable-compaction-abort=[0",
            "`\u2013enable-compaction-parallel=[0",
            "",
            "`\u2013enable-notification=[0",
            "",
            "`\u2013enable-email-alert=[0",
            "--email-recipients=RECIPIENT",
            "--email-sender=SENDER",
            "--email-user=USER",
            "--email-password=PWD",
            "--email-host=HOST",
            "--email-port=PORT",
            "`\u2013enable-email-encrypt=[0",
            "--alert-auto-failover-node",
            "--alert-auto-failover-max-reached",
            "--alert-auto-failover-node-down",
            "--alert-auto-failover-cluster-small",
            "--alert-ip-changed",
            "--alert-disk-space",
            "--alert-meta-overhead",
            "--alert-meta-oom",
            "--alert-write-failed",
            "",
            "`\u2013enable-auto-failover=[0",
            "--auto-failover-timeout=TIMEOUT (>=30)",
            "",
            "--max-concurrent-reps=[32]",
            "--checkpoint-interval=[1800]",
            "--worker-batch-size=[500]",
            "--doc-batch-size=[2048]KB",
            "--failure-restart-interval=[30]",
            "--optimistic-replication-threshold=[256]",
            "",
            "--create",
            "--edit",
            "--delete",
            "--xdcr-cluster-name=CLUSTERNAME",
            "--xdcr-hostname=HOSTNAME",
            "--xdcr-username=USERNAME",
            "--xdcr-password=PASSWORD",
            "",
            "--create",
            "--delete",
            "--xdcr-from-bucket=BUCKET",
            "--xdcr-cluster-name=CLUSTERNAME",
            "--xdcr-to-bucket=BUCKETNAME"
        ],
        [
            "Description",
            "Server to add to cluster",
            "Admin username for the server to be added",
            "Admin password for the server to be added",
            "",
            "Server to re-add to cluster",
            "Admin username for the server to be added",
            "Admin password for the server to be added",
            "",
            "See server-add OPTIONS",
            "The server to remove from cluster",
            "",
            "Server to failover",
            "",
            "New admin username",
            "New admin password",
            "New cluster REST/http port",
            "Per node RAM quota in MB",
            "",
            "Per node path to store data",
            "Per node path to store index",
            "",
            "Named bucket to act on",
            "Bucket type, either memcached or couchbase",
            "Supports ASCII protocol and does not require authentication",
            "Standard port, exclusive with bucket-port",
            "Bucket RAM quota in MB",
            "Replication count",
            "1]` | Enable/disable flush",
            "1]` | Enable/disable index replicas",
            "Wait for bucket create to be complete before returning",
            "Force command execution without asking for confirmation",
            "Compact database data only",
            "Compact view data only",
            "",
            "Percentage of disk fragmentation when database compaction is triggered",
            "Size of disk fragmentation when database compaction is triggered",
            "Percentage of disk fragmentation when views compaction is triggered",
            "Size of disk fragmentation when views compaction is triggered",
            "Enable compaction from this time onward",
            "Stop enabling compaction at this time",
            "1]` | Allow compaction to abort when time expires",
            "1]` | Allow parallel compaction processes for database and view",
            "",
            "1]` | Allow notifications",
            "",
            "1]` | Allow email alert",
            "Email recipients, separate addresses with, or ;",
            "Sender email address",
            "Email server username",
            "Email server password",
            "Email server hostname",
            "Email server port",
            "1]` | Email encryption with 0 the default for no encryption",
            "Node was failed over via autofailover",
            "Maximum number of auto failover nodes reached",
            "Node not auto failed-over as other nodes are down at the same time",
            "Node not auto failed-over as cluster was too small",
            "Node ip address changed unexpectedly",
            "Disk space used for persistent storage has reached at least 90% capacity",
            "Metadata overhead is more than 50% of RAM for node",
            "Bucket memory on a node is entirely used for metadata",
            "Writing data to disk for a specific bucket has failed",
            "",
            "1]` | Allow auto failover",
            "Specify amount of node timeout that triggers auto failover",
            "",
            "Maximum concurrent replicators per bucket, 8 to 256.",
            "Intervals between checkpoints, 60 to 14400 seconds.",
            "Doc batch size, 500 to 10000.",
            "Document batching size, 10 to 100000 KB",
            "Interval for restarting failed xdcr, 1 to 300 seconds",
            "Document body size threshold (bytes) to trigger optimistic replication",
            "",
            "Create a new xdcr configuration",
            "Modify existed xdcr configuration",
            "Delete existing xdcr configuration",
            "Remote cluster name",
            "Remote host name to connect to",
            "Remote cluster admin username",
            "Remote cluster admin password",
            "",
            "Create and start a new replication",
            "Stop and cancel a replication",
            "Source bucket name to replicate from",
            "Remote cluster to replicate to",
            "Remote bucket to replicate to"
        ]
    ],
    "pageTitle": "couchbase-manual-2.1",
    "title": "",
    "url": "http://docs.couchbase.com/couchbase-manual-2.1/",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 25,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042985140.15/warc/CC-MAIN-20150728002305-00115-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 73199215,
    "recordOffset": 72943914,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampAfterTable": "{257808=The server has a process that will periodically scan every key in RAM and compile them into a log, named access.log as well as maintain a backup of this access log, named access.old. The server can use this backup file during warmup if the most recent access log has been corrupted during warmup or node failure. By default this process runs initially at 2:00 GMT and will run again in 24- hour time periods after that point. You can configure this process to run at a different initial time and at a different fixed interval., 291398=To prevent auto compaction taking place when your database is in heavy use, you can configure a time during which compaction is allowed. This is expressed as the hour and minute combination between which compaction occurs. For example, you could configure compaction to take place between 01:00 and 06:00., 79505=The expiration value is user-specified on a document basis at the point when the data is stored. The expiration can also be updated when the data is updated, or explicitly changed through the Couchbase protocol. The expiration time can either be specified as a relative time (for example, in 60 seconds), or absolute time (31st December 2012, 12:00pm)., 862889=May be returned within the view processor as:, 247744=This indicates we have three reader threads and two writer threads on bucket_name in the cluster at hostname:11210. The vBucket map for the data bucket is grouped into multiple shards, where one read worker will access one of the shards. In this example we have one reader for each of the three shards. This report also tell us we are optimized for read data access because we have more reader threads than writer threads for the bucket. You can also view the number of threads if you view the data bucket properties via a REST call:, 635487=Be aware that if you are trying to restore data to a different cluster, that you should make sure that cluster should have the same number of vBuckets as the cluster that you backed up. If you attempt to restore data from a cluster to a cluster with a different number of vBuckets, it will fail when you use the default port of 8091. The default number of vBuckets for Couchbase 2.0 is 1024; in earlier versions of Couchbase, you may have a different number of vBuckets. If you do want to restore data to a cluster with a different number of vBuckets, you should perform this command with port 11211, which will accommodate the difference in vBuckets:, 966632=Then precise date (and time) ranges can be selected by specifying the date and time in the generated data. For example, to get information between 1st April 2011, 00:00 and 30th September 2011, 23:59:, 810164=Interval between checkpoints, 60 to 14400 (seconds). Default 1800. At this time interval, batches of data via XDCR replication will be placed in the front of the disk persistence queue. This time interval determines the volume of data that will be replicated via XDCR should replication need to restart. The greater this value, the longer amount of time transpires for XDCR queues to grow. For example, if you set this to 10 minutes and a network error occurs, when XDCR restarts replication, 10 minutes of items will have accrued for replication., 648598=This shows we transferred 1053 batches of data at 550.8 batches per second. The tool outputs \u201ccannot save bucket design\u2026.\u201d to indicate that no design documents were exported. To import information from a.csv file to a named bucket in a cluster:, 264041=By default the scanner process will run once every 24 hours with a default initial start time of 2:00 AM UTC. This means after you install a new Couchbase Server 2.0 instance or restart the server, by default the scanner will run every 24- hour time period at 2:00 AM UTC by default. To change the time interval when the access scanner process runs to every 20 minutes:, 127693=For Windows 2008, you must upgrade your Windows Server 2008 R2 installation with Service Pack 1 installed before running Couchbase Server. You can obtain Service Pack 1 from Microsoft TechNet., 966952=The flexible structure and nature of the startkey and endkey values enable selection through a variety of range specifications. For example, you can obtain all of the data from the beginning of the year until the 5th March using:, 238821=The server-side (embedded) proxy exists within Couchbase Server using port 11211. It supports the memcached protocol and allows an existing application to communicate with Couchbase Cluster without installing another piece of proxy software. The downside to this approach is performance., 1081154=0 to 21199 \u2014 inclusive for dynamic cluster communication, 264931=In this example we set the initial time to 1:00 PM UTC., 61032=SASL authenticating Couchbase buckets may only be placed on port 11211 and each bucket is differentiated by its name and password. SASL bucket may not be placed on any other port beside 11211. These buckets can be reached with either a vBucket aware smart client or a binary client that has SASL support. These buckets cannot be reached with ASCII clients., 915638=Converts a JavaScript Date object or a valid date string such as \u201c2012-07-30T23:58:22.193Z\u201d into an array of individual date components. For example, the previous string would be converted into a JavaScript array:, 121920=Please note that you have to update your firewall configuration to allow connections to the following ports: 11211, 11210, 11209, 4369, 8091, 8092 and from 21100 to 21299., 1081334=Couchbase Server supports Red Hat (and CentOS) versions 5 starting with update 2, Ubuntu 9 and Windows Server 2008 (other versions have been shown to work but are not being specifically tested). There are both 32-bit and 64-bit versions available. Community support for Mac OS X is available. Future releases will provide support for additional platforms., 60667=Non-SASL buckets may be placed on any available port with the exception of port 11211 if the bucket is not named \u201cdefault\u201d. Only one Non-SASL bucket may placed on any individual port. These buckets may be reached with a vBucket aware smart client, an ASCII client or a binary client that doesn\u2019t use SASL authentication, 220476=All nodes in the cluster should be able to communicate with each other on 11210 and 8091., 1051812=In a Couchbase Server cluster, any communication (stats or data) to a port other than 11210 will result in the request going through a Moxi process. This means that any stats request will be aggregated across the cluster (and may produce some inconsistencies or confusion when looking at stats that are not \u201caggregatable\u201d)., 89635=However, Couchbase Server also allows information to be stored in the database with an expiry value. The expiry value states when a key/value pair should be automatically deleted from the entire database, and can either be specified as a relative time (for example, in 60 seconds), or absolute time (31st December 2012, 12:00pm)., 1052158=In general, it is best to run all your stat commands against port 11210 which will always give you the information for the specific node that you are sending the request to. It is a best practice to then aggregate the relevant data across nodes at a higher level (in your own script or monitoring system)., 601130=To change the initial time that the access scanner process runs from the default of 2:00 AM UTC:, 591149=For this command, host is the IP address for your Couchbase cluster, or node in the cluster. The port will always be the standard port used for cluster-wide stats and is at 11210. You also provide the named bucket and the password for the named bucket. After this you provide command options and authentication., 600576=By default the scanner process will run once every 24 hours with a default initial start time of 2:00 AM UTC. This means after you install a new Couchbase Server 2.0 instance or restart the server, by default the scanner will run every 24- hour time period at 2:00 AM GMT and then 2:00 PM GMT by default. To change the time interval when the access scanner process runs to every 20 minutes:, 807545=(Number) xdcrCheckpointInterval: Interval between checkpoints, 60 to 14400 (seconds). Default 1800., 264562=This updates the parameter for the named bucket, beer-sample on the given node on localhost. To change the initial time that the access scanner process runs from the default of 2:00 AM UTC:, 973512=If you specify a group_level of 2 then you must specify a key using at least the year and month information. For example, you can specify an explicit key, such as [2012,8] :, 1003127=The input includes a count for each of the error types for each month. Note that because the key output includes the year, month and date, the view also supports explicit querying while still supporting grouping and roll-up across the specified group. For example, to show information from 15th November 2010 to 30th April 2011 using the following query:, 812156=Document batching size, 10 to 100000 (KB). Default 2048. In general, increasing this value by 2 or 3 times will improve XDCR transmissions rates, since larger batches of data will be sent in the same timed interval. For unidirectional replication from a source to a destination cluster, adjusting this setting by 2 or 3 times will improve overall replication performance as long as persistence to disk is fast enough on the destination cluster. Note however that this can have a negative impact on the destination cluster if you are performing bi-directional replication between two clusters and the destination already handles a significant volume of reads/writes., 110290=Couchbase clusters with mixed platforms are not supported. Specifically, Couchbase Server on Mac OS X uses 64 vBuckets as opposed to the 1024 vBuckets used by other platforms. Due to this difference, if you need to move data between a Mac OS X cluster and a cluster hosted on another platform use cbbackup and cbrestore. For more information, see Backup and Restore Between Mac OS X and Other Platforms., 645209=This shows we successfully transferred 10000 total documents in batch size of 1088 documents each. This next examples shows how you can send all the data from a node to standard output:, 237774=We configured the memcached client to have just one server in its server list (localhost), so all operations are forwarded to localhost:11211 \u2014 a port serviced by the proxy. The proxy hashes the document ID to a vBucket, looks up the host server in the vBucket table, and then sends the operation to the appropriate Couchbase Server on port 11210., 259777=Here the localhost:11210 is the host name and default memcached port for a given node and beer_sample is a named bucket for the node. If you do not specify a bucket name, the command will apply to any existing default bucket for the node., 59970=The default bucket is a Couchbase bucket that always resides on port 11211 and is a non-SASL authenticating bucket. When Couchbase Server is first installed this bucket is automatically set up during installation. This bucket may be removed after installation and may also be re-added later, but when re-adding a bucket named \u201cdefault\u201d, the bucket must be place on port 11211 and must be a non-SASL authenticating bucket. A bucket not named default may not reside on port 11211 if it is a non-SASL bucket. The default bucket may be reached with a vBucket aware smart client, an ASCII client or a binary client that doesn\u2019t use SASL authentication., 601389=In this example we set the initial time to 11:00 PM UTC.}",
    "lastModified": "Sat, 30 May 2015 02:14:55 GMT",
    "textBeforeTable": "There are two types of data bucket in Couchbase Server: 1) memcached buckets, and 2) couchbase buckets. The two different types of buckets enable you to store data in-memory only, or to store data in-memory as well as on disk for added reliability. When you set up Couchbase Server you can choose what type of bucket you need in your implementation: Couchbase Server provides data management services using buckets ; these are isolated virtual containers for data. A bucket is a logical grouping of physical resources within a cluster of Couchbase Servers. They can be used by multiple client applications across a cluster. Buckets provide a secure mechanism for organizing, managing, and analyzing data storage resources. Data Storage\u00b6 Access to the Cluster Manager is provided through the administration interface (see Administration Tools ) on a dedicated network port, and through dedicated network ports for client access. Additional ports are configured for inter-node communication. Client proxy service to redirect requests Security for administrative and client access Multi-tenancy Run-time logging Statistics gathering and aggregation Node monitoring Node administration Cluster management Every node within a Couchbase Cluster includes the Cluster Manager component. The Cluster Manager is responsible for the following within a cluster: Cluster Manager\u00b6 Cluster A cluster is a collection of one ore more instances of Couchbase Server that are configured as a logical cluster. All nodes within the cluster are",
    "textAfterTable": "Port Description Node to Node Node to Client Cluster Administration XDCR 8091 Web Administration Port Yes Yes Yes Yes 8092 Couchbase API Port Yes Yes No Yes 11209 Internal Cluster Port Yes No No No 11210 Internal Cluster Port Yes Yes No No 11211 Client interface (proxy) No Yes No No 4369 Erlang Port Mapper ( epmd ) Yes No No No 21100 to 21199 (inclusive) Node data exchange Yes No No No Port 8091 Used by the Web Console from outside the second level firewall (for REST/HTTP traffic). Port 8092 Used to access views, run queries, and update design documents. Port 11210 Used by smart client libraries or client-side Moxi to directly connect to the data nodes. Port 11211 Used by pre-existing Couchbase and memcached (non-smart) client libraries that are outside the",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}