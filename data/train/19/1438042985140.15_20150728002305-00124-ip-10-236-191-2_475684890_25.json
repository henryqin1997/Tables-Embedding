{
    "relation": [
        [
            "Date",
            "Apr 9, 2001",
            "Oct 28, 2002",
            "Aug 30, 2006",
            "Sep 6, 2006",
            "Feb 13, 2007",
            "Mar 27, 2007",
            "Feb 12, 2008",
            "Nov 20, 2008",
            "Feb 16, 2010",
            "Oct 4, 2012",
            "Dec 9, 2014"
        ],
        [
            "Code",
            "AS",
            "AS",
            "AS",
            "AS",
            "AS",
            "AS",
            "AS",
            "FPAY",
            "AS",
            "FPAY",
            "AS"
        ],
        [
            "Event",
            "Assignment",
            "Assignment",
            "Assignment",
            "Assignment",
            "Assignment",
            "Assignment",
            "Assignment",
            "Fee payment",
            "Assignment",
            "Fee payment",
            "Assignment"
        ],
        [
            "Description",
            "Owner name: SRI INTERNATIONAL, CALIFORNIA Free format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ARNOLD, JAMES F.;ISRAEL, DAVID J.;TYSON, W. MABRY;AND OTHERS;REEL/FRAME:011693/0126;SIGNING DATES FROM 20010404 TO 20010405",
            "Owner name: DISCERN COMMUNICATIONS, INC., CALIFORNIA Free format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:SRI INTERNATIONAL;REEL/FRAME:013430/0575 Effective date: 20021007",
            "Owner name: SILICON VALLEY BANK, CALIFORNIA Free format text: SECURITY AGREEMENT;ASSIGNOR:SPANLINK COMMUNICATIONS, INC.;REEL/FRAME:018184/0470 Effective date: 20060524",
            "Owner name: SILICON VALLEY BANK, CALIFORNIA Free format text: SECURITY AGREEMENT;ASSIGNOR:SPANLINK COMMUNICATIONS, INC.;REEL/FRAME:018260/0042 Effective date: 20060524",
            "Owner name: SPANLINK COMMUNICATIONS, INC., MINNESOTA Free format text: MERGER;ASSIGNOR:DISCERN COMMUNICATIONS, INC.;REEL/FRAME:018883/0164 Effective date: 20030630",
            "Owner name: POWERSET, INC., CALIFORNIA Free format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:SPANLINK COMMUNICATIONS, INC.;REEL/FRAME:019069/0236 Effective date: 20070322",
            "Owner name: SPANLINK COMMUNICATIONS, INC., MINNESOTA Free format text: RELEASE OF SECURITY INTEREST;ASSIGNOR:SILICON VALLEY BANK;REEL/FRAME:020497/0097 Effective date: 20080204",
            "Year of fee payment: 4",
            "Owner name: MICROSOFT CORPORATION,WASHINGTON Free format text: MERGER;ASSIGNOR:POWERSET, INC.;REEL/FRAME:023937/0185 Effective date: 20091123",
            "Year of fee payment: 8",
            "Owner name: MICROSOFT TECHNOLOGY LICENSING, LLC, WASHINGTON Free format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MICROSOFT CORPORATION;REEL/FRAME:034541/0001 Effective date: 20141014"
        ]
    ],
    "pageTitle": "Patent US6910003 - System, method and article of manufacture for concept based information ... - Google Patents",
    "title": "",
    "url": "http://www.google.com/patents/US6910003?dq=6,891,551",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 25,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042985140.15/warc/CC-MAIN-20150728002305-00124-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 475755047,
    "recordOffset": 475684890,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampBeforeTable": "{6182=Referring to FIG. 13, the automaton 1300 receives free text from the free-text document 1103 of the data acquisition unit 1102 (FIG. 11). The free text is transformed into a sequence of text tokens 1301, which is provided to a name recognizer 1302. The name recognizer 1302 identifies and extracts names 1305 and acronyms as well as multi-words such as \u201cbecause of\u201d that are combined to form single lexical items from the text 1301. The output 1305 of the name recognizer 1302 is provided to a parser 1304 for handling basic phrases 1307. The parser 1304 constructs basic syntactic constituents of the language, consisting only of those that can be nearly unambiguously constructed from the input using finite-state rules (i.e., noun groups, verb groups, and particles).}",
    "TableContextTimeStampAfterTable": "{118966=An exemplary template 1310 will be described next. In this example, the system 1100 extracts information from articles about mergers and acquisitions. The following came from a single sentence: \u201cIBM acquires Microsoft.\u201d, 118311=The output of the automaton 1300 is a set of template files 1310 that contain information about the texts, including sources and the day and time of the article, as well as topic-specific information extracted, including the participants in the topic event/relationship (e.g., company names, person names). These items are related to specific segments of text to support the answers. These templates are loaded into a data store, so that a user can query the system for articles of interested based on the topic area, period of interest, and the participants involved in the events/relationships of interest., 165096=Rules should not be recursive. There should be no cycles. If there are the grammar is no longer necessarily finite-state, and such rules may not be supported by the implementation., 115454=The next level of processing, performed by the parser 1304, handles basic phrases such as noun groups, verb groups, and several critical word classes, including certain prepositions. This level identifies certain syntactic constructs. One of these is the noun group, that is, the head noun of a noun phrase together with its determiners and other left modifiers. Another is a \u201cverb group,\u201d that is, the verb together with its auxiliaries and any intervening adverbs. Verb groups are recognized by a finite-state grammar that tags them as Active, Passive, Gerund, or Infinitive., 117008=The input to the fourth stage of processing by the domain phase transducer 1308 is a list of complex phrases in the order in which they occur. Patterns for events of interest are encoded as finite-state machines, where state transitions are effected by phrases. The state transitions are driven off the head words in the phrases. That is, each pair of relevant head word and phrase type\u2014such as \u201ccompany-NounGroup,\u201d \u201cformed-Passive VerbGroup,\u201d \u201cbargaining-NounGroup,\u201d and \u201cbargaining-PresentParticipleVerbGroup\u201d\u2014has an associated set of state transitions., 162424=Name will be something like Preprocessor or Parser. It should be possible to specify the types of the values of the attributes. This is a provisional list of possible types. The types of input and output objects should normally be declared in the grammar part., 140598=Each user query or search parameter can be entered using the keyboard or pointing device of the handheld computer 2010 or 2014. Alternatively, the user can verbally instruct the handheld computer 2010 or 2014 with the query or search parameter. In this case, the handheld computer 2010 or 2014 can execute a speech recognizer 2008 that maps the user's voice to a set of reference patterns representing the phonetic and phonological descriptions of speech previously obtained from training data. In order to perform this mapping, signal processing techniques such as Fast Fourier Transforms (FFT), Linear Predictive Coding (LPC), or filter banks can be applied to a digital form of the speech signal to extract an appropriate parametric representation of the speech signal. A commonly-used representation is a feature vector containing for each time interval, the FFT or LPC coefficients that represent the frequency and/or energy bands contained in the speech signal., 111449=The automaton 1300 thus divides the natural-language handling process into separate levels for recognizing phrases and recognizing event patterns. Phrases can be recognized reliably with syntactic information, and they provide precisely the elements that are required for stating the event patterns of interest. The earlier stages of the automaton 1300 recognize smaller linguistic objects and work in a largely domain-independent fashion. They use linguistic knowledge to recognize that portion of the syntactic structure of the sentence that linguistic methods can determine reliably, requiring little or no modification or augmentation as the system is moved from domain to domain. The later stages take these linguistic objects as input and find domain-dependent patterns among them., 119766=Turning now to the sentence \u201cIBM acquired Microsoft,\u201d the template 1310 might look as follows:, 151872=The grammar specification metalanguage uses the following metacharacters:, 139935=Each of the mobile devices or handheld computers 2010 and 2014 has a processor, memory, a small display, a data storage device, and suitable input/output devices such as a pointing device, a keyboard, a microphone, a speaker, and parallel/serial/infrared ports, among others. The handheld computers 2010-2014 can include the 3Com Palm, HP 1200 LX, the Psion 3a, the Sharp Zaurus, and Windows CE handheld units. Instead of a mouse or other pointing device, the display can provide a resistive touch surface. This lets the user use a simple plastic stylus or a finger to select various on-screen objects., 45352=The present invention provides interactive question-answering and automated information routing on large collections of free-text information, including news feeds, Web pages, recognized speech, and corporate documents. For example, a user may ask the question, \u201cWho did AOL buy in 1999?\u201d In response, the present invention generates the direct response, \u201cAOL acquired Netscape in 1999,\u201d and provides the relevant quote, along with a citation to the source text used to answer the question. Everything is automatic: no manually prepared answers are required., 92371=During a set-up phase, the information extraction engine 1108 parses free-text documents to identify topics (events and relationships of interest) and objects (people, organizations and locations, among others) involved in those events and relationships. The topic and associated objects are defined and constructed by an analyst when the system 1100 is set up, as discussed in more detail in FIG. 12., 241542=The system builds a chart using a fully incremental parser based which adds new edges or annotations to extend a word lattice, Categorial Grammar was used to give a straightforward syntax/semantics interface, and the grammar was subsequently compiled into simple Dependency Grammar. This enabled the use of a packed parser based on the packed incremental recognizer described by Milward (1994)., 147879=The text generated by the speech recognizer 2102 and the closed caption decoder 2104 is used for cataloging, searching, and retrieving the corresponding video stream. The text extracted from the video stream, along with a time-stamp, is provided to the information retrieval engine and suitably indexed so that when the text is found to be responsive to a particular natural language query, the time-stamp can be used to retrieve the corresponding video stream. Further, audio time stamps can be aligned with time-stamps associated with the processed video stream for subsequent retrieval., 102434=The output of the information extraction engine 1108 is provided to a communications engine 1112 to handle various communications protocols such as Hypertext Transfer Protocol (HTTP). The communication engine 1112 also receives input from a natural language query user interface 1110. The natural language user interface 1110 processes data from a query and reply user front end 1120. The query and reply front end 1120 converts user queries, which can be natural language queries, or search terms, into an internal query format and submits the query to the information extraction and query engine 1104. Exemplary natural language queries can be \u201cTell me about joint ventures involving SBC in the Communications Services Sector\u201d or \u201cDid Barnes & Noble acquire anyone this year?\u201d Exemplary search term queries can be \u201c\u2018joint ventures\u2019 AND SBC\u201d or \u201c\u2018Barnes & Noble\u2019 AND buy OR purchase.\u201d, 166810=If two or more rules have the same rule-identifier, only the last such rule is used. This allows the grammar to be modified by adding the changed rules at the end. 11 is also possible to effectively delete a rule by using (<<fail>> as its RHS., 117603=The first three stages of processing 1302, 1304, and 1306 all operate within the bounds of single sentences. The final level of processing 1308 operates over the whole text. Its task is to see that all the information collected about a single entity or relationship is combined into a unified whole. This is one of the primary ways the problem of coreference is dealt with in this embodiment. The three criteria that are taken into account in determining whether two structures can be merged are the internal structure of the noun groups, nearness along some metric, and the consistency, or more generally, the compatibility of the two structures., 110077=The output 1307 of the parser 1304 in turn is provided to a combiner 1306. The combiner 1306 handles complex phrases 1309 such as complex noun groups and complex verb groups. The combiner 1306 produces larger constituents from the output of the parser when it can be done fairly reliably on the basis of local information. Examples are possessives, appositives, \u201cof\u201d prepositional phrases (\u201cJohn Smith, 56, president of IBM's subsidiary\u201d), coordination of same-type entities, and locative and temporal prepositional phrases., 119232=The desired information, in this case corporate buyers and sellers, is represented as transitions with a start state and an end state. The remaining information in the template is meta-data, e.g., data about the location in the text (by character position) of the various linguistic elements that supply the source of the extracted information. (For example, 261:18 means that the relevant linguistic element starts at the position of the 261st character in the article and goes on for 18 characters.), 132289=Once the system 1100 receives a natural language query from the user, natural language rules are applied to understand the specific goals of the question: the topic area, the type of information sought, and any specific constraints (step 1504). This is accomplished by interpreting the user's natural language query based on the grammar files generated in step 1214 of FIG. 12. The information derived from this interpretation is used to generate a database query which is submitted to the information cache (typically a database, or modified search engine). The information cache returns an output associated with the query. The result is then formatted (step 1506). The formatting includes highlighting relevant portions of the text as well as summarizing the results in a natural language such as English. Next, the formatted response is sent to the user (step 1508)., 139466=Additionally, to serve mobile users, a relay station 2006 is connected to the network 2002. The relay station 2006 communicates with mobile devices such as handheld computers 2010 and 2014. The communication between the relay station 2006 and the remote computers 2010 and 2014 may be performed wirelessly using radio transmissions or optically using infrared beams, among others., 91248=These documents can also be physically copied to a local file system, or can be remotely accessed from their original site. The output of the data acquisition system 1102 is provided to an information extraction and query engine 1104. The information extraction and query engine 1104 can have a pre-filter unit 1106 to perform preprocessing selection of potentially relevant texts (pre-search filtering). The pre-search filtering operation includes format conversion and categorization of information from the data acquisition system 1102. The information extraction and query engine 1104 also includes an information extraction engine 1108. As explained in more detail below, the information extraction engine 1108 identifies events, entities, and relationships using natural language parsing. The information extraction engine 1108 also includes a database 1109 for storing indices for the text associated with the extracted information from the data acquisition system 1102 and the pre-filter unit 1106., 156270=Case in atoms in the grammar specifications is never significant. So SYMBOL, Symbol and symbol are the same. (It would be disastrous to make a distinction between NG and Ng.) However, it is good practice to be consistent, 199005=This is the basis of the architecture of the deep processing component of the SL T system (Boye et al., 1999). The SL T system keeps the top 5 analyses produced by the recognizer to allow later stages of processing to act as a filter on the results of the recognizer. Statistically trained triples (Carter 1997) build in domain dependence to choose the best syntactic/semantic parse. Other systems such as Verbmobil (Kasper et al. 1999, Goertz et al. 1999) and OVIS (van Noord et al, 1999) keep the recognizer lattice, annotating this with syntactic and semantic information., 100589=Once processed, the extracted information is stored and organized in the information cache 1109 , which in various instantiations could be a relational database or modified search engine, to facilitate searches on combinations of topics and objects., 110676=The name recognizer 1302, the parser 1304, and the combiner 1306 are mostly domain independent. The output 1309 of the combiner is eventually provided to a domain phase transducer 1308, which is domain dependent. The domain phase transducer 1308 scans the sequence of phrases for patterns for events of interest to the topic being searched, and when they are found, builds structures that encode the information about entities and events contained in the pattern. A merge phase 1306 merges structures arising from different parts of the text if they provide information about the same entity or event. The output of the domain phase transducer is stored as one or more templates 1310., 215051=How can we deal with this kind of negative information? The first option is just to ignore it. Negation (implicit or explicit) and non-intersective modification is not that common in newspaper texts or in many dialogue scenarios, so the correct inferences will normally go through. However, this means we are unnecessarily throwing away useful information. The second option is to perform some checking of the monotonicity properties of the context e.g. by checking there is no \u2018not\u2019 with the potential to have scope over the material of interest. The third option is to move closer to deep processing, since part of the job of full parsing is to determine constituency, hence scoping, and the job of a grammar to provide useful generalizations using the recursive structure of a language., 193579=It should be noted that there are many different varieties of indexed/flat structures, going back at least to Kay 1970. For example, neo-Davidsonian semantics is sometimes described as a flat representation, since event variables act somewhat similarly to indices. The semantics for a sentence such as \u201cJohn runs at 5 pm\u201d is given by a conjunction of two constraints hanging off an event variable i.e., 211263=Where shallow systems tend to be more problematic is when we try to improve coverage. Many systems rely on precisely ordered pattern matching rules. Adding a rule or changing the order for one phenomenon often causes another to break. This is not unlike trying to maintain a large set of grammar rules in a deep analysis system., 151800=Fastspec Grammar Specification Language, 203421=In contrast, in a deep analysis system with a general purpose grammar, there has to be specific customization to the domain. This may be via specialization of the grammar to the domain (c.f. OVIS), or via the introduction of domain specific preference mechanisms. For example, the SL T system uses \u2018treebanking\u2019 (Carter 1997) which involves a human picking correct analyses in order for the machine to learn domain specific syntactic and semantic triples which select between alternative readings., 82639=The second and more sophisticated situation occurs when a user's question is partially understood, but a significant noun phrase or other qualifying factor is present by not recognized. For example, a corporate announcements grammar may recognize articles where corporations make a public announcement of any general sort. Suppose then that a user asks:, 165425=Grammar start state, 55493=The following describes, by way of example, the internal data storage and retrieval aspects of the present invention. In the given example, a typical business news article is processed through a series of topic grammars. The system recognizes that a corporate acquisition has taken place, and extracts the essential elements of information, including the involved companies and their roles, the time of the event, and location. This information can then be used in several ways, including to generate brief article summaries (e.g., \u201cFeb. 11, 2000: IBM buys Accessible Software Corporation\u201d), route information to subscribers, or answer a user's detailed questions about the event., 196100=Finally, there has also been much interest in using indexed representations for underspecified semantic representation (e.g. Reyle 1993, Egg 1998). Here the emphasis has mainly been on weakening structural constraints to enable underspecified representation of quantifier scope. Structural constraints are divided into dominance, precedence and immediate dominance constraints (similar to the work of Marcus et al. 1983 on the description of syntactic tree structure) making it possible to state that a piece of representation is within the scope of another, without further specifying the relationship., 28996=This is a continuation-in-part of an application filed on Sep. 17, 1999 under Ser. No. 09/398,233 now U.S. Pat. No. 6,601,026., 162717=Attribute types can optionally be declared to enable run-time type checking of attribute values. The root category identifies the top level rules for this grammar part. The default root category is START., 146052=Since the operation of the speech recognizer 2102 is already discussed, it will not be repeated here. With respect to data sources with closed-captioning, the closed caption decoder 2104 generates a word-for-word transcript from a television, VCR, DSS or DVD program. The closed caption decoder 2104 deciphers text information embedded in closed-caption transmission. The text data is stored in line 21, field 1 of a video signal's vertical blanking interval (VBI). The information contained in line 21 contains not only raw data but also timing information. After a timing interval which contains a \u201ccolor burst\u201d, a start bit followed by 16 bits of digital information transmitted as two 8-bit words formatted per the USA Standard Code of Information Interchange (USASCII;x3.4-1967) with odd parity. The closed caption decoder 2104 converts the 8-bit words into text and deliver the text to the data acquisition unit 1102. A variety of decoders can be used, including units deploying the MC144143, available from Motorola Corporation in Phoenix, Ariz. Alternatively, stand-alone units such as the TextGrabber decoder, available from SunBelt Industries Technologies Group, Inc., Jacksonville Beach, Fla., can be used to convert the closed captioned information contained within a television or video signal to text for the data acquisition unit 1102., 103416=In response, the information extraction and query engine 1104 performs a database search and returns the result to the natural language user interface 1110. The natural language user interface 1110 in turn sends this information to the communication engine 1112. The output of the communication engine 1112 is provided to the query and reply front end 1120. Embodiments of the query and reply front end 1120 can provide natural language responses and can summarize the response., 129423=In another exemplary template 1310, the system 1100 extracts information from newspaper articles about high-level management changes in private companies. From a single sentence: \u201cPenelope Muse Abernathy, 41, the Times newsroom business manager, was named vice president, planning, a new post\u201d, the system 1100 is to extract information relating to management changes. The desired information on management changes, can be represented as transitions with a start state and an end state. Each state, in turn, has three main elements: a person, a position, and an organization (company). Using this example, transitions come in two flavors:, 134756=The distilled result is provided to an output box 1702: First, a short summary box 1704 is shown illustrating a particular group of search results, in this case a group of documents (shown with one document) involving Telefono de Mexico S.A. de C. V. and SBC. The response to the question takes the form of a brief phrasal summary of the information (e.g., \u201cJoint Ventures involving Telefonos de Mexico S.A. de C.V. and SBC Communications Inc.\u201d) in the summary box 1704., 142136=Once the system 1100 returns text associated with the query, the text can be shown to the user on the display. Because the system 1100 provides a concise summary along with documents that are responsive to the query, the user can easily review the resulting text on the small display of the handheld computer., 136245=In one embodiment, the language of the natural language query can differ from the language of the searchable documents as well as the language of the natural language reply. For instance, a German user can enter a natural language query in German. The German query can be parsed by a grammar set up to parse German queries, and the resulting query can be applied to documents that can be in Japanese, English, and German, or any other languages. The result of the search can then be summarized in German for the user to review., 163326=Instantiation declarations support a mechanism in the grammar compiler to instantiate rules by sets of variable values. Any rule that contains one or more binding-vars will be instantiated in all possible consistent ways by the set of instantiations defined by \u2018Instantiate . . . Rules . . . By . . . \u2019 declarations.}",
    "textBeforeTable": "Patent Citations While the present invention has been described in terms of several preferred embodiments, there are many alterations, permutations, and equivalents that may fall within the scope of this invention. It should also be noted that there are many alternative ways of implementing the methods and apparatuses of the present invention. It is therefore intended that the following appended claims be interpreted as including all such alterations, permutations, and equivalents as fall within the true spirit and scope of the present invention. This work points to various ways in which we can mix some of the advantages of linguistic analysis with shallower methods. The approach advocated incorporates linguistic information where necessary (e.g. for determining the scope of negation), but also allows linguistic constraints to be relaxed to ensure robustness. Conclusions It should be noted that the current algorithm does not check consistency of contextual constraints: different assumptions about the context may have been made during the filling of different slot values, and ideally the algorithm should check that each translation corresponds to a consistent path through the lattice. Despite this, the ability of the rules to deal with context and domain dependency, and to provide robust interpretation provide very good system performance. After creating the set of potential slot-values, the algorithm then filters the set to obtain a consistent set of slot-value pairs. The first stage is to filter out any cases",
    "textAfterTable": "Jun 26, 2007 Hitachi, Ltd. Question-answering method and question-answering apparatus US7283951 * Nov 8, 2001 Oct 16, 2007 Insightful Corporation Method and system for enhanced data searching US7299186 * Feb 17, 2005 Nov 20, 2007 Hitachi, Ltd. Speech input system, speech portal server, and speech input terminal US7321850 * Jan 31, 2006 Jan 22, 2008 Matsushita Electric Industrial Co., Ltd. Language transference rule producing apparatus, language transferring apparatus method, and program recording medium US7328199 * Oct 7, 2005 Feb 5, 2008 Microsoft Corporation Componentized slot-filling architecture US7337117 * Sep 21, 2004 Feb 26, 2008 At&T Delaware Intellectual Property, Inc. Apparatus and method for phonetically screening predetermined character strings US7363212 * Mar 31, 2004 Apr 22, 2008 Avaya Technology Corp. Method and apparatus for translating a classification system into a target language US7398201 Feb 19, 2003",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}