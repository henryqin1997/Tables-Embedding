{
    "relation": [
        [
            "Forecast",
            "SPF",
            "best forecast from Table 2",
            "univariate forecast",
            "TVP BVAR(4)",
            "avg. of all Table 2 forecasts",
            "avg. of univ., DVAR(4)",
            "avg. of univ., IDTR VAR(4)"
        ],
        [
            "GDP growth forecast: 1970-84,",
            ".310",
            "1.173",
            "1.305",
            "1.239",
            "1.182",
            "1.215",
            "1.206"
        ],
        [
            "GDP growth forecast: 1970-84,",
            "1.436",
            "1.879",
            "2.098",
            "1.959",
            "1.920",
            "1.908",
            "1.910"
        ],
        [
            "GDP growth forecast: 1970-84,",
            "2.589",
            "2.669",
            "2.821",
            "2.981",
            "2.834",
            "2.725",
            "2.719"
        ],
        [
            "GDP growth forecast: 1985-2005,",
            ".104",
            ".371",
            ".379",
            ".407",
            ".386",
            ".389",
            ".371"
        ],
        [
            "GDP growth forecast: 1985-2005,",
            ".460",
            ".742",
            ".777",
            ".781",
            ".764",
            ".805",
            ".742"
        ],
        [
            "GDP growth forecast: 1985-2005,",
            "1.543",
            "1.418",
            "1.633",
            "1.529",
            "1.555",
            "1.680",
            "1.473"
        ]
    ],
    "pageTitle": "FRB: Finance and Economics Discussion Series: Screen Reader Version - Forecasting with Small Macroeconomic VARs in the Presence of Instabilities *",
    "title": "Table 14: Accuracy of select VAR forecasts compared to SPF forecasts (RMSEs in all cases)",
    "url": "http://www.federalreserve.gov/Pubs/feds/2007/200741/index.html",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 25,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042987155.85/warc/CC-MAIN-20150728002307-00099-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 429114655,
    "recordOffset": 429059807,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampBeforeTable": "{1=1. The table reports average rankings of the full set of forecast methods or models listed in Table 1. The average rankings in the first column of figures are calculated, for each forecast method, across a total of 216 (= ) forecasts of output (3: GDP growth, HPS gap, HP gap), inflation (2: GDP inflation, CPI inflation), and interest rates (2: T-bill rate, federal funds rate) at horizons (3) of , , and and sample periods (2) of 1970-84 and 1985-05. The average rankings in remaining columns are based on forecasts with models that include particular variables or forecasts of a particular variable, etc. For example, the average rankings in the second column are based on 144 forecasts of just output and inflation, with forecasts of interest rates omitted from the average ranking calculation.}",
    "TableContextTimeStampAfterTable": "{44493=We obtained benchmark SPF forecasts of growth, inflation, and interest rates from the website of the Federal Reserve Bank of Philadelphia.18 The available forecasts of GDP/GNP growth and inflation span our full 1970 to 2005 sample. The SPF forecasts of CPI inflation and the 3-month Treasury bill rate begin in 1981:Q3. Our benchmark Greenbook forecasts of GDP/GNP growth and inflation and CPI inflation are taken from data on the Federal Reserve Bank of Philadelphia's website and data compiled by Peter Tulip (some of the data are used in Tulip (2005)). We take 1970-99 vintage Greenbook forecasts of GDP/GNP growth and GDP/GNP inflation from the Philadelphia Fed's data set.19 Forecasts of GDP growth and inflation for 2000 are calculated from Tulip's data set. Finally, we take 1979:Q4-2000:Q4 vintage Greenbook forecasts of CPI inflation from Tulip's data set.20, 56510=Consistent with the results in Campbell (2006), D'Agostino, et al. (2005), Stock and Watson (2006), and Tulip (2005), there is also a clear decline in the predictability of both output and inflation: it has become harder to beat the accuracy of a univariate forecast. For example, for each forecast horizon, a number of methods or models beat the accuracy of the univariate forecast of GDP growth during the 1970-84 period (Tables 2 and 4). In fact, many of these do so at a level that is statistically significant. But over the 1985-2005 period, only the BVAR(4)-TVP models are more accurate, at only the 1-year ahead horizon. The reduction in predictability is almost, but not quite, as extreme for the HPS output gap (Tables 3 and 5). While several models perform significantly better than the benchmark in the 1970-84 period, only two classes of methods, the BDVARs and the BVAR-TVPs, significantly outperform the benchmark in the 1985-05 period., 371633=2. RMSEs for SPF forecasts of CPI inflation are not reported for the 1970-84 sample because the SPF data don't begin until 1981., 57472=The predictability of inflation has also declined, although less dramatically than for output. For example, in models with GDP growth and GDP inflation (Table 2), the best 1-year ahead forecasts of inflation improve upon the univariate benchmark RMSE by more than 10 percent in the 1970-84 period but only 5 percent in 1985-05. The evidence of a decline in inflation predictability is perhaps most striking for CPI forecasts at the horizon. In both Tables 4 and 5, most of the models convincingly outperform the univariate benchmark during the 1970-84 period, with statistically significant maximal gains of 18%. But in the following period, many fewer methods outperform the benchmark, with gains typically about 4%., 378431=2. RMSEs for forecasts of CPI inflation are not reported for the 1970-84 sample because the SPF and Greenbook data don't begin until circa 1980., 21190=Despite the appeal of both the rolling and DLS methods, one drawback they share is that they reduce the (effective) number of observations used to estimate each of the model parameters regardless of whether they have exhibited any significant structural change. There are any number of ways to avoid this problem. One would be to attempt to identify structural change in every variable in each equation. To do so one could use any number of approaches, including those proposed in Andrews (1993), Bai and Perron (1998, 2003), and many others. However, in the context of VARs (for which there are numerous parameters), these tests can be poorly sized and exhibit low power, particularly in samples of the size often observed when working with quarterly macroeconomic data. This is precisely the conclusion reached by Boivin (1999). Instead, in light of the importance of mean shifts highlighted in such studies as Clements and Hendry (1996), Kozicki and Tinsley (2001a,b), and Levin and Piger (2003), we focus attention on identifying structural change in the intercepts of the model., 39202=In the case of the CPI and the interest rates, for which real time revisions are small to essentially non-existent (see, for example, Kozicki (2004)), we simply abstract from real time aspects of the data. For the CPI, we follow the advice of Kozicki and Hoffman (2004) for avoiding choppiness in inflation rates for the 1960s and 1970s due to changes in index bases, and use a 1967 base year series taken from the BLS website in late 2005.16 For the T-bill rate, we use a series obtained from FAME., 81140=Of course, an immediate question is, what is reasonable? Trend GDP growth is generally thought to have evolved slowly over time, (at least) declining in the 1970s and rising in the 1990s. The available real-time estimates of potential GDP from the CBO, taken from Kozicki (2004), show some variation in trend growth. CBO estimates of potential output growth rose from about 2.1 percent in 1991 vintage data to 3.2 percent in 2001 and 2.75 percent in 2004 vintage data.27 At the same time, the implicit inflation goal of monetary policymakers is thought to have trended up from the 1970s through the mid-1980s, and then trended down (see Figure 1 and the associated discussion in section 2). The trend in inflation implies a comparable trend in short-term interest rates. Accuracy in longer-term forecasting is likely to require forecast endpoints that roughly match up to variation in such trends in growth and inflation., 80060=As noted in section 3, as the forecast horizon increases beyond the one year period considered above, the so-called endpoints come to play an increasingly important role in determining the forecast. Kozicki and Tinsley (1998, 2001a,b), among others, have shown that these endpoints can vary significantly over time. In this section we examine which, if any of the forecast methods considered above, imply reasonable endpoints. For simplicity, we use a 10-year ahead forecast (the forecast in period +39, from a forecast origin of using data through ) as a proxy for the endpoint estimate. Kozicki and Tinsley (2001b) use a similar metric (Kozicki and Tinsley compare 10 year-ahead forecasts to survey measures of long-term inflation expectations)., 4388=The second reason is that there is an increasing body of evidence suggesting that these VARs may be prone to instabilities.1 Examples include Webb (1995), Boivin (1999, 2006), Kozicki and Tinsley (2001b, 2002), and Cogley and Sargent (2001, 2005). Still more studies have examined instabilities in smaller models, such as AR models of inflation or Phillips curve models of inflation. Examples include Stock and Watson (1996, 1999, 2003, 2006), Levin and Piger (2003), Roberts (2006), and Clark and McCracken (2006b). Although many different structural forces could lead to instabilities in macroeconomic VARs (e.g., Rogoff (2003) and others have suggested that globalization has altered inflation dynamics), much of the aforementioned literature has focused on shifts potentially attributable to changes in the behavior of monetary policy., 22285=To capture potential structural change in the intercepts, we consider several different methods of what might loosely be called `intercept corrections'. The most straightforward is to use pretesting procedures to identify shifts in the intercepts, introduce dummy variables to capture those shifts, estimate the augmented model and proceed to forecasting. In particular, we follow Yao (1988) and Bai and Perron (1998, 2003) in using information criteria to identify break dates associated with the model intercepts. Specifically, at each forecast origin we first choose the number of lags in the system using the AIC and then use an information criterion to select up to two structural breaks in the set of model intercepts. For computational tractability, we use a simple sequential approach -- a partial version of Bai's (1997) sequential method -- to identifying multiple breaks. We first use the information criterion to determine if one break has occurred. If the criterion identifies one break, we then search for a second break that occurred between the time of the first break and the end of the sample.4 The model with up to two intercept breaks is then estimated by OLS and used to forecast. We use two such models, one with breaks identified by the AIC and a second with breaks identified using the BIC., 27451=Another approach to managing structural change in model parameters is to integrate the structural change directly into the VAR.9 Following Doan, et al. (1984) and more recent work by Brainard and Perry (2000) and Cogley and Sargent (2001, 2005), we model the structural change in the parameters of a VAR in , , with random walks.10 However, in light of the potentially adverse effects of parameter estimation noise on forecast accuracy and the potentially unique importance of time variation in intercepts (see above), we consider two different scopes of parameter change. In the first we allow time variation in all coefficients -- both the model intercepts and slope coefficients. In the second, we allow for stochastic variation in only the intercepts.11, 48091=In evaluating the performance of the forecasting methods described above, we follow Stock and Watson (1996, 2003, 2006), among others, in using squared error to evaluate accuracy and considering forecast performance over multiple samples. Specifically, we measure accuracy with root mean square error (RMSE). The forecast samples are generally specified as 1970-84 and 1985-2005 (the latter sample is shortened to 1985-2000 in comparisons to Greenbook forecasts, for which publicly available data end in 2000).21 We split the full sample in this way to ensure our general findings are robust across sample periods, in light of the evidence in Stock and Watson (2003) and others of instabilities in forecast performance over time. However, because real time data on core PCE inflation only begin in 1996, we also present select results for a forecast sample of 1996-2005.22, 43419=As the forecast horizon increases beyond a year, forecasts are increasingly determined by the unconditional means implied by a model. As highlighted by Kozicki and Tinsley (1998, 2001a,b), these unconditional means -- or, in the Kozicki and Tinsley terminology, endpoints -- may vary over time. The accuracy of long horizon forecasts (two or three years ahead, for example) depend importantly on the accuracy of the model's endpoints. As a result, we examine simple measures of the endpoints implied by real time, 1970-2005 estimates of a select subset of the forecasting models described above. For simplicity, we use 10-year ahead forecasts (forecasts for period made with vintage data ending in period ) as proxies for the endpoints., 55737=While there are many nuances in the detailed results, some clear patterns emerge. The RMSEs clearly show the reduced volatility of the economy since the early 1980s, particularly for output. For each horizon, the benchmark univariate RMSE of GDP growth forecasts declined by roughly 2/3 across the 1970-84 and 1985-05 samples; the benchmark RMSE for HPS gap forecasts declined by about 1/2. The reduced volatility is less extreme for the inflation measures but still evident. For each horizon, the benchmark RMSEs fell by roughly 1/2 across the two periods, with the exception that at the horizon the variability in GDP inflation declined nearly 2/3., 65311=Tables 12 and 13 provide aggregate or summary information on the forecast performance of all the methods and nearly all of the data combinations considered. The summary information covers all of the variable combinations and models included in Tables 2-5, as well as variable combinations that include the HP measure of the output gap or the federal funds rate as the interest rate, models based on a fixed lag of two instead of four, and the full set of forecasting methods described in section 2 and listed in Table 1. Our summary approach follows the ranking methodology of Tables 6 and 7. That is, in Tables 12 and 13 we present average rankings for every method we consider across every forecast horizon, various subclasses of models, and the 1970-84 and 1985-05 samples. Note, however, that we exclude the 1996-05 sample (and, as a result, results from models including core PCE inflation), in part because of its overlap with the longer 1985-05 period., 69955=The last two columns of Table 12 compare the performance of methods across the 1970-84 and 1985-05 periods. As in the above detailed comparisons of a subset of results, across the two subperiods there are some sharp differences in the performance of many of even the better performing methods.26 Only four methods have an average ranking of less than 20 over the 1970-84 period (in order from smallest to largest): the average of all forecasts, the average of the univariate and VAR(4) with inflation detrending forecasts, the VAR(2) with full exponential smoothing detrending, and the average of the univariate, VAR(4), DVAR(4), and TVP BVAR(4) forecasts. For the 1985-05 sample, a total of 11 methods have average rankings below 20, but only two of them -- the average of the univariate and VAR(4) with inflation detrending forecasts and the average of the univariate, VAR(4), DVAR(4), and TVP BVAR(4) forecasts -- correspond to the four methods that produce average rankings of less than 20 in the 1970-84 sample. Some of the models that perform relatively well in 1970-84 fare much more poorly in the second sample. For example, the average ranking of the VAR(2) with full exponential smoothing detrending plummets from 17.7 in 1970-84 to 63.9 in 1985-05. Not surprisingly, the rank correlation between these two columns is relatively low, at just 0.58., 75531=Perhaps not surprisingly, the SPF forecasts generally dominate the time series model forecasts. For example, in forecasts of GDP growth for 1970-84, the RMSE for the SPF is 2.571, compared to the best time series RMSE of 3.735 (in which case the best forecast is the all forecast average reported in Table 2). In forecasts of GDP inflation for 1970-84, the RMSE for the SPF is 1.364, compared to the best time series RMSE of 1.727 (again, from the all-forecast average in Table 2). At such short horizons, of course, the SPF has a considerable information advantage over simple time series methods. As described in Croushore (1993), the SPF forecast is based on a survey taken in the second month of each quarter. Survey respondents then have considerably more information, on variables such as interest rates and stock prices, than is reflected in time series forecasts that don't include the same information (as reflected in the bottom panel of Table 14, that information gives the SPF its biggest advantage in near-term interest rates). However, the SPF's advantage over time series methods generally declines as the forecast horizon rises. For instance, in forecasts of GDP growth for 1970-84, the SPF and best time series RMSEs are, respectively, 2.891 and 2.775; for forecasts of GDP inflation, the corresponding RMSEs are 2.192 and 2.141., 59355=The change in predictability makes it difficult to identify methods that consistently improve upon the forecast accuracy of univariate benchmarks. As noted above, none of the methods consistently improve upon the GDP growth benchmark across the subperiods. For forecasts of the HPS gap, the BVAR(4)-TVP models generally outperform the benchmark over both periods. However, the 1970-84 gains are not statistically significant. In the case of inflation forecasts, though, a number of the forecasts significantly outperform the univariate benchmark in both samples. Of particular note are the forecasts that average the benchmark univariate projection with a VAR projection -- either the VAR(4), DVAR(4), or VAR(4) with inflation detrending -- and the average of the univariate forecast with (together) the VAR(4), DVAR(4), and TVP BVAR(4) projections. In the 1970-84 period, these averages nearly always outperform the benchmark, although without necessarily being the best performer. In the 1985-05 period, the averages continue to outperform the benchmark and are frequently among the best performers., 45801=As discussed in such sources as Romer and Romer (2000), Sims (2002), and Croushore (2006), evaluating the accuracy of real time forecasts requires a difficult decision on what to take as the actual data in calculating forecast errors. The GDP data available today for, say, 1970, represent the best available estimates of output in 1970. However, output as defined today is quite different from the definition of output in 1970. For example, today we have available chain weighted GDP; in the 1970s, output was measured with fixed weight GNP. Forecasters in 1970 could not have foreseen such changes and the potential impact on measured output. Accordingly, in our baseline results, we use the first available estimates of GDP/GNP and the GDP/GNP deflator in evaluating forecast accuracy. In particular, we define the actual value to be the first estimate available in subsequent vintages. In the case of -step ahead (for = 0, 1, and 4) forecasts made for period with vintage data ending in period , the first available estimate is normally taken from the vintage data set. In light of our abstraction from real time revisions in CPI inflation and interest rates, the real time data correspond to the final vintage data. In Clark and McCracken (2006a) we provide supplementary results using final vintage (2005:Q4 vintage) data as actuals. Our qualitative results remain broadly unchanged with the use of final vintage data as actuals., 74271=Table 14 compares the accuracy of some of the better time series forecasting methods with the accuracy of SPF projections. The variables we report are those for which SPF forecasts exist: GDP growth, GDP inflation, and CPI inflation (in the case of CPI inflation, the SPF forecasts don't begin until 1981, so we only report CPI results for the 1985-05 period). We also report results for forecasts of the T-bill rate from the SPF and the selected time series models. In particular, Table 14 provides, for the 1970-84 and 1985-05 samples, RMSEs for forecasts from the SPF and a select set of the better-performing time series forecasts: the best forecast RMSE for each variable in each period from those methods included in Table 2 (Table 4 for CPI inflation forecasts), the univariate benchmark forecast, several of the average forecasts, and the baseline TVP BVAR(4). To be sure, comparing forecasts from a source such as SPF against the best forecast from Table 2 or 4 gives the time series models an unrealistic advantage, in that, in real time, a forecaster wouldn't know which method is most accurate. However, as the results presented below make clear, our general findings apply to all of the individual forecasts included in the comparison., 152140=2. Unless otherwise noted, all models are estimated recursively, using all data (starting in 1955 or later) available up to the forecasting date., 25281=Our final variant of intercept correction draws on the approach developed by Kozicki and Tinsley (2001a,b). In their `moving endpoints' structure, the baseline VAR is modeled as having time varying intercepts that allow continuous variation in the long run expectations of the corresponding variables. Our precise method, though, is perhaps more closely related to Kozicki and Tinsley (2002).7 In the context of a small-scale macro VAR, the variables in their model are modeled as deviations from latent time varying steady states (trends). However, whereas they use the Kalman filter to extract estimates of this unknown trend, for tractability we use simple exponential smoothing methods to get estimates. Cogley (2002) develops a model in which exponential smoothing provides an estimate of a time-varying inflation target of the central bank, a target that the public doesn't observe but does learn about over time. With exponential smoothing, the trend estimate can be easily constructed in real time and updated over the multi-step forecast horizon to reflect forecasts of inflation. As indicated in Figure 1, exponential smoothing yields a trend estimate quite similar to an estimate of long-run inflation expectations based on 1981-2005 data from the Hoey survey of financial market participants and the Survey of Professional Forecasters (for a 10-year ahead forecast of CPI inflation) and 1960-1981 estimates of long-run inflation expectations developed by Kozicki and Tinsley (2001a). We construct two different sets of forecasts using the exponential smoothing approach.8 Following Kozicki and Tinsley (2001b, 2002), in the first we use our exponentially smoothed inflation series to detrend both inflation and the interest rate measure. In the second we detrend the inflation and interest rate series separately. In either case we do not detrend the output variable., 78583=In light of the more limited availability of Greenbook (GB) forecasts (the public sample ends in 2000), in lieu of comparing VAR forecasts directly to GB forecasts, we simply compare the GB forecasts to SPF forecasts. As long as the GB and SPF forecasts are broadly comparable in RMSE accuracy, our findings for VARs compared to SPF will also apply to VARs compared to GB forecasts. Table 15 reports RMSEs of forecasts of GDP growth, GDP inflation, and CPI inflation, for samples of 1970-84 and 1985-2000 (we omit an interest rate comparison because, for much of the sample, GB did not include an unconditional interest rate forecast). Consistent with evidence in such studies as Romer and Romer (2000) and Sims (2002), GB forecasts tend to be more accurate, especially for inflation. For instance, the 1970-84 RMSEs of 1-year ahead forecasts of GDP inflation are 2.192 for SPF and 1.653 for GB. However, perhaps reflecting declining predictability, any advantage of GB over SPF is generally smaller in the second sample than the first. Regardless, the accuracy differences between SPF and GB forecasts are modest enough that comparing VAR forecasts against GB instead of SPF wouldn't alter the findings described above., 72799=Just as Tables 12 and 13 provide aggregate evidence on the best methods, they also show what methods consistently perform the worse in the full set of models, methods, and horizons. Perhaps most simply, not a single method on the second pages of the tables has an average rank less than 20! Consistent with the subset of results summarized in Tables 6 and 7, the lowest-ranked methods include: DLS estimation of VARs or DVARs, DVARs with output, in addition to inflation and the interest rate, differenced; and VARs with intercept correction. The consistency of the rankings for these worst-performing methods may be considered impressive. In addition, the average rankings of forecasts based on rolling estimation of VARs (and DVARs, BVARs, etc.) are generally considerably lower than the average rankings of the corresponding VARs estimated with the full sample of data. For example, the average ranking of rolling DVAR(2) forecasts is 41.2, compared to the recursively estimated DVAR(2)'s average ranking of 32.8. While those methods generally falling in the middle ranks (between an average rank of, say, 20 and 50) may not be considered robust approaches to forecasting with the VARs of interest, in particular instances some of these methods may perform relatively well. For example, the DVAR with AIC lags determined for each equation has an average ranking of 39.4, but yields relatively accurate forecasts of GDP inflation in 1985-05 (Tables 2 and 4)., 77222=Moreover, the SPF's advantage is much greater in the 1970-84 sample than the 1985-05 sample. Campbell (2006) notes the same for SPF growth forecasts compared to AR(1) forecasts of GDP growth, attributing the pattern to declining predictability (other recent studies documenting reduced predictability include D'Agostino, et al. (2005), Stock and Watson (2006), and Tulip (2005)). In this later period, the RMSEs of forecasts of GDP growth from the SPF and best time series approach are 1.384 and 1.609, respectively. The RMSEs of forecasts of GDP inflation from the SPF and best time series approach are 0.831 and 0.926, respectively. Reflecting the declining predictability of output and inflation and the reduced advantage of the SPF at longer horizons, for 1-year ahead forecasts in the 1985-05 period, the advantage of the SPF over time series methods is quite small. For instance, in 1-year ahead forecasts of GDP growth, the TVP BVAR(4) using GDP growth, GDP inflation, and the T-bill rate beats the SPF (RMSE of 1.218 vs. 1.274); in forecasts of GDP inflation, the TVP BVAR again beats the SPF (RMSE of 0.764 vs. 0.804)., 64376=Consistent with the 1985-05 results in Tables 2-5, the forecast results for 1996-05 in Tables 8-11 show that univariate benchmarks are difficult to beat. Of the inflation measures, the benchmark is harder to beat with core PCE inflation than with GDP inflation. For 1996-05, only a few forecasts (e.g., rolling VAR(4) or DVAR(4) forecasts for ) beat the univariate benchmark, and none statistically significantly. A few more forecasts are able to improve (some statistically significantly) on the accuracy of the univariate benchmark for GDP inflation. Importantly, for models with GDP inflation, those methods that performed relatively well over the samples covered in Tables 2-5 -- such as the averages of the benchmarks with the VAR(4) or DVAR(4) models -- also perform relatively well over the 1996-05 sample., 63153=Tables 8-11 report RMSE results for models including core PCE inflation. As noted above, reflecting the real time core PCE data availability, the forecast sample is limited to 1996-05. As in Tables 2-5, we report results for models with two different measures of output, GDP growth and the HPS output gap, but a single interest rate measure, the Treasury bill rate. For comparison, we also report 1996-05 results for models using GDP inflation instead of core PCE inflation. As in the case of the results for 1970-84 and 1985-05, we use White (2000) and Hansen (2005) bootstraps to determine whether any of the RMSE ratios are significantly less than one, on both a pairwise (given model against univariate) and best-in-column basis. Individual RMSE ratios that are significantly less than 1 (10% confidence level) are indicated with a slanted font. Note, though, that once the search involved in selecting a best forecast is taken into account, the univariate model is never beaten in the 1996-05 results (that is, none of the data snooping-robust -values are less than .10)., 58312=Reflecting the decline in predictability, many of the methods that perform well over 1970-84 fare much more poorly over 1985-05. The instabilities in performance are clearly evident in both output and inflation forecasts, but more dramatic for output forecasts. For example, a VAR with AIC determined lags and intercept breaks (denoted VAR(AIC), intercept breaks) forecasts both GDP growth and the HPS gap well in the 1970-84 period, with gains as large as 25% for 1-year ahead forecasts of the HPS gap. However, in the 1985-05 period, the VAR with intercept breaks ranks among the worst performers, yielding 1-year ahead output forecasts with RMSEs 60 percent higher than the univariate forecast RMSEs. In the case of inflation forecasts, a DVAR(4) estimated with Bayesian methods and a rolling sample of data (denoted BDVAR(4)) beats the benchmark, by as much as 13 percent, at every horizon during the 1970-84 period. But in the 1985-05 period, the BDVAR(4) is always beaten by the univariate benchmark model, by as much as 21%.}",
    "lastModified": "Thu, 06 Sep 2007 15:29:49 GMT",
    "textBeforeTable": "--> $2\\n$1 to: \\(Table \\d+.*\\: .+\\r?\\n?.+)\\\\r\\n(\\ ) Pattern replaced: Pattern deleted: Table \\d+:",
    "textAfterTable": "same as above with fixed lag order of 2 DVAR(AIC), output diff. VAR in , , with system lag set by AIC DVAR(BIC), output diff. VAR in , , with system lag set by BIC BVAR(4) VAR(4) in , , est. with Minnesota priors, using , , , BVAR(2) same as above with fixed lag order of 2",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}