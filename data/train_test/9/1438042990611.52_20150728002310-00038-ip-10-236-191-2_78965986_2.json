{
    "relation": [
        [
            "MTA",
            "Postfix",
            "Postfix",
            "Postfix",
            "Sendmail",
            "Sendmail",
            "Sendmail",
            "Sendmail"
        ],
        [
            "Msgs/Minute",
            "15",
            "18",
            "20",
            "10",
            "13",
            "15",
            "20"
        ],
        [
            "CPU Use",
            "~70%",
            "~80%",
            "~90%",
            "~50%",
            "~70%",
            "~95%",
            "100%"
        ],
        [
            "Load Average",
            "9",
            "9",
            "11",
            "1",
            "2",
            "4.5",
            "*"
        ]
    ],
    "pageTitle": "Benchmarking Mail Relays and Forwarders \u00ab Russell Coker's Documents",
    "title": "",
    "url": "http://doc.coker.com.au/papers/benchmarking-mail-relays-and-forwarders/",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 2,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042990611.52/warc/CC-MAIN-20150728002310-00038-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 78994183,
    "recordOffset": 78965986,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampAfterTable": "{8905=I presented this paper at the OSDC conference in 2006., 22513=The total number of DNS packets sent and received for each mail server was 2546 for Sendmail, 1525 for Exim, and 1020 for Postfix. Postfix clearly wins in this case for being friendly to the local DNS cache and for not sending pointless IPv6 queries to external DNS servers. For further tests I will use Postfix as I don\u2019t have time to configure a machine that is fast enough to handle the DNS needs of Sendmail., 13494=All the machines in question were running the latest Fedora rawhide as of late September 2006., 24876=I installed a PCI Ethernet card with Intel Corporation 82557/8/9 chipset to use instead of the Ethernet port on the motherboard which had a Intel Corporation 82801BA/BAM/CA/CAM chipset and observed no performance difference. I did not have suitable supplies of spare hardware to test a non-Intel card., 30618=This test seems contrived specifically to abuse DNS and test alias expansion performance, while avoiding the huge performance bottleneck of the queue process. In order to follow RFC, every file written to the queue is opened O_SYNC and brings with it horrible write performance. Try a 1:1 or a 1:3 relay test and watch performance tank., 27471=#!/usr/bin/perl # # use: # mkzones.pl 100 a%s.example.com 10.254.0 10.253.0.7 # the above command creates zones a0.example.com to a99.example.com with an # A record for the mail server having the IP address 10.254.0.X where X is # a number from 1 to 254 and an NS record # with the IP address 10.1.2.4 # # then put the following in your /etc/named.conf #include \"/etc/named.conf.postal\"; # # the file \"users\" in the current directory will have a sample user list for # postal # my $inclfile = \"/etc/named.conf.postal\"; open(INCLUDE, \">$inclfile\") or die \"Can not create $inclfile\"; open(USERS, \">users\") or die \"Can\u2019t create users\"; my $zonedir = \"/var/named/data\"; for(my $i = 0; $i < $ARGV[0]; $i++) { my $zonename = sprintf($ARGV[1], $i); my $filename = \"$zonedir/$zonename\"; open(ZONE, \">$filename\") or die \"Can not create $filename\"; print INCLUDE \"zone \\\"$zonename\\\" {\\n type master;\\n file \\\"$filename\\\";\\n};\\n\\n\"; print ZONE \"\\$ORIGIN $zonename.\\n\\$TTL 86400\\n\\@ SOA localhost. root.localhost. (\\n\"; # serial refresh retry expire ttl print ZONE \" 2006092501 36000 3600 604800 86400 )\\n\"; print ZONE \" IN NS ns.$zonename.\\n\"; print ZONE \" IN MX 10 mail.$zonename.\\n\"; my $final = $i % 254 + 1; print ZONE \"mail IN A $ARGV[2].$final\\n\"; print ZONE \"ns IN A $ARGV[3]\\n\"; close(ZONE); print USERS \"user$final\\@$zonename\\n\"; } close(INCLUDE); close(USERS);, 19761=It seems that there are four DNS requests per recipient giving a total of 1016 DNS requests per message. When 15 messages per minute are delivered to 254 recipients that means 254 DNS requests per second plus some extra requests (lookups of the sending IP address etc).}",
    "textBeforeTable": "The following table shows the amount of CPU time used by the server (from top output) and the load average as well as the mail server in use and the number of messages per minute sent through it. I initially tested with only a single thread of Postal connecting to the server. This means that there was no contention on the origin side and it was all on the MTA side. I tested Sendmail and Postfix with an /etc/aliases file expanding to 254 addresses (one per domain). All the messages had the same sender, and the message size was a random value from 0 to 10K. The script in appendix 1 creates the DNS configuration for the 254 zones and the file of email addresses (one per zone) to use as destinations. I configured the server as a DNS server and a mail relay. A serious mail server will often have a DNS cache running on localhost so for my purposes having primary zones under example.com configured on a DNS server on localhost seemed appropriate. Test 1, BIND and MTA on the Same Server done do ifconfig eth0:$n 10.254.0.$n netmask 255.255.255.0 for n in `seq 1 254`  To prepare for the testing I set up a server running BHM with 254 IP addresses to receive email (mail servers perform optimisations if they see the same IP address being used). The following script creates the interfaces: Preparation All the machines in question were running the latest Fedora",
    "textAfterTable": "Surprisingly the named process appeared to be using ~10% of the CPU at any given time when running Postfix and 25% of the CPU when running Sendmail (not sure why Sendmail does more DNS work \u2013 both MTAs were in fairly default Fedora configurations). As for this operation CPU was the bottleneck it appears that having the named process on the same machine might not be a good optimisation. When testing 15 and 20 messages per minute with Sendmail the CPU use was higher than with Postfix and in my early tests with 256M of RAM in the kernel started reporting ip_conntrack: table full, dropping packet. which disrupted the tests by deferring connections. The conntrack errors are because the TCP connection tracking code in the kernel has a fixed number of entries where the default is chosen based on the amount of RAM in the system. With 256M of RAM in the test system the number of connections that could be tracked was just under 15,000. After upgrading the system to 384M of RAM there was support for tracking 24,568 connections and the problem went away. You can change the maximum number of connections by the command echo NUMBER > /proc/sys/net/ipv4/ip_conntrack_max or for a permanent change edit /etc/sysctl.conf and add the line net.ipv4.ip_conntrack_max = NUMBER and then run sysctl -p to load the settings from /etc/sysctl.conf. Note that adding more RAM will increase many system resource limits that affect the operation of the system. My preferred solution to this",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}