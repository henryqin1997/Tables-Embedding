{
    "relation": [
        [
            "Prefix Length",
            "0",
            "0",
            "1",
            "1",
            "2",
            "2"
        ],
        [
            "PQ Size",
            "1024",
            "64",
            "1024",
            "64",
            "1024",
            "64"
        ],
        [
            "Avg MS (old)",
            "3286.0",
            "3320.4",
            "316.8",
            "314.3",
            "31.8",
            "31.9"
        ],
        [
            "Avg MS (new)",
            "7.8",
            "7.6",
            "5.6",
            "5.6",
            "3.8",
            "3.7"
        ]
    ],
    "pageTitle": "[LUCENE-2089] explore using automaton for fuzzyquery - ASF JIRA",
    "title": "",
    "url": "https://issues.apache.org/jira/browse/LUCENE-2089?focusedCommentId=12834111&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 4,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042992201.62/warc/CC-MAIN-20150728002312-00233-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 868908807,
    "recordOffset": 868847354,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampBeforeTable": "{66720=LUCENE-2123 Move FuzzyQuery rewrite as separate RewriteMode into MTQ, was: Highlighter fails to highlight FuzzyQuery, 65166=LUCENE-2140 TopTermsScoringBooleanQueryRewrite minscore, 63616=LUCENE-2261 configurable MultiTermQuery TopTermsScoringBooleanRewrite pq size, 61887=LUCENE-1513 fastss fuzzyquery, 1296=Mike, this is awesome. I ran benchmarks: we are just as fast as before (with only Lev1 and Lev2 enabled), but with smaller generated code. When i turn on Lev3, it speeds up the worst-case ones (no prefix, pq=1024, fuzzy of n=3, n=4), but slows down some of the \"better-case\" n=3/n=4 cases where there is a prefix or PQ., 112782=We build Levenshtein DFAs in linear time with respect to the length of the word: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.652, 52032=Committed revision 921820.}",
    "TableContextTimeStampAfterTable": "{189091=? We mentioned it here already, LUCENE-1513, but our use case is very specific... and why to allow 5 spelling mistakes in Unicode if user's input contains 3 characters only in Latin1? We should hardcode some constraints., 216600=However, given the speedups to AutomatonQuery itself done in LUCENE-1606, it will actually surpass this approach, impose no index or storage requirements, scale to higher N, and allow for full back compat., 198693=here is a description from the 2002 paper that describes how automaton works (for regex, wildcard, fuzzy, whatever the case) I edited the description to substitute components with their implementation... and yes it works for all Unicode (all over 1 million codepoints not just the BMP), 235804=another difference here is that the minimum distance is not fixed, but changes during enumeration, if the priority queue fills up then there is no point wasting time seeking to terms that will only be dropped, see LUCENE-2140, 247595=Fuad, this is the wrong paper, it will not work for lucene...this issue uses http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.652 (linked in the summary)., 243986=Ok; I am trying to study DFA&NFA and to compare with LUCENE-2230 (BKTree size is fixed without dependency on distance, but we need to hard-cache it...). What I found is that classic Levenshtein algo is eating 75% CPU, and classic brute-force TermEnum 25%... Distance (submitted by end user) must be integer..., 250363=Downloadable article (PDF): http://www.mitpressjournals.org/doi/pdf/10.1162/0891201042544938?cookieSet=1, 211470=For LUCENE-2230 I did a lot of long-run load-stress tests (against SOLR), but before doing that I created baseline for static admin screen in SOLR: 1500TPS. And I reached 220TPS with Fuzzy Search... what I am trying to say is this: can DFA with Levenshtein reach 250TPS (in real-world multi-tier web environment)? Baseline for static page is 1500. Also, is DFA mostly CPU-bound? Can we improve it by making (some) I/O-bound unload? Just joking, 216254=This is not necessary for AutomatonQuery, and imposes too much of a space tradeoff. You can see an example of this in LUCENE-1513, where deletion neighborhoods are indexed., 239314=the advantage of the (more complex) 2002 paper is that we can run it on lucene's existing term dictionary, and it will seek to the right spots (i.e. you can take the code i attached here, and pass it to automatonquery and it executes efficiently)., 239853=i tried to make a visual description of how Automaton works for regexp, wildcard, and fuzzy here if you are interested: http://rcmuir.wordpress.com/2009/12/04/finite-state-queries-for-lucene/, 139026=this is the part i am working on now, most of it already one under LUCENE-2140 and some setup now under LUCENE-2261}",
    "textBeforeTable": "Minimum Sim = 0.73f (edit distance of 1) Its cool to be at the point where we are actually able to measure these kinds of tradeoffs! Here are the results anyway: I ran it many times and its consistent (obviously differences of just a few MS are not significant). I bolded the ones i think illustrate the differences I am talking about. separately, I think we can add heuristics: e.g. for n > 3 WITH a prefix, use the DFA in \"linear mode\" until you drop to n=2, as you already have a nice prefix anyway, stuff like that. But if the user doesn't supply a prefix, i think seeking is always a win. I think this is because the benchmark is contrived, but realistically n=3 (with seeking!) should be a win for users. A less-contrived benchmark (a 'typical' massive term dictionary) would help for tuning. Mike, this is awesome. I ran benchmarks: we are just as fast as before (with only Lev1 and Lev2 enabled), but with smaller generated code. When i turn on Lev3, it speeds up the worst-case ones (no prefix, pq=1024, fuzzy of n=3, n=4), but slows down some of the \"better-case\" n=3/n=4 cases where there is a prefix or PQ. 27/Feb/10 20:50 Robert Muir added a comment -",
    "textAfterTable": "2 64 31.9 3.7 4.5 Minimum Sim = 0.58f (edit distance of 2) Prefix Length PQ Size Avg MS (flex trunk) Avg MS (1,2) Avg MS (1,2,3) 0 1024 4223.3 87.7 91.2 0 64 4199.7 12.6 13.2 1 1024 430.1 56.4 62.0 1 64 392.8 9.3 8.5 2 1024 82.5 45.5 48.0 2 64 38.4 6.2 6.3 Minimum Sim = 0.43f (edit distance of 3) Prefix Length PQ Size Avg MS (flex trunk) Avg MS (1,2) Avg MS (1,2,3) 0 1024 5299.9 424.0 199.8 0 64 5231.8 54.1 93.2 1 1024 522.9 103.6 107.9 1 64 480.9 14.5 49.3 2 1024 89.0 67.9 70.8 2 64 46.3 6.8 19.7 Minimum Sim = 0.29f (edit distance of 4) Prefix Length PQ Size Avg MS (flex trunk) Avg",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}