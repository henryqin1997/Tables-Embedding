{
    "relation": [
        [
            "Please select all that apply regarding the Phoenix student workshop. (Select all that apply)",
            "My child enjoyed the student workshop.",
            "My child enjoyed socializing with peers at the workshop.",
            "The activities were varied.",
            "My child enjoyed working with the teachers.",
            "My child had a chance to learn some new math strategies.",
            "My child had the opportunity to review math skills.",
            "The activities were too hard.",
            "The activities were too easy."
        ],
        [
            "Total Count",
            "10",
            "12",
            "10",
            "11",
            "8",
            "10",
            "0",
            "1"
        ],
        [
            "% of Total",
            "83%",
            "100%",
            "83%",
            "92%",
            "67%",
            "83%",
            "0%",
            "8%"
        ]
    ],
    "pageTitle": "Evaluating Online Learning: Challenges and Strategies for Success-- Pg 14",
    "title": "",
    "url": "http://www2.ed.gov/admins/lead/academic/evalonline/report_pg14.html",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 1,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042990112.92/warc/CC-MAIN-20150728002310-00161-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 856284723,
    "recordOffset": 856263954,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampBeforeTable": "{27457=Evaluators very commonly have difficulty collecting data from respondents who do not feel personally invested in the evaluation, and online program evaluators are no exception. In the case of Louisiana's Algebra I Online program, evaluators faced problems getting data from control group teachers. Initially, the state department of education had hoped to conduct a quasi-experimental study (see Glossary of Common Evaluation Terms, p. 65) comparing the performance of students in the online program with students in face-to-face settings. Knowing it might be a challenge to find and collect data from control groups across the state, the program administrators required participating districts to agree up front to identify traditional classrooms (with student demographics matching those of online courses) that would participate in the collection of data necessary for ongoing program evaluation. It was a proactive move, but even with this agreement in place, the external evaluator found it difficult to get control teachers to administer posttests at the end of their courses. The control teachers had been identified, but they were far removed from the program and its evaluation, and many had valid concerns about giving up a day of instruction to issue the test. In the end, many of the students in the comparison classrooms did not complete posttests; only about 64 percent of control students were tested compared to 89 percent of online students. In 2005, hurricanes Katrina and Rita created additional problems, as many of the control group classrooms were scattered and data were lost., 30945=In 2004, Chicago Public Schools (CPS) established the Virtual High School (CPS/VHS) to provide students with access to a wide range of online courses taught by credentialed teachers. The program seemed like an economical way to meet several district goals: Providing all students with highly qualified teachers; expanding access to a wide range of courses, especially for traditionally underserved students; and addressing the problem of low enrollment in certain high school courses. Concerned about their students' course completion rates, CPS/VHS administrators wanted to learn how to strengthen student preparedness and performance in their program. Seeing student readiness as critical to a successful online learning experience, the project's independent evaluator, TA Consulting, and district administrators focused on student orientation and support; in particular, they wanted to assess the effectiveness of a tutorial tool developed to orient students to online course taking., 29480=To address this problem, the researchers changed course midway through the study, refocusing it on the preparedness of in-class mentors who supported the online courses. This change kept the focus on student support and preparation, but sidestepped the problem of assigning students randomly to the tutorial. In the revised design, evaluators collected data directly from participating students and mentors, gathering information about students' ability to manage time, the amount of on-task time students needed for success, and the level of student and mentor technology skills. The evaluators conducted surveys and focus groups with participants, as well as interviews with the administrators of CPS/VHS and Illinois Virtual High School (IVHS), the umbrella organization that provides online courses through CPS/VHS and other districts in the state. They also collected data on student grades and participation in orientation activities. To retain a comparative element in the study, evaluators analyzed online course completion data for the entire state: They found that CPS/VHS course completion rates were 10 to 15 percent lower than comparable rates for all students in IVHS in the fall of 2004 and spring of 2005, but in the fall of 2005, when fewer students enrolled, CPS/VHS showed its highest completion rate ever, at 83.6 percent, surpassing IVHS's informal target of 70 percent.10}",
    "textBeforeTable": "At this time 12 responses have been received. 100% returned, 12 surveys deployed via e-mail. Title I Student Workshop Survey\u2013Phoenix Figure 2. Example of Tabulated Results From an Arizona Virtual Academy Online Parent Survey About the Quality of a Recent Student Workshop* Another common problem for online evaluators is the challenge of collecting and aggregating data from multiple sources. As noted earlier, Washington state's DLC offers a wide array of online resources for students and educators. To understand how online courses contribute to students' progress toward a high school diploma and college readiness, the program evaluators conducted site visits to several high schools offering courses through DLC. In reviewing student transcripts, however, the evaluators discovered that schools did not have the same practices for maintaining course completion data and that DLC courses were awarded varying numbers of credits at different schools\u2014the same DLC course might earn a student .5 credit, 1 credit, 1.5 credits, or 2 credits. This lack of consistency made it difficult to aggregate data across sites and to determine the extent to which DLC courses helped students to graduate from high school or complete a college preparation curriculum. Define Data Elements Across Many Sources Web sites and online courses can offer other opportunities to collect important information with no burden on the participant. For example, evaluators could analyze the different pathways users take as they navigate through a particular online tool or Web site,",
    "textAfterTable": "\u00a0 Please use the space below to let us know your thoughts about the student workshop. (Text limited to 250 characters.)(Text input) Recipient Response \u00a0 All 3 math teachers were very nice and understanding and they did not yell at you like the brick and mortar schools, which made learning fun. \u00a0 My son did not want to go when I took him. When I picked him up he told me he was glad he went. \u00a0 She was bored, \"it was stuff she already knew,\" she stated. She liked the toothpick activity. She could have been challenged more. She LOVED lunch! \u00a0 My child really enjoyed the chance to work in a group setting. She seemed to learn a lot and the games helped things \"click.\" \u00a0 She was happy she went and said she learned a lot and had lots of fun. That is what I was hoping for when I enrolled her. She is happy and better off for going. \u00a0 THANKS FOR THE WORKSHOP NEED MORE OF THEM \u00a0 The teachers were fun, smart and awesome, and the children learn new math strategies. \u00a0 Thank you keep up the good work. Source: Arizona Virtual Academy * The U.S. Department of Education does not mandate or prescribe particular curricula or",
    "hasKeyColumn": true,
    "keyColumnIndex": 0,
    "headerRowIndex": 0
}