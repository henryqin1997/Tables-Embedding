{
    "relation": [
        [
            "Patente citante",
            "US7756348 *",
            "US7869516 *",
            "US7936825 *",
            "US8055025 *",
            "US8094714",
            "US8155202 *",
            "US8194184 *",
            "US8265464",
            "US8396132",
            "US8509552 *",
            "US8526500",
            "US8605944 *",
            "US8780988 *",
            "US8878862",
            "US8937623",
            "US8943090 *",
            "US9042454",
            "US9077860",
            "US20040190619 *",
            "US20040233995 *",
            "US20080025387 *",
            "US20090316786 *",
            "US20100079667 *",
            "US20100296572 *",
            "US20110069170 *",
            "US20120014433 *",
            "US20130117662 *",
            "US20130254235 *",
            "CN102100068B",
            "WO2010008654A1 *"
        ],
        [
            "Fecha de presentaci\ufffdn",
            "30 Oct 2006",
            "31 Mar 2003",
            "31 Ene 2003",
            "14 Jun 2008",
            "16 Jul 2008",
            "11 Ene 2008",
            "21 Ago 2009",
            "26 Feb 2009",
            "16 Mar 2010",
            "6 Oct 2009",
            "11 Ago 2009",
            "18 Mar 2009",
            "28 Feb 2008",
            "22 Ago 2012",
            "15 Oct 2012",
            "15 Sep 2012",
            "11 Ene 2008",
            "5 Dic 2011",
            "31 Mar 2003",
            "31 Ene 2003",
            "13 Jun 2007",
            "10 Abr 2007",
            "21 Ago 2009",
            "16 Jul 2008",
            "18 Mar 2009",
            "",
            "",
            "15 Sep 2012",
            "5 May 2009",
            "5 May 2009"
        ],
        [
            "Fecha de publicaci\ufffdn",
            "13 Jul 2010",
            "11 Ene 2011",
            "3 May 2011",
            "8 Nov 2011",
            "10 Ene 2012",
            "10 Abr 2012",
            "5 Jun 2012",
            "11 Sep 2012",
            "12 Mar 2013",
            "13 Ago 2013",
            "3 Sep 2013",
            "10 Dic 2013",
            "15 Jul 2014",
            "4 Nov 2014",
            "20 Ene 2015",
            "27 Ene 2015",
            "26 May 2015",
            "7 Jul 2015",
            "30 Sep 2004",
            "25 Nov 2004",
            "31 Ene 2008",
            "24 Dic 2009",
            "1 Abr 2010",
            "25 Nov 2010",
            "24 Mar 2011",
            "19 Ene 2012",
            "9 May 2013",
            "26 Sep 2013",
            "6 Nov 2013",
            "21 Ene 2010"
        ],
        [
            "Solicitante",
            "Hewlett-Packard Development Company, L.P.",
            "Hewlett-Packard Development Company, L.P.",
            "Panasonic Corporation",
            "City University Of Hong Kong",
            "Sony Corporation",
            "Activevideo Networks, Inc.",
            "Vestel Elektronik Sanayi Ve Ticaret A.S.",
            "International Business Machines Corporation",
            "Panasonic Corporation",
            "Marvell International Ltd.",
            "Seiko Epson Corporation",
            "Mitsubishi Electric Corporation",
            "Vixs Systems, Inc.",
            "2236008 Ontario Inc.",
            "Apple Inc.",
            "A9.Com, Inc.",
            "Activevideo Networks, Inc.",
            "Activevideo Networks, Inc.",
            "Lee Ruby B.",
            "Kiyofumi Abe",
            "Eul Gyoon Lim",
            "Nxp B.V.",
            "Vestel Elektronik Sanayi Ve Ticaret A.S.",
            "Kumar Ramaswamy",
            "Mitsubishi Electric Corporation",
            "Qualcomm Incorporated",
            "Cisco Technology, Inc.",
            "A9.Com, Inc.",
            "\u7d22\u5c3c\u516c\u53f8",
            "Sony Corporation"
        ],
        [
            "T\ufffdtulo",
            "Method for decomposing a video sequence frame",
            "Motion estimation using bit-wise block comparisons for video compresssion",
            "Moving image coding method and moving image decoding method",
            "Motion estimation method",
            "Speculative start point selection for motion estimation iterative search",
            "System and method for encoding scrolling raster images",
            "Method and apparatus for increasing the frame rate of a video signal",
            "Administering a time-shifting cache in a media playback device",
            "Moving picture coding method and moving picture decoding method",
            "Digital image processing error concealment method",
            "System and method for global inter-frame motion detection in video sequences",
            "In-train monitor system",
            "Hierarchical video analysis-based real-time perceptual video coding",
            "Composition manager camera",
            "Page flipping with backend scaling at high resolutions",
            "Content collection search with robust content matching",
            "Interactive encoded content system including object models for viewing on a remote device",
            "System and method for providing video content associated with a source image to a television in a communication network",
            "Motion estimation using bit-wise block comparisons for video compresssion",
            "Moving image coding method and moving image decoding method",
            "Intelligent moving robot based network communication capable of outputting/transmitting images selectively according to moving of photographed object",
            "Motion estimation at image borders",
            "Method and apparatus for increasing the frame rate of a video signal",
            "Methods and systems for transcoding within the distributiion chain",
            "In-train monitor system",
            "Entropy coding of bins across bin groups using variable length codewords",
            "Utilizing scrolling detection for screen content encoding",
            "Content collection search with robust content matching",
            "Speculative start point selection for motion estimation iterative search",
            "Speculative start point selection for motion estimation iterative search"
        ]
    ],
    "pageTitle": "Patente US7224731 - Motion estimation/compensation for screen capture video - Google Patentes",
    "title": "",
    "url": "http://www.google.es/patents/US7224731?dq=flatulence",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 7,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438042990177.43/warc/CC-MAIN-20150728002310-00163-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 490033535,
    "recordOffset": 489986042,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampBeforeTable": "{6603=FIG. 10 shows a pixel map (1000) illustrating whether pixels have changed or not changed at locations in the second frame (901) relative to the previous frame (900). In the pixel map (1000), the shaded regions (1010-1013) represent pixels that have not changed in value. A first shaded region (1010) represents pixels of the background (910) that are identical (same value, same content) in the two frames. In addition, several shaded regions (1011-1013) represent pixels within the window (920) that have changed locations in the two frames, but happen to have the same value before and after (different content, same value). This is fairly common if the moved regions include palettized content of uniform color.}",
    "TableContextTimeStampAfterTable": "{75933=In a common screen capture scenario, a screen capture module (not shown) captures screen areas that the encoder (300) compresses as a series of frames. The screen capture module can be a standalone software application, a feature of a multimedia production or encoding package, a plug-in, or some other form of product. The captured screen areas can show an entire screen (for example, an entire desktop environment), a selected window, or an arbitrary region of the desktop environment. In general, a screen area depicts some or all of the screen content presented or prepared for presentation in a desktop environment or other graphical user interface for a computer system. To capture a screen area, the screen capture module uses a Bit Block Transfer or other screen capture technique, such as one described in U.S. patent application Ser. No. 10/160,697, filed May 30, 2002, entitled \u201cReducing Information Transfer in Screen Capture Series,\u201d hereby incorporated by reference., 115906=The medium shaded regions (1130, 1131) represent pixels that changed between the two frames but were motion estimated (the same content at a shifted location). These pixels correspond to parts of the dragged window (920)., 113889=The white regions (1020-1023) represent pixels that have changed in value. The first white region (1020) represents pixels of the background (910) exposed when the window (920) is dragged. The second white region (1021) represents pixels for which the border region (930) of the window (920) in the second frame (901) replaced center area (940) pixels in the previous frame (900). The third white region (1022) represents pixels of the window (920) in the second frame (901) that overlay parts of the background (910) shown in the first frame (900). The fourth white region (1023) represents pixels for which the center area (940) of the window (920) in the second frame (901) replaced border region (930) pixels in the previous frame (900)., 116181=Finally, the dark shaded regions (1140, 1141) represent pixels that did not change between the two frames, but could also be predicted by motion estimation. These pixels correspond to parts of the dragged window (920). Depending on the relative efficiencies (e.g., coding of the pixel map), the encoder can send the pixels of the dark shaded regions (1140, 1141) as identical pixels or motion estimated pixels. For example, the encoder can choose to send the pixels in the dark shaded regions (1140, 1141) as identical pixels or motion estimated pixels depending on which way results in lower bitrate for the pixels (a closed loop solution), or depending on the size or regularity of the resulting identical pixel or motion estimated pixel regions., 44878=The following concurrently filed U.S. patent applications relate to the present application: 1) U.S. patent application Ser. No. 10/186,481, entitled, \u201cRate Allocation for Mixed Content Video,\u201d filed Jun. 28, 2002, the disclosure of which is hereby incorporated by reference; 2) U.S. patent application Ser. No. 10/186,639, entitled, \u201cAdaptive Entropy Encoding/Decoding for Screen Capture Content,\u201d filed Jun. 28, 2002, the disclosure of which is hereby incorporated by reference; and 3) U.S. patent application Ser. No. 10/186,887, entitled, \u201cText Detection in Continuous Tone Image Segments,\u201d filed Jun. 28, 2002, the disclosure of which is hereby incorporated by reference.}",
    "textBeforeTable": "Citas de patentes In view of the many possible embodiments to which the principles of my invention may be applied, I claim as my invention all such embodiments as may come within the scope and spirit of the following claims and equivalents thereto. Having described and illustrated the principles of my invention with reference to various described embodiments, it will be recognized that the described embodiments can be modified in arrangement and detail without departing from such principles. It should be understood that the programs, processes, or methods described herein are not related or limited to any particular type of computing environment, unless indicated otherwise. Various types of general purpose or specialized computing environments may be used with or perform operations in accordance with the teachings described herein. Elements of the described embodiments shown in software may be implemented in hardware and vice versa. The decoder then continues with other processing for the current frame. For example, the decoder assembles the current frame using the motion compensated region(s) together with intra pixel data and/or values for pixels that did not change relative to the reference frame, as described above. Subsequently, the encoder can continue with motion compensation for the next frame. The decoder constructs (1230) pixels in the motion compensated region(s) in the current frame. For example, for a motion vector (\u0394x, \u0394y) and a motion compensated region at the location (x, y) in",
    "textAfterTable": "US5844613 30 Jun 1997 1 Dic 1998 Microsoft Corporation Global motion estimator for motion video signal encoding US5847776 24 Jun 1996 8 Dic 1998 Vdonet Corporation Ltd. Method for entropy constrained motion estimation and coding of motion vectors with increased search range US5912991 * 19 May 1997 15 Jun 1999 Samsung Electronics Co., Ltd. Contour encoding method using error bands US5929940 24 Oct 1996 27 Jul 1999 U.S. Philips Corporation Method and device for estimating motion between images, system for encoding segmented images US5949489 31 Jul 1998 7 Sep 1999 Mitsubishi Denki Kabushiki Kaisha Image signal coding system US5963258 31 Jul 1998 5 Oct 1999 Mitsubishi Denki Kabushiki Kaisha Image signal coding system US5963259 15 Jul 1997 5 Oct 1999 Hitachi, Ltd. Video coding/decoding system and video coder and video decoder used for the same system US5970173 4 Jun 1996 19 Oct 1999 Microsoft Corporation",
    "hasKeyColumn": true,
    "keyColumnIndex": 3,
    "headerRowIndex": 0
}