{
    "relation": [
        [
            "Citing Patent",
            "US6526325 *",
            "US6577252 *",
            "US6801887 *",
            "US6829576 *",
            "US6980933 *",
            "US7020615 *",
            "US7069210 *",
            "US7085712 *",
            "US7313519 *",
            "US7319756 *",
            "US7363216 *",
            "US7386445 *",
            "US7447640",
            "US7523039 *",
            "US7565213 *",
            "US7610553 *",
            "US7630902 *",
            "US7937271 *",
            "US7996233 *",
            "US8000975 *",
            "US8019598 *",
            "US8019616",
            "US8050934 *",
            "US8065139 *",
            "US8103515",
            "US8135593 *",
            "US8160869",
            "US8165871 *",
            "US8175730",
            "US8195472 *",
            "US8224659",
            "US8255208",
            "US8271293",
            "US8285555",
            "US8320500 *",
            "US8392177 *",
            "US8468026",
            "US8473302",
            "US8488800",
            "US8615391 *",
            "US8655663 *",
            "US8725519",
            "US8843380 *",
            "US8924221 *",
            "US9076444 *",
            "US9093120 *",
            "US20010013003 *",
            "US20020154774 *",
            "US20040088160 *",
            "US20040138886 *",
            "US20040162721 *",
            "US20040181403 *",
            "US20050010397 *",
            "US20050060053 *",
            "US20050119880 *",
            "US20070016404 *",
            "US20090003489 *",
            "US20090048826 *",
            "US20090089049 *",
            "US20090198489 *",
            "US20090216353 *",
            "US20100228550 *",
            "US20110112670 *",
            "US20120010738 *",
            "US20120209612 *",
            "US20130003992 *",
            "US20130226595 *",
            "US20130275142 *",
            "USRE42935 *",
            "USRE44126 *",
            "CN101785316B",
            "CN101790755B",
            "CN102436820A *",
            "CN102436820B",
            "EP2176859A1 *",
            "WO2006051451A1 *",
            "WO2008062990A1 *",
            "WO2008082165A1 *",
            "WO2009025441A1 *",
            "WO2009025447A1 *",
            "WO2009031754A1 *",
            "WO2009066869A1 *",
            "WO2011110031A1 *"
        ],
        [
            "Filing date",
            "15 Oct 1999",
            "9 Jan 2002",
            "20 Sep 2000",
            "18 Oct 2002",
            "27 Jan 2004",
            "2 Nov 2001",
            "29 Nov 2000",
            "5 Nov 2003",
            "25 Apr 2002",
            "16 Apr 2002",
            "23 Jul 2003",
            "18 Jan 2005",
            "11 Jun 2002",
            "2 Sep 2003",
            "5 May 2005",
            "5 Apr 2003",
            "4 Jan 2005",
            "21 Mar 2007",
            "12 Aug 2003",
            "22 Jan 2008",
            "14 Nov 2003",
            "21 Dec 2007",
            "29 Nov 2007",
            "14 Jun 2005",
            "14 Jun 2011",
            "3 May 2011",
            "3 Jun 2008",
            "2 Jun 2008",
            "30 Jun 2009",
            "26 Oct 2009",
            "17 Jul 2008",
            "23 Aug 2011",
            "28 Mar 2011",
            "20 Nov 2007",
            "6 May 2008",
            "2 Feb 2009",
            "7 Aug 2012",
            "10 Jul 2008",
            "16 Mar 2010",
            "6 Jul 2006",
            "29 Sep 2008",
            "12 Dec 2007",
            "17 Jul 2008",
            "29 Mar 2013",
            "13 Feb 2008",
            "10 Feb 2011",
            "29 Nov 2000",
            "16 Apr 2002",
            "2 Sep 2003",
            "23 Jul 2003",
            "5 Jun 2002",
            "12 Mar 2004",
            "14 Nov 2003",
            "17 Aug 2004",
            "5 Nov 2003",
            "6 Jul 2006",
            "6 May 2008",
            "2 Jun 2008",
            "25 Sep 2008",
            "2 Feb 2009",
            "7 Dec 2006",
            "29 Sep 2008",
            "17 Feb 2009",
            "17 May 2010",
            "",
            "",
            "29 Mar 2013",
            "6 Jan 2012",
            "21 Dec 2007",
            "15 Nov 2011",
            "30 Jun 2008",
            "30 Jun 2008",
            "29 Sep 2010",
            "29 Sep 2010",
            "30 Jun 2008",
            "3 Nov 2005",
            "20 Nov 2007",
            "28 Dec 2007",
            "11 Jun 2008",
            "30 Jun 2008",
            "30 Jun 2008",
            "9 Oct 2008",
            "23 Nov 2010"
        ],
        [
            "Publication date",
            "25 Feb 2003",
            "10 Jun 2003",
            "5 Oct 2004",
            "7 Dec 2004",
            "27 Dec 2005",
            "28 Mar 2006",
            "27 Jun 2006",
            "1 Aug 2006",
            "25 Dec 2007",
            "15 Jan 2008",
            "22 Apr 2008",
            "10 Jun 2008",
            "4 Nov 2008",
            "21 Apr 2009",
            "21 Jul 2009",
            "27 Oct 2009",
            "8 Dec 2009",
            "3 May 2011",
            "9 Aug 2011",
            "16 Aug 2011",
            "13 Sep 2011",
            "13 Sep 2011",
            "1 Nov 2011",
            "22 Nov 2011",
            "24 Jan 2012",
            "13 Mar 2012",
            "17 Apr 2012",
            "24 Apr 2012",
            "8 May 2012",
            "5 Jun 2012",
            "17 Jul 2012",
            "28 Aug 2012",
            "18 Sep 2012",
            "9 Oct 2012",
            "27 Nov 2012",
            "5 Mar 2013",
            "18 Jun 2013",
            "25 Jun 2013",
            "16 Jul 2013",
            "24 Dec 2013",
            "18 Feb 2014",
            "13 May 2014",
            "23 Sep 2014",
            "30 Dec 2014",
            "7 Jul 2015",
            "28 Jul 2015",
            "9 Aug 2001",
            "24 Oct 2002",
            "6 May 2004",
            "15 Jul 2004",
            "19 Aug 2004",
            "16 Sep 2004",
            "13 Jan 2005",
            "17 Mar 2005",
            "2 Jun 2005",
            "18 Jan 2007",
            "1 Jan 2009",
            "19 Feb 2009",
            "2 Apr 2009",
            "6 Aug 2009",
            "27 Aug 2009",
            "9 Sep 2010",
            "12 May 2011",
            "12 Jan 2012",
            "16 Aug 2012",
            "3 Jan 2013",
            "29 Aug 2013",
            "17 Oct 2013",
            "15 Nov 2011",
            "2 Apr 2013",
            "28 Nov 2012",
            "6 Aug 2014",
            "2 May 2012",
            "28 Aug 2013",
            "21 Apr 2010",
            "18 May 2006",
            "29 May 2008",
            "10 Jul 2008",
            "26 Feb 2009",
            "26 Feb 2009",
            "12 Mar 2009",
            "28 May 2009",
            "15 Sep 2011"
        ],
        [
            "Applicant",
            "Creative Technology Ltd.",
            "Mitsubishi Denki Kabushiki Kaisha",
            "Nokia Mobile Phones Ltd.",
            "National Central University",
            "Dolby Laboratories Licensing Corporation",
            "Koninklijke Philips Electronics N.V.",
            "Koninklijke Philips Electronics N.V.",
            "Qualcomm, Incorporated",
            "Dolby Laboratories Licensing Corporation",
            "Koninklijke Philips Electronics N.V.",
            "Stmicroelectronics Asia Pacific Pte. Ltd.",
            "Nokia Corporation",
            "Sony Corporation",
            "Samsung Electronics Co., Ltd.",
            "Gracenote, Inc.",
            "Apple Inc.",
            "Digital Rise Technology Co., Ltd.",
            "Digital Rise Technology Co., Ltd.",
            "Panasonic Corporation",
            "Samsung Electronics Co., Ltd.",
            "Texas Instruments Incorporated",
            "Samsung Electronics Co., Ltd.",
            "Texas Instruments Incorporated",
            "Koninklijke Philips Electronics N.V.",
            "Huawei Technologies Co., Ltd.",
            "Huawei Technologies Co., Ltd.",
            "Samsung Electronics Co., Ltd.",
            "Samsung Electronics Co., Ltd.",
            "Sony Corporation",
            "Dolby Laboratories Licensing Corporation",
            "Samsung Electronics Co., Ltd.",
            "Digital Rise Technology Co., Ltd.",
            "Digital Rise Technology Co., Ltd.",
            "Samsung Electronics Co., Ltd.",
            "At&T Intellectual Property Ii, Lp",
            "Samsung Electronics Co., Ltd.",
            "Digital Rise Technology Co., Ltd.",
            "Samsung Electronics Co., Ltd.",
            "Dolby Laboratories Licensing Corporation",
            "Samsung Electronics Co., Ltd.",
            "D&M Holdings, Inc.",
            "Samsung Electronics Co., Ltd.",
            "Samsung Electronics Co., Ltd.",
            "Huawei Technologies Co., Ltd",
            "Samsung Electronics Co., Ltd.",
            "Yahoo! Inc.",
            "Rakesh Taori",
            "Oomen Arnoldus Werner Johannes",
            "Samsung Electronics Co., Ltd.",
            "Stmicroelectronics Asia Pacific Pte Limited",
            "Oomen Arnoldus Werner Johannes",
            "Chien-Hua Hsu",
            "Atsuhiro Sakurai",
            "Arora Manish",
            "Sharath Manjunath",
            "Samsung Electronics Co., Ltd.",
            "Ye Li",
            "Samsung Electronics Co., Ltd.",
            "Samsung Electronics Co., Ltd.",
            "Samsung Electronics Co., Ltd.",
            "Nxp B.V.",
            "D&M Holdings Inc.",
            "Sascha Disch",
            "Mitsubishi Electric Corporation",
            "Intonow",
            "Sascha Disch",
            "Huawei Technologies Co., Ltd.",
            "Sony Corporation",
            "Dolby Laboratories Licensing Corporation",
            "Dolby Laboratories Licensing Corporation",
            "\u4e09\u661f\u7535\u5b50\u682a\u5f0f\u4f1a\u793e",
            "\u4e09\u661f\u7535\u5b50\u682a\u5f0f\u4f1a\u793e",
            "\u534e\u4e3a\u6280\u672f\u6709\u9650\u516c\u53f8",
            "\u534e\u4e3a\u6280\u672f\u6709\u9650\u516c\u53f8",
            "Samsung Electronics Co., Ltd.",
            "Koninkl Philips Electronics Nv",
            "Samsung Electronics Co Ltd",
            "Samsung Electronics Co Ltd",
            "Samsung Electronics Co Ltd",
            "Samsung Electronics Co Ltd",
            "Samsung Electronics Co Ltd",
            "Seungkwon Beack",
            "Huawei Technologies Co.,Ltd."
        ],
        [
            "Title",
            "Pitch-Preserved digital audio playback synchronized to asynchronous clock",
            "Audio signal encoding apparatus",
            "Speech coding exploiting the power ratio of different speech signal components",
            "Nonlinear operation method suitable for audio encoding/decoding and hardware applying the same",
            "Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients",
            "Method and apparatus for audio coding using transient relocation",
            "Method of and system for coding and decoding sound signals",
            "Method and apparatus for subsampling phase spectrum information",
            "Transient performance of low bit rate audio coding systems by reducing pre-noise",
            "Audio coding",
            "Method and system for parametric characterization of transient audio signals",
            "Compensation of transient effects in transform coding",
            "Acoustic signal encoding method and apparatus, acoustic signal decoding method and apparatus and recording medium",
            "Method for encoding digital audio using advanced psychoacoustic model and apparatus thereof",
            "Device and method for analyzing an information signal",
            "Method and apparatus for reducing data events that represent a user's interaction with a control interface",
            "Apparatus and methods for digital audio coding using codebook application ranges",
            "Audio decoding using variable-length codebook application ranges",
            "Acoustic coding of an enhancement frame having a shorter time length than a base frame",
            "User adjustment of signal parameters of coded transient, sinusoidal and noise components of parametrically-coded audio before decoding",
            "Phase locking method for frequency domain time scale modification based on a bark-scale spectral partition",
            "Method and apparatus for encoding audio signal, and method and apparatus for decoding audio signal",
            "Local pitch control based on seamless time scale modification and synchronized sampling rate conversion",
            "Method of audio encoding",
            "Signal classification processing method, classification processing device, and encoding system",
            "Methods, apparatuses and system for encoding and decoding signal",
            "Method and apparatus for encoding continuation sinusoid signal information of audio signal and method and apparatus for decoding same",
            "Encoding method and apparatus for efficiently encoding sinusoidal signal whose magnitude is less than masking value according to psychoacoustic model and decoding method and apparatus for decoding encoded sinusoidal signal",
            "Device and method for analyzing an information signal",
            "High quality time-scaling and pitch-scaling of audio signals",
            "Audio encoding method and apparatus, and audio decoding method and apparatus, for processing death sinusoid and general continuation sinusoid",
            "Codebook segment merging",
            "Audio decoding using variable-length codebook application ranges",
            "Method, medium, and system scalably encoding/decoding audio/speech",
            "Clustered OFDM with channel estimation",
            "Method and apparatus for frequency encoding, and method and apparatus for frequency decoding",
            "Audio decoding using variable-length codebook application ranges",
            "Parametric audio encoding and decoding apparatus and method thereof having selective phase encoding for birth sine wave",
            "Segmenting audio signals into auditory events",
            "Method and apparatus to extract important spectral component from audio signal and low bit-rate audio signal coding and/or decoding method and apparatus using the same",
            "Audio signal interpolation device and audio signal interpolation method",
            "Audio encoding and decoding apparatus and method thereof",
            "Method and apparatus for encoding residual signals and method and apparatus for decoding residual signals",
            "Method and device for encoding a high frequency signal, and method and device for decoding a high frequency signal",
            "Method and apparatus for sinusoidal audio coding and method and apparatus for sinusoidal audio decoding",
            "Audio fingerprint extraction by scaling in time and resampling",
            "Method of and system for coding and decoding sound signals",
            "Audio coding",
            "Method for encoding digital audio using advanced psychoacoustic model and apparatus thereof",
            "Method and system for parametric characterization of transient audio signals",
            "Editing of audio signals",
            "Coding apparatus and method thereof for detecting audio signal transient",
            "Phase locking method for frequency domain time scale modification based on a bark-scale spectral partition",
            "Method and apparatus to adaptively insert additional information into an audio signal, a method and apparatus to reproduce additional information inserted into audio data, and a recording medium to store programs to execute the methods",
            "Method and apparatus for subsampling phase spectrum information",
            "Method and apparatus to extract important spectral component from audio signal and low bit-rate audio signal coding and/or decoding method and apparatus using the same",
            "Clustered OFDM with channel estimation",
            "Encoding method and apparatus for efficiently encoding sinusoidal signal whose magnitude is less than masking value according to psychoacoustic model and decoding method and apparatus for decoding encoded sinusoidal signal",
            "Method and apparatus for adaptively determining quantization step according to masking effect in psychoacoustics model and encoding/decoding audio signal by using determined quantization step",
            "Method and apparatus for frequency encoding, and method and apparatus for frequency decoding",
            "Device for and method of processing an audio data stream",
            "Audio signal interpolation device and audio signal interpolation method",
            "Device and Method for Manipulating an Audio Signal Having a Transient Event",
            "Audio signal processing device",
            "Extraction and Matching of Characteristic Fingerprints from Audio Signals",
            "Device and method for manipulating an audio signal having a transient event",
            "Method and device for encoding a high frequency signal, and method and device for decoding a high frequency signal",
            "Signal processing device, method, and program",
            "Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients",
            "Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients",
            "Audio encoding method and apparatus, and audio decoding method and apparatus, for processing death sinusoid and general continuation sinusoid",
            "Method and apparatus for encoding and decoding continuation sinusoidal signal of audio signal",
            "High frequency band signal coding and decoding methods and devices",
            "High frequency band signal coding and decoding methods and devices",
            "Method and apparatus for encoding and decoding continuation sinusoidal signal of audio signal",
            "Audio coding and decoding",
            "Method, medium, and system scalably encoding/decoding audio/speech",
            "Audio encoding and decoding apparatus and method thereof",
            "Method and apparatus for encoding continuation sinusoid signal information of audio signal and method and apparatus for decoding same",
            "Audio encoding method and apparatus, and audio decoding method and apparatus, for processing death sinusoid and general continuation sinusoid",
            "Parametric audio encoding and decoding apparatus and method thereof",
            "Frequency band determining method for quantization noise shaping and transient noise shaping method using the same",
            "Method and device for encoding high frequency signal, and method and device for decoding high frequency signal"
        ]
    ],
    "pageTitle": "Patent US6266644 - Audio encoding apparatus and methods - Google Patents",
    "title": "",
    "url": "http://www.google.ca/patents/US6266644",
    "hasHeader": true,
    "headerPosition": "FIRST_ROW",
    "tableType": "RELATION",
    "tableNum": 8,
    "s3Link": "common-crawl/crawl-data/CC-MAIN-2015-32/segments/1438043060830.93/warc/CC-MAIN-20150728002420-00074-ip-10-236-191-2.ec2.internal.warc.gz",
    "recordEndOffset": 481046863,
    "recordOffset": 480998611,
    "tableOrientation": "HORIZONTAL",
    "TableContextTimeStampAfterTable": "{107773=As shown in the FIG. 12 flowchart, in step 1201, the masking thresholds for the sinusoidally modeled audio are determined. In step 1203, very low signal-to-mask ratio (\u201cSMR\u201d) parameters are discarded. In step 1205, audio below masking plus duration criteria are discarded. In step 1207, trajectories with low SMR are discarded. In step 1209, the audio data is converted to a corresponding difference-based representation, in step 1211, the audio data amplitude and frequency are conventionally quantized, and in step 1213, the amplitude and frequency values are Huffman coded., 123120=As shown in FIG. 16, in step 1601, a trajectory is received. Next, in step 1603, the time-average SMR of the received trajectory is calculated. If, in step 1605, the calculated SMR is greater than or equal to an SMR-threshold, then the trajectory is left unchanged. If instead, in step 1605, the calculated SMR is less than the SMR-threshold, then the trajectory is downsampled in accordance with steps 1607 through 1615. Downsampling is preferably performed (separately) on each amplitude and frequency trajectory., 130006=The preferred operation of phase selector 1801 and envelope generator 1802 are more easily understood with reference to FIGS. 19a and 19 b. In FIG. 19a, a sinusoidally encoded region is shown in an upper graph while a transient region is shown in the lower graph, time being depicted along the x-axis and amplitude along the y-axis. Time is indicated in frames and amplitude are respectively depicted roughly in terms of dB. FIG. 19b is arranged the same as in FIG. 19a except that a transition frame, NA, has been enlarged to more clearly show preferred octave-dependent transitions where multiresolution sinusoidal modeling replaces traditional modeling., 142248=The FIG. 25 flowchart illustrates a method for line segment approximation. As shown, in step 2501, noise encoded data is received. Preferably the data has been bark band modeled. Next, in step 2503, the first and last points are chosen as breakpoints (i.e. they will be transferred in the final encoded data). In step 2505, the data is polled for another breakpoint that minimizes error (e.g. mean square error) between received and synthesized audio data for a determined data reduction ratio. Then, in step 2507, a determination is made as to whether the number of breakpoints is greater than or equal to the reduction ratio times the number of points in the received data. If, in step 2509, the condition of step 2507 is not met, then operation proceeds to step 2505 for another iteration. If instead, in step 2509, the condition of step 2507 is met, then the time differences of the found breakpoints are calculated in step 2511 and then Huffman coded in step 2513. Further, having met this condition, the amplitude differences of the break points are calculated in step 2515, then quantized to a 1.5 dB scale in step 2517, and then Huffman coded in step 2519. An example of the line segment approximation method of FIG. 25 is illustrated in FIG. 26. The upper graph depicts an original noise source which is then shown in quantized form in the lower graph. While the appearance has changed significantly due to the substantial reduction of data, high fidelity is yet achieved., 132024=Also shown are decreasing and increasing envelopes respectively at frames NA 1911 and NB 1914, which are produced by envelope generator 1802 (FIG. 18) and through the operation of summer 504. (Note that an increasing envelope preferably extends from a zero level to a maximum level according to a corresponding stored amplitude or frequency.) A simple ramping function is easily created (e.g. using a progressive multiply or add), has been shown to provide sufficiently high fidelity results and is therefore preferred. The ramping function has been found to sufficiently mask not only phase-matched transitions to a transient region, but also time-varying phase transitions preferably applied by a decoder at transitions from a transient region. However, numerous other envelopes, such as an exponential function, can also be used according to fidelity or other considerations. As shown in FIG. 19, where multiresolution sinusoidal modeling is used, a separate ramping function is preferably applied for each frequency range. Such multiple functions are applied due to the frequency-varying window sizes utilized., 122093=Returning to FIG. 13, with reference to FIGS. 16 and 17, after SMR trajectory processing and upon receipt by downsample processor 1209, the SMR processed data is then downsampled. Despite other quantization utilized, the use of a high bit rate encoder necessitates further data reduction. Conventional data reduction methods, such as reducing the number of bits used to quantize each parameter and wholly eliminating selected sinusoidal triads, were found to have a substantial detrimental impact on audio fidelity. Thus, after much experimentation, it is determined that significant data reduction can be achieved with minimized impact on audio fidelity by smoothing only the least perceptually important trajectories. The preferred downsampling process is illustrated in FIG. 16 and then exemplified in FIGS. 17a and 17 b. Using downsampling, a data reduction of approximately 50 percent per trajectory is achieved with little if any noticeable impact on audio fidelity., 141608=As shown in FIG. 24, HF noise quantizer 563 preferably comprises rounding quantizer 2401 and line segment approximator 2403. Conventionally, noise is each parameter is individually quantized in time, resulting in a very high bit rate in even the quantized data. Rounding quantizer 2401 preferably performs such a quantization prior to line segment approximation. Line segment approximation, however, smoothes less perceptually important data, thereby producing quantized data having only twenty percent of the original sampled noise gains with little if any perceptual alteration of the data., 111396=The following table lists the preferred SMR-trajectory thresholds utilized with SMR-trajectory processor 1207. As discussed, the use of a traditional sinusoidal modeler is preferred as providing a low bit-rate, however, in applications where higher fidelity is considered more important than bit-rate, multiresolution sinusoidal modeling might be employed. Therefore, preferred thresholds for both are included in the chart. In the case of a traditional sinusoidal modeler, the threshold parameters reflect an audio source sampled at 44.1 kHz and modeled using a window size of approximately 20 msec and a hop size of approximately 10 msec. In the case of a multiresolution sinusoidal modeler, the threshold parameters reflect an audio source again sampled at 44.1 kHz, but with modeling using window sizes of approximately 13 msec (at 2500-5000 Hz), 26 msec (at 1250-2500 Hz) and 43 msec (at 0-1250 Hz), each with a hop size of 50 percent. Those skilled in the art will, however, appreciate that the use of other window numbers/sizes, frequency band and threshold parameter variations, among other permutations, might be required according to the application and/or specific audio sources, among other factors. Once again, as with other potential variables throughout the invention, providing automatic operation is preferred over requiring direct user modification., 128638=The FIG. 18 flow diagram illustrates a preferred sinusoidal splicer according to the invention. As shown, splicer 534 comprises communicatingly coupled elements including phase selector 1801 and envelope generator 1802. Operationally, phase selector 1801 receives sinusoidal parameters from sinusoidal quantizer 533, selects from among the available phases those phases needed for phase matching during decoding and discards the remaining phase parameters. Envelope generator 1802 modifies the sinusoidal amplitude and frequency parameters to provide decreasing and increasing envelopes respectively at non-transient to transient region boundaries and at transient to non-transient region boundaries., 110515=The FIG. 15 flowchart illustrates the preferred operation of SMR-trajectory processor 1207 with respect to a given trajectory. In step 1501, a trajectory is received. In step 1503, the length of the received trajectory is determined. In step 1505, a time-averaged SMR is calculated for the received trajectory. Next, in step 1507 the determined trajectory length and calculated SMR for the received trajectory are compared with a threshold length and SMR pair. If, in step 1509 the received trajectory length and SMR are greater than or equal to the threshold length and SMR, then, in step 1511, the received trajectory is retained. Otherwise, the received trajectory is discarded in step 1513. Retained trajectories are then transferred to downsample processor 1209 as indicated in FIG. 13., 133210=The FIG. 20 flowchart illustrates the preferred methods used by splicer 534 for phase selection and envelope generation. As shown, in step 2001, splicer 534 receives a frame of audio data. If, in step 2003, the received frame is a pre-transient frame, then the phase parameters at the end of the frame are saved in step 2005, and a decreasing envelope is generated in the next frame. If instead, the received frame is not a pre-transient frame, the operation proceeds to step 2011. If, in step 2011, the received frame is an end of transient frame, then the phase parameters at the end of the frame are saved in step 2005, and an increasing envelope is generated in the current frame. If, in step 2011, the received frame is not an end of transient frame, then the phase parameters for the frame are discarded., 144998=Turning now to FIG. 27, compressed domain processor preferably comprises communicatingly coupled elements including non-transient stretcher 2701 and transient mover 2703. During time scale modification, non-transient stretcher 2701 preferably operates in a conventional fashion to stretch and compress sinusoidal and noise encoded data, but only for non-transients. In contrast, transient-mover 2703 neither alters nor affects the relationship between data points in a transient region. This relationship is illustrated in greater detail in the FIG. 28 flowchart, which depicts a preferred method for compressed domain time compression and expansion. As shown, encoded audio data is received in step 2801. If, in step 2803, sinusoidal data is received, then the frame lengths are contracted or expanded in step 2807 according to the desired amount of time scale modification. If, in step 2811, the received data includes noise, then, the energy gain envelopes are expanded or contracted in time. If instead, in step 2811, the received data contains transients, then, in step 2815, the received transient region (or region portion) is moved to another position in time., 140057=A more preferred embodiment of the FIG. 22 method is illustrated in FIG. 23. As shown, a high frequency region is selected encompassing from four windows before transient event 2301 to five frames after transient event 2301. The high frequency in this case is set at 16 kHz. Thus, if a window is received within the high frequency region (e.g. from window 6 to window 15), then the MDCT coefficients are grouped from 0 to 16 kHz. On the other hand, if a window is received whose window number is outside the high frequency range (e.g. from 1 to 5 or 16 to 24), then the DCT coefficients are grouped from 0 to 5 kHz., 108418=Turning now to the FIG. 13 flow diagram, sinusoidal quantizer 533 preferably comprises communicatingly coupled elements including psychoacoustic masking threshold processor 1201, SMR limiter 1203, trajectory-former (\u201ctracker\u201d) 1205, SMR-trajectory processor 1207, down-sample processor 1209, difference processor 1211, final quantizer 1212 and Huffman coder 1213. Operationally, upon receipt of audio data from limiter 532, a conventional psychoacoustic masking threshold processor 1201, SMR limiter and tracker are each utilized in a conventional manner. Masking threshold processor 1201 computes masking thresholds for the audio data, SMR limiter removes audio data that is significantly below computed masking thresholds (e.g. \u22123 dB), and tracker forms trajectories from the SMR-limited audio data., 106299=The FIG. 11 flowchart illustrates how, following sinusoidal modeling, region limiter 532 (FIG. 5) preferably uses transient parameters stored in frame list 726 to limit sinusoidally encoded data to only non-transient regions of the source audio. As shown, in step 1101, region limiter 532 receives a first frame of audio source data. Since the audio source has been sinusoidally modeled, the data will include frame-based sinusoidal parameter triads. Next, in step 1103, region limiter 532 polls frame list 726 for the frame type of the current frame (in this instance, the first frame). If, in step 1105, the frame type is a transient, then the sinusoidal parameters for the frame are discarded and operation proceeds to step 1111. Otherwise, operation proceeds directly to step 1111. If in step 1111, more frames remain, then region limiter 532 receives a next frame (i.e. now the current frame) in step 113 and operation proceeds to step 1103. Otherwise, limiting has been completed., 110064=The FIG. 14 graph illustrates an example of this relationship according to audio sources tested. As shown, increasing average SMR is given along the y-axis and increasing trajectory length is depicted along the x-axis. Line 1401 indicates an exemplary SMR-trajectory length threshold such that audio data falling below line 1401 can be discarded, while all audio data at or above line 1401 should be preserved., 138438=Turning now to FIGS. 22 and 23, with reference to FIG. 5, the transform coded data produced by transient modeler 552 is transferred to transient quantizer 553. While quantization of transform coded data is conventionally accomplished using only psychoacoustic modeling, as discussed, an unacceptable tradeoff was encountered relying on this method. That is, in order to achieve an acceptable bit rate, fidelity had to be sacrificed to unacceptable levels. However, it is found that both high fidelity and low bit rates can be achieved by the preferred pruning type process 2200 illustrated in FIG. 22. This process is then followed by a conventional psychoacoustic modeling method, such as that illustrated. As shown, a data window (e.g. 256 points) is received in step 2201 and the frame number of the transient event is received in step 2203. Next, in step 2205, it is determined whether the window number of the received frame is within a higher frequency range criteria. If, in step 2211, the window number is within the criteria, then, in step 2215, the MDCT coefficients are grouped from 0 to a high frequency range. Otherwise, the coefficients are grouped from 0 to a low frequency range in step 2215. Following this method, conventional psychoacoustic modeling is performed. Alternatively, data might be pruned prior to encoding, for example, using region limiter 551. In addition, any number of frequency and time ranges can be used. For example, each of the 24 MDCT windows could have a separate frequency range., 136913=The FIG. 21 flowchart, with reference to FIG. 7, illustrates how region limiter 551 preferably uses transient parameters stored in frame list 726 to limit transform coded data to only transient regions of the source audio. As shown, in step 2101, region limiter 551 receives a first frame of audio source data. Next, in step 2103, region limiter 551 polls frame list 726 (FIG. 7) for the frame type of the current frame (in this instance, the first frame). If, in step 2105, the frame type is not a transient, then the audio source data for the frame are discarded and operation proceeds to step 2111. Otherwise, operation proceeds directly to step 2111. If in step 2111, more frames remain, then region limiter 551 receives a next frame (i.e. now the current frame) in step 2113 and operation proceeds to step 2103. Otherwise, limiting has been completed., 124558=In step 1611, downsample processor 1309 calculates the average of each consecutive non-overlapping parameter pair. Next, in step 1613, each first parameter in each pair is replaced with the corresponding calculated average. Finally, in step 1615, the second parameter in each parameter pair is discarded., 104415=The FIG. 10 simplified flow diagram illustrates a generic example of a sinusoidal modeler 531 (FIG. 5) and the data generated by the modeler when an audio source is supplied. As shown, sinusoidal modeler 531 broadly comprises communicatingly coupled elements including filterbank 1001 and parameter estimaters 1002 a-c. Operationally, an audio source received by filterbank 1001 separated into frequency bands which are then analyzed by parameter estimators 1002 a-c. (Note that the complete frequency range of all parameter estimaters is preferably from 0 to 5 kHz, thereby correspondingly limiting sinusoidal encoding to that range. As noted earlier, non-transient frequencies above 5 kHz will be noise modeled.) The results of parameter estimation are then output as frame-based sinusoidal parameter triads. A separate triad is produced for each sinusoid used to represent the audio contained in each frame of the audio source, as given by N1, N2 and N3, and each sinusoid includes a triad of amplitude, frequency and phase parameters. These sinusoidal parameter triads are then transferred to transient detector 112 and region limiter 532 as depicted., 109323=Continuing with FIG. 13, with reference to FIGS. 14 and 15, the trajectories formed by tracker 1205 are then transferred to SMR-trajectory processor 1207. SMR-trajectory processor 1207 operates in accordance with a discovery concerning the perceptual relationship between SMR and trajectory length. Listening tests have revealed that audio signals represented by increasing trajectory lengths require decreasing SMR thresholds in order to be perceptually important and visa versa. Stated alternatively, whether audio data can be discarded without adversely impacting audio fidelity can be determined according to an inversely proportional relationship between trajectory length and time-averaged SMR., 130738=As shown in FIG. 19a, an interface is formed in frames NA and NA-1 joining a non-transient region extending from frame NA-X to frame boundary 1901 and a transient region extending from frame boundary 1901 to frame boundary 1902. A further interface is formed in frame NB (\u201cend-of-transient frame\u201d) joining the same transient region to a further non-transient region beginning at frame boundary 1902. Since frame NA 1912 includes the sinusoidal overlap, the sinusoidally encoded phase parameters must be matched to the transform coded phase in that frame. However, since an instantaneous phase transition would produce audible artifacts, the phase is preferably corrected in frame NA-1 1911, which immediately precedes the transient region (\u201cpre-transient frame\u201d). Therefore, the phase parameters at frame boundary 1901 are preserved in the final sinusoidally encoded data. In contrast, at the end of a transient region, phase is preferably corrected during the sinusoidal overlap, since phase matching is immediately required. Therefore, the phase parameters at frame boundary 1902 are preserved in the final sinusoidally encoded data., 47207=This inventor's prior U.S. patent application Ser. No. 09/007,995, filed Jan. 16, 1998, teaches a number of improvements to conventional encoding methods. Among these improvements are multi resolution sinusoidal encoding, sinusoidal transient encoding, and a composite encoding system employing these encoding methods in combination with noise modeling. U.S. patent application Ser. No. 09/007,995 is hereby incorporated by reference as if repeated verbatim immediately hereinafter., 123697=Steps 1607 through 1609 address the problem that while downsampling is preferably performed on trajectory parameter pairs, trajectories can have either even or odd lengths (i.e. an even or odd number of trajectory parameters). Thus, if, in step 1607, an even length trajectory has been received, then downsampling is performed on trajectory parameter pairs beginning with the first trajectory parameter in steps 1611 through 1615. If instead, in step 1607, an odd length trajectory is received, then the first trajectory parameter is skipped in 1609 and downsampling of steps 1611 through 1615 are performed beginning with the second trajectory parameter (i.e. the first parameter is retained unaltered.) Note that a \u201cskipped\u201d is transferred along with the other resultant data., 125836=Returning again to FIG. 13, following downsampling, the downsampled trajectories are preferably transferred from downsample processor 1309 to difference processor, 1311, then final quantizer 1312 and finally, Huffman coder 1313. Each of these remaining quantizer 533 elements preferably operates in a conventional manner. More specifically, difference processor 1311 performs a temporal difference along each amplitude and frequency trajectory. Next, final quantizer 1312 quantizes all amplitudes to a 1.5 dB magnitude scale, frequencies above 500 Hz to the nearest ten cents and frequencies below 500 Hz to the nearest 3 Hz. Finally, Huffman coder 1313 performs well-known Huffman coding. This completes sinusoidal quantization.}",
    "textBeforeTable": "Patent Citations While the present invention has been described herein with reference to particular embodiments thereof, a latitude of modification, various changes and substitutions are intended in the foregoing disclosure, and it will be appreciated that in some instances some features of the invention will be employed without a corresponding use of other features without departing from the scope and spirit of the invention as set forth. Therefore, many modifications may be made to adapt a particular situation or material to the teachings of the invention without departing from the essential scope and spirit of the present invention. It is intended that the invention not be limited to the particular embodiment disclosed as the best mode contemplated for carrying out this invention, but that the invention will include all embodiments and equivalents falling within the scope of the appended claims. FIG. 34 illustrates exemplary composite encoded audio according to the invention. More specifically, graph 34 a depicts an audio source and graph 34 b depicts a composite waveform formed by combining sinusoidal, transient and noise encoding as discussed herein. The remain graphs 34 c through 34 f respectively represent each of the encoded data components of graph 34 b. That is graph 34 c shows sinusoidally encoded data, 34 d shows transform coded transients, 34 e shows LF noise encoded data and 34 f depicts HF noise encoded data according to the teachings herein. The FIG. 33 flowchart",
    "textAfterTable": "Sascha Disch Device and Method for Manipulating an Audio Signal Having a Transient Event US20120010738 * 17 May 2010 12 Jan 2012 Mitsubishi Electric Corporation Audio signal processing device US20120209612 * 16 Aug 2012 Intonow Extraction and Matching of Characteristic Fingerprints from Audio Signals US20130003992 * 3 Jan 2013 Sascha Disch Device and method for manipulating an audio signal having a transient event US20130226595 * 29 Mar 2013 29 Aug 2013 Huawei Technologies Co., Ltd. Method and device for encoding a high frequency signal, and method and device for decoding a high frequency signal US20130275142 * 6 Jan 2012 17 Oct 2013 Sony Corporation Signal processing device, method, and program USRE42935 * 21 Dec 2007 15 Nov 2011 Dolby Laboratories Licensing Corporation Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients USRE44126",
    "hasKeyColumn": false,
    "keyColumnIndex": -1,
    "headerRowIndex": 0
}